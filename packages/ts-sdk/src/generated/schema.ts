/**
 * This file was auto-generated by openapi-typescript.
 * Do not make direct changes to the file.
 */


/** OneOf type helpers */
type Without<T, U> = { [P in Exclude<keyof T, keyof U>]?: never };
type XOR<T, U> = (T | U) extends object ? (Without<T, U> & U) | (Without<U, T> & T) : T | U;
type OneOf<T extends any[]> = T extends [infer Only] ? Only : T extends [infer A, infer B, ...infer Rest] ? OneOf<[XOR<A, B>, ...Rest]> : never;

export interface paths {
  "/data_credentials": {
    /**
     * Get All Credentials
     * @description Returns all data credentials accessible to the authenticated user.
     */
    get: operations["get_data_credentials"];
    /**
     * Create a Credential
     * @description Creates a Nexla data credential with the specified configuration in your Nexla account.
     *
     * > Note: `name`, `credentials_type`, and `credentials` are required.
     */
    post: operations["create_data_credential"];
  };
  "/data_credentials/{credential_id}": {
    /**
     * Get Credential by ID
     * @description Returns a credential object if a valid ID is provided.
     */
    get: operations["get_data_credential"];
    /**
     * Update Credential
     * @description Updates a data credential in the authenticated user's account.
     *
     * > Note: This method does not perform partial updating of the `credentials` object. The entire `credentials` object will be updated if this is added to the payload.
     */
    put: operations["update_data_credential"];
    /**
     * Delete a Credential
     * @description Deletes a credential from your Nexla account.
     */
    delete: operations["delete_data_credential"];
  };
  "/data_credentials/{credential_id}?expand=1": {
    /**
     * Get Credential by ID with expanded references
     * @description Returns a credential object along with advanced information about associated references if a valid ID is provided.
     */
    get: operations["get_data_credential_expanded"];
  };
  "/data_credentials/{credential_id}/probe": {
    /**
     * Test credential validity
     * @description Use this endpoint to check whether or not a credential is valid.
     */
    get: operations["data_credential_probe"];
  };
  "/data_credentials/{credential_id}/probe/tree": {
    /**
     * Preview Storage Structure
     * @description Use this endpoint to preview the structure/hierarchy of storage to which this credential grants access. For example, you can use this endpoint to see the folder and file structure of a file storage system or the table-column structure of a database.
     * This can be used to inspect the directory hierarchy of file content storage or the database schema of a database/warehouse storage system. Note that this endpoint is only valid for credentials for storage systems wherein a storage structure needs to be reviewed.
     */
    post: operations["preview_storage_structure"];
  };
  "/data_credentials/{credential_id}/probe/sample": {
    /**
     * Preview Connector Content
     * @description Use this endpoint to preview the data content in a storage system.
     *
     * 1. For file systems, this can be used to preview the file content of any specific file.
     * 2. For database systems, it can be used to preview sample rows from a table or query result.
     * 3. For the rest connector, it can be used to preview the results of any API request.
     * 4. For streaming connectors, it can be used to preview some records in a topic.
     *
     * For most connectors, it can also be used to determine the type of records that might be detected in the resulting Nexset.
     */
    post: operations["preview_connector_content"];
  };
  "/flows": {
    /**
     * Get All Flows
     * @description Returns all flows accessible to the authenticated user.
     */
    get: operations["get_flows"];
  };
  "/flows/{flow_id}": {
    /**
     * Get Flow by ID
     * @description Returns a flow object if a valid flow ID is provided.
     */
    get: operations["get_flow_by_id"];
    /**
     * Delete a Flow
     * @description Deletes a flow from your Nexla account.
     */
    delete: operations["delete_flow"];
  };
  "/flows/{flow_id}/activate": {
    /**
     * Activate a Flow
     * @description To activate the entire flow, use either the `origin_node_id` from any data source, set or sink in the flow, or include the ?all=1 or ?full_tree=1 query parameter.
     *
     * >**Note**:
     * > 1. All endpoints for activating or pausing a flow operate on the specific resource given and all of the flow nodes downstream from that resource. This allows for pausing and activating sub-flows while leaving the rest of the flow state unchanged.
     * >
     * >  2. You can also activate a flow by using the id of the `data_source`/ `data_set` / `data_sink` that the flow node is linked to. See relevant endpoints in the API references for those resources.
     */
    put: operations["flow_activate_with_flow_id"];
  };
  "/flows/{flow_id}/pause": {
    /**
     * Pause a Flow
     * @description To pause the entire flow, use either the `origin_node_id` from any data source, set or sink in the flow, or include the ?all=1 or ?full_tree=1 query parameter.
     *
     * >**Note**:
     * > 1. All endpoints for activating or pausing a flow operate on the specific resource given and all of the flow nodes  downstream from that resource. This allows for pausing and activating sub-flows while leaving the rest of the flow state unchanged.
     * >
     * >  2. You can also pause a flow by using the id of the `data_source`/ `data_set` / `data_sink` that the flow node is linked to. See relevant endpoints in the API references for those resources.
     */
    put: operations["flow_pause_with_flow_id"];
  };
  "/flows/{flow_id}/copy": {
    /**
     * Copy a Flow
     * @description Use this endpoint to create a copy of an existing flow.
     */
    post: operations["flow_copy_with_flow_id"];
  };
  "/flows/{flow_id}/docs/recommendation": {
    /**
     * Generate an AI suggestion for flow documentation
     * @description Request a suggestion for Flow documentation. GenAI has to be configured properly for this request, or else you get a message with an error.
     */
    post: operations["flow_docs_recommendation"];
  };
  "/{resource_type}/{resource_id}/flow": {
    /**
     * Get Flow (by Resource ID)
     * @description Returns a flow object if a valid resource type and resource ID is provided.
     *
     * > Note: This is a variant of flow endpoints where the flow node can referenced not by its own ID, but by the ID of the unique resource that is linked to that flow node.
     */
    get: operations["get_flow_by_resource_id"];
    /**
     * Delete a Flow (by Resource ID)
     * @description Deletes a flow from your Nexla account.
     *
     * > Note: This is a variant of flow endpoints where the flow node can referenced not by its own ID, but by the ID of the unique resource that is linked to that flow node.
     */
    delete: operations["delete_flow_by_resource_id"];
  };
  "/{resource_type}/{resource_id}/activate": {
    /**
     * Activate a Flow (with Resource ID)
     * @description To activate the entire flow include the ?all=1 or ?full_tree=1 query parameter.
     *
     * >**Note**:
     * > 1. All endpoints for activating or pausing a flow operate on the specific resource given and all of the flow nodes downstream from that resource. This allows for pausing and activating sub-flows while leaving the rest of the flow state unchanged.
     * > 2. This is a variant of flow endpoints where the flow node can referenced not by its own ID, but by the ID of the unique resource that is linked to that flow node.
     */
    put: operations["flow_activate_with_resource_id"];
  };
  "/{resource_type}/{resource_id}/pause": {
    /**
     * Pause a Flow (with Resource ID)
     * @description To pause the entire flow include the entire flow include the ?all=1 or ?full_tree=1 query parameter.
     *
     * >**Note**:
     * > 1. All endpoints for activating or pausing a flow operate on the specific resource given and all of the flow nodes  downstream from that resource. This allows for pausing and activating sub-flows while leaving the rest of the flow state unchanged.
     * >
     * > 2. This is a variant of flow endpoints where the flow node can referenced not by its own ID, but by the ID of the unique resource that is linked to that flow node.
     */
    put: operations["flow_pause_with_resource_id"];
  };
  "/data_sources": {
    /**
     * Get All Sources
     * @description Returns all data sources accessible to the authenticated user.
     */
    get: operations["get_data_sources"];
    /**
     * Create a Source
     * @description Creates a new data source in the authenticated user's account.
     *
     * Depending on the type of source you want to create (`source_type`), properties like `source_config` and `data_credentials_id` will require appropriate configuration.
     *
     * > Note: `name`, `source_type`, `source_config` and `data_credentials_id` are required.
     */
    post: operations["create_data_source"];
  };
  "/data_sources/{source_id}": {
    /**
     * Get Source by ID
     * @description Returns a source object if a valid ID is provided.
     */
    get: operations["get_data_source"];
    /**
     * Update a Source
     * @description Updates a data source in the authenticated user's account.
     *
     * Depending on the type of source you want to update (`source_type`), properties like `source_config` and `data_credentials_id` will require appropriate configuration.
     *
     * > Note: This method does not perform partial updating of `source_config`. The entire `source_config` object will be updated if this is added to the payload.
     */
    put: operations["update_data_source"];
    /**
     * Delete a Source
     * @description Deletes a source from your Nexla account.
     */
    delete: operations["delete_data_source"];
  };
  "/data_sources/{source_id}?expand=1": {
    /**
     * Get Source by ID with Expanded References
     * @description Returns a source object along with advanced information about associated references if a valid ID is provided.
     */
    get: operations["get_data_source_expanded"];
  };
  "/data_sources/{source_id}/activate": {
    /**
     * Activate a Source
     * @description Activate a paused data source.
     */
    put: operations["activate_source"];
  };
  "/data_sources/{source_id}/pause": {
    /**
     * Pause a Source
     * @description Pause an active data source.
     */
    put: operations["pause_source"];
  };
  "/data_sources/{source_id}/copy": {
    /**
     * Copy a Source
     * @description Use this endpoint to create a copy of an existing flow.
     */
    post: operations["copy_source"];
  };
  "/data_sets": {
    /**
     * Get All Nexsets
     * @description Retrieves all Nexsets accessible to the authenticated user.
     */
    get: operations["get_nexsets"];
    /**
     * Create a Nexset
     * @description Creates a Nexset from another Nexset.
     *
     * The endpoint accepts a parent Nexset ID along with all transform and validation rules that should be applied to the parent Nexset.
     *
     * The two payload variants reflect the following two ways of specifying transform rules:
     * 1. Attach the transform code that should be applied: Set `has_custom_transform: false`, and attach a `transform` code snippet.
     * 2. Use the ID of a reusable record transform: Set `has_custom_transform: false`, and attach the `transform_id` of the record transform to be applied.
     */
    post: operations["create_nexset"];
  };
  "/data_sets/{set_id}": {
    /**
     * Get a Nexset
     * @description Returns a Nexset object if a valid ID is provided.
     */
    get: operations["get_nexset"];
    /**
     * Update a Nexset
     * @description Updates a Nexset in the authenticated user's account.
     */
    put: operations["update_nexset"];
    /**
     * Delete a Nexset
     * @description Deletes a Nexset from the authenticated user's account.
     */
    delete: operations["delete_nexset"];
  };
  "/data_sets/{set_id}/activate": {
    /**
     * Activate Nexset
     * @description Activates a paused Nexset.
     */
    put: operations["activate_nexset"];
  };
  "/data_sets/{set_id}/pause": {
    /**
     * Pause Nexset
     * @description Pauses an active Nexset.
     */
    put: operations["pause_nexset"];
  };
  "/data_sets/{set_id}/copy": {
    /**
     * Copy Nexset
     * @description Use this endpoint to create a clone of an existing Nexset.
     */
    post: operations["copy_nexset"];
  };
  "/data_sets/{set_id}/samples": {
    /**
     * Get Nexset Samples
     * @description Use this endpoint to fetch some sample records from this Nexset. Use the relevant query parameters to control whether the samples returned are from the live Nexset topic or the Nexset sample cache.
     */
    get: operations["get_nexset_samples"];
  };
  "/data_sets/{data_set_id}/docs/recommendation": {
    /**
     * Generate an AI suggestion for Nexset documentation
     * @description Request a suggestion for Nexset documentation. GenAI has to be configured properly for this request, or else you get a message with an error.
     */
    post: operations["data_set_docs_recommendation"];
  };
  "/data_sinks": {
    /**
     * Get All Sinks
     * @description Retrieves all data sinks accessible to the authenticated user.
     */
    get: operations["get_data_sinks"];
    /**
     * Create a Sink
     * @description Creates a Nexla data_sink with the specified configuration in your Nexla account.
     *
     * > Note: `name` ,`data_set_id`, `sink_type`, `sink_config` and `data_credentials_id` are required.
     */
    post: operations["create_data_sink"];
  };
  "/data_sinks/{sink_id}": {
    /**
     * Get Sink by ID
     * @description Returns a data_sink object if a valid ID is provided.
     */
    get: operations["get_data_sink"];
    /**
     * Update Sink
     * @description Updates a data_sink object in the authenticated user's account.
     *
     * > Note: This method does not perform partial updating of the `sink_config` object. The entire `sink_config` object will be updated if this is added to the payload.
     */
    put: operations["update_data_sink"];
    /**
     * Delete a Sink
     * @description Deletes a sink from your Nexla account.
     */
    delete: operations["delete_data_sink"];
  };
  "/data_sinks/{sink_id}?expand=1": {
    /**
     * Get Sink by ID with Expanded References
     * @description Returns a data_sink object along with advanced information about associated references if a valid ID is provided.
     */
    get: operations["get_data_sink_expanded"];
  };
  "/data_sinks/{sink_id}/activate": {
    /**
     * Activate a Sink
     * @description Activate a paused data sink.
     */
    put: operations["activate_data_sink"];
  };
  "/data_sinks/{sink_id}/pause": {
    /**
     * Pause a Sink
     * @description Pause an active data sink.
     */
    put: operations["pause_data_sink"];
  };
  "/data_sinks/{sink_id}/copy": {
    /**
     * Copy a Sink
     * @description Use this endpoint to create a copy of an existing data sink.
     */
    post: operations["copy_data_sink_source"];
  };
  "/data_maps": {
    /**
     * Get all Data Maps
     * @description Retrieves all lookups (data maps) accessible to the authenticated user.
     */
    get: operations["get_data_maps"];
    /**
     * Create a Static Data Map
     * @description Creates a new static data map in the authenticated user's account. Dynamic data maps can only be created by creating a Destination (Sink) of the type `data_map`.
     *
     * For statically assigned data maps, you can choose to add data rows to the data map by either of the following methods:
     * 1. Send data map entries with this request. In this case, the rows of data are sent as a `data_map` array of objects.
     * 2. Send data map entries as a separate call to add/update entries.
     *
     * You must include `map_primary_key` to specify which map attribute should be used for data matching.
     */
    post: operations["create_static_data_map"];
  };
  "/data_maps/{data_map_id}": {
    /**
     * Get Data Map by ID
     * @description Retrieves a data map object if a valid ID is provided.
     *
     * This call to `/data_maps` **does not** return data map entries, as they can be a large array of objects for big data maps.
     *
     * You can include the `expand` query parameter to fetch the data map entries of smaller static data maps.
     */
    get: operations["get_data_map"];
    /**
     * Update Data Map Metadata
     * @description Updates a data map in the authenticated user's account.
     *
     * This endpoint is suitable for updating the metadata of a data map. We recommend using the data map entries update and delete endpoints to update data map rows.
     */
    put: operations["update_data_map_metadata"];
    /**
     * Delete a Data Map
     * @description Deletes a data map from your Nexla account.
     */
    delete: operations["delete_data_map"];
  };
  "/data_maps/{data_map_id}/entries": {
    /**
     * Upsert Static Data Map Entries
     * @description Updates the entries in a static data map. Use this endpoint to add new entries or update the row corresponding to a specific key.
     */
    put: operations["upsert_data_map_entries"];
  };
  "/data_maps/{data_map_id}/entries/{entry_keys}": {
    /**
     * Check Data Map Entries
     * @description Returns the rows of data from the data map that matches a desired key or key pattern.
     *
     * This endpoint can be used to check whether the data map contains rows of data that match the desired key, keys, or key patterns. Key names should be provided in the path in the format described below.
     */
    get: operations["check_data_map_entries"];
    /**
     * Delete Data Map Entries
     * @description Deletes specific entries from the data map.
     *
     * Use this endpoint to remove specific entries from the data map.
     */
    delete: operations["delete_data_map_entries"];
  };
  "/transforms": {
    /**
     * Get all Reusable Record Transforms
     * @description Reusable record transforms are reusable code blocks that can be used to modify an input record of a Nexset into an output record of that Nexset.
     * Use this endpoint to fetch all reusable record transforms.
     */
    get: operations["get_reusable_record_transforms"];
    /**
     * Create a Reusable Record Transform
     * @description Create a new reusable record transform.
     */
    post: operations["create_reusable_record_transform"];
  };
  "/transforms/{transform_id}": {
    /**
     * Get A Reusable Record Transform
     * @description Returns a reusable record transform object if a valid ID is provided.
     */
    get: operations["get_reusable_record_transform"];
    /**
     * Update Reusable Record Transform
     * @description Updates a transform in the authenticated user's account.
     */
    put: operations["update_reusable_record_transform"];
    /**
     * Delete a Reusable Record Transform
     * @description Use this endpoint to delete a reusable record transform.
     */
    delete: operations["delete_reusable_record_transform"];
  };
  "/transforms/{transform_id}/copy": {
    /**
     * Copy a Reusable Record Transform
     * @description Use this endpoint to create a copy of an existing reusable record transform.
     */
    post: operations["copy_transform"];
  };
  "/transforms/public": {
    /**
     * Get all Public Reusable Record Transforms
     * @description The Nexla team regularly adds common reusable record transforms that are made available to all Nexla accounts.
     *
     * Use this endpoint to fetch all such "publicly" available reusable record transforms.
     */
    get: operations["get_public_reusable_record_transforms"];
  };
  "/attribute_transforms": {
    /**
     * Get all Attribute Transforms
     * @description Reusable attribute transforms are reusable code blocks that can be used to define the value of an output attribute in a Nexset. These code blocks can be used to enhance the set of transforms available to end users when using the Nexset Designer.
     *
     * Use this endpoint to fetch all attribute transforms accessible to the authenticated user.
     */
    get: operations["get_attribute_transforms"];
    /**
     * Create an Attribute Transform
     * @description Create a new attribute transform.
     */
    post: operations["create_attribute_transform"];
  };
  "/attribute_transforms/{attribute_transform_id}": {
    /**
     * Get Attribute Transform by ID
     * @description Returns an attribute transform object if a valid ID is provided.
     */
    get: operations["get_attribute_transform"];
    /**
     * Update Attribute Transform
     * @description Updates an attribute transform in the authenticated user's account.
     */
    put: operations["update_attribute_transform"];
    /**
     * Delete an Attribute Transform
     * @description Deletes an attribute transform from your Nexla account.
     */
    delete: operations["delete_attribute_transform"];
  };
  "/attribute_transforms/public": {
    /**
     * Get all Public Attribute Transforms
     * @description The Nexla team regularly adds common reusable attribute transforms that are made available to all Nexla accounts.
     *
     * Use this endpoint to fetch all such "publicly" available reusable attribute transforms.
     */
    get: operations["get_public_attribute_transforms"];
  };
  "/code_containers": {
    /**
     * Get all Code Containers
     * @description Use this endpoint to fetch all code containers accessible to the authenticated user.
     */
    get: operations["get_code_containers"];
    /**
     * Create a Code Container
     * @description Use this endpoint to create a new code container.
     */
    post: operations["create_code_container"];
  };
  "/code_containers/{code_container_id}": {
    /**
     * Get Code Container by ID
     * @description Returns a code container object if a valid ID is provided.
     */
    get: operations["get_code_container"];
    /**
     * Update a Code Container
     * @description Updates a code container in the authenticated user's account.
     */
    put: operations["update_code_container"];
    /**
     * Delete a Code Container
     * @description Deletes a code container from the authenticated user's account.
     */
    delete: operations["delete_code_container"];
  };
  "/code_containers/{code_container_id}/copy": {
    /**
     * Copy a Code Container
     * @description Use this endpoint to create a copy of an existing code container.
     */
    post: operations["copy_code_container"];
  };
  "/code_containers/public": {
    /**
     * Get all Public Code Containers
     * @description The Nexla team regularly adds common code containers that are made available to all Nexla accounts.
     *
     * Use this endpoint to fetch all such "publicly" available code containers.
     */
    get: operations["get_public_code_containers"];
  };
  "/projects": {
    /**
     * Get all Projects
     * @description Retrieves a list of all projects accessible to the authenticated user.
     */
    get: operations["get_projects"];
    /**
     * Create a project
     * @description Creates a project with the specified configuration. Note that flows can also be attached to the project later by calling endpoints to update the project.
     */
    post: operations["create_project"];
  };
  "/projects/{project_id}": {
    /**
     * Get Project by ID
     * @description Returns a project if a valid ID is provided.
     */
    get: operations["get_project"];
    /**
     * Modify a Project
     * @description Modifies a project's information and settings if a valid ID and body are provided.
     */
    put: operations["update_project"];
    /**
     * Delete Project by ID
     * @description Deletes a project if a valid ID is provided. Note that flows belonging to the project will only be removed from the project and will not be deleted.
     */
    delete: operations["delete_project"];
  };
  "/projects/{project_id}/flows": {
    /**
     * Get Project Flows
     * @description Returns a list of flows belonging to a project.
     */
    get: operations["get_project_flows"];
    /**
     * Add Flows to Project
     * @description Adds a list of flows to a project. The existing flow list is retained and merged with the new flow list.
     */
    put: operations["add_project_flows"];
    /**
     * Replace Project Flows List
     * @description Replaces the list of flows belonging to a project. Existing flows are removed from the project.
     */
    post: operations["replace_project_flows"];
    /**
     * Remove Flows From A Project
     * @description Removes data flows from a project. If no request body is provided, all flows belonging to the project will be removed. The flows themselves will not be deleted, but they will no longer belong to the project.
     */
    delete: operations["remove_project_flows"];
  };
  "/projects/{project_id}/data_flows": {
    /**
     * Get Project Flows (Deprecated)
     * @description Returns a list of flows belonging to a project.
     *
     * > **Note**: This version of the endpoint has been deprecated. The returned flow response does not reference the new unique flow ids, instead references composite data flow ids of the type `{resource_type}/{resource_id}`. See get_project_flows for a new version of this endpoint that references unique `flow_id`.
     */
    get: operations["get_project_flows_(deprecated)"];
    /**
     * Add Flows to Project (Deprecated)
     * @description Adds a list of flows to a project. The existing flow list is retained and merged with the new flow list.
     *
     * > **Note**: This version of the endpoint has been deprecated. The request body and response does not reference flows with new unique flow_ids, instead references composite data flow ids of the type `{resource_type}/{resource_id}`. See add_project_flows for a new version of this endpoint that references unique `flow_id`.
     */
    put: operations["add_project_flows_(deprecated)"];
    /**
     * Replace Project Flows List (Deprecated)
     * @description Replaces the list of flows belonging to a project. Existing flows are removed from the project.
     *
     * > **Note**: This version of the endpoint has been deprecated. The request body and response does not reference flows with new unique flow_ids, instead references composite data flow ids of the type `{resource_type}/{resource_id}`. See replace_project_flows for a new version of this endpoint that references unique `flow_id`.
     */
    post: operations["replace_project_flows_(deprecated)"];
    /**
     * Remove Flows From A Project (Deprecated)
     * @description Removes data flows from a project. If no request body is provided, all flows belonging to the project will be removed. The flows themselves will not be deleted, but they will no longer belong to the project.
     *
     * > **Note**: This version of the endpoint has been deprecated. The request body and response does not reference flows with new unique flow_ids, instead references composite data flow ids of the type `{resource_type}/{resource_id}`. See remove_project_flows for a new version of this endpoint that references unique `flow_id`.
     */
    delete: operations["remove_project_flows_(deprecated)"];
  };
  "/orgs": {
    /**
     * Get all Organizations
     * @description Returns all organizations accessible to the authenticated user.
     */
    get: operations["get_orgs"];
  };
  "/orgs/{org_id}": {
    /**
     * Get Organization by ID
     * @description Returns an organization if a valid ID is provided.
     */
    get: operations["get_org"];
    /**
     * Update an Organization
     * @description Updates properties of an organization.
     */
    put: operations["update_org"];
  };
  "/orgs/{org_id}/members": {
    /**
     * Get All Members in Organization
     * @description Retrieves a list of all users in an organization.
     */
    get: operations["get_org_members"];
    /**
     * Update Organization Members
     * @description Add or update members in an organization. This endpoint can also be used to modify an existing member's role in the organization.
     *
     * When adding a new member using their email id, if a user account for that email id does not exist on the platform then a new user account will be created. If the user already exists on the platform as a member of a different organization then their membership will get updated to include this organization also.
     */
    put: operations["update_org_members"];
    /**
     * Remove Members from an Organization.
     * @description Removes one or more members from the organization. Note that this will not delete the user account from the platform, but will remove the user's ability to access this organization's resources.
     */
    delete: operations["delete_org_members"];
  };
  "/teams": {
    /**
     * Get all Teams
     * @description Returns all teams accessible to the authenticated user.
     */
    get: operations["get_teams"];
    /**
     * Create a team
     * @description Creates a team with the specified configuration and members.
     */
    post: operations["create_team"];
  };
  "/teams/{team_id}": {
    /**
     * Get Team by ID
     * @description Returns a team if a valid ID is provided.
     */
    get: operations["get_team"];
    /**
     * Modify a Team
     * @description Modifies a team's information and settings if a valid ID and body are provided.
     */
    put: operations["update_team"];
    /**
     * Delete Team by ID
     * @description Deletes a team if a valid ID is provided.
     */
    delete: operations["delete_team"];
  };
  "/teams/{team_id}/members": {
    /**
     * Get Team Members
     * @description Returns a list of the members belonging to a team.
     */
    get: operations["get_team_members"];
    /**
     * Add Members to A Team
     * @description Adds a list of members to a team. The existing list of members will be retained and merged with the new list of members.
     */
    put: operations["add_team_members"];
    /**
     * Replace Team Members List
     * @description Replaces the list of members belonging to a team. Existing members will be removed from the team.
     */
    post: operations["replace_team_members"];
    /**
     * Remove Team Members
     * @description Removes members from a team. If no request body is provided, all members belonging to the team will be removed.
     */
    delete: operations["delete_team_members"];
  };
  "/users": {
    /**
     * Get All Users
     * @description Returns all users that can be viewed by authenticated user.
     */
    get: operations["get_users"];
    /**
     * Create a User
     * @description Create a new user in this environment.
     *
     * > This requires admin access to the provided organization.
     */
    post: operations["create_user"];
  };
  "/users?expand=1": {
    /**
     * Get All Users with Expanded References
     * @description Returns all users that can be viewed by the authenticated user.
     */
    get: operations["get_users_expand"];
  };
  "/users/{user_id}": {
    /**
     * Get User by ID
     * @description Returns a user if a valid ID is provided.
     */
    get: operations["get_user"];
    /**
     * Modify a User
     * @description Modifies a user's information and settings if a valid ID and body are provided
     */
    put: operations["update_user"];
  };
  "/users/{user_id}?expand=1": {
    /**
     * Get User by ID with Expanded References
     * @description Returns a user if a valid ID is provided.
     */
    get: operations["get_user_expand"];
  };
  "/users/current": {
    /**
     * Get info on current user
     * @description Returns the user information of the currently logged-in user, including org memberships and current org info.
     */
    get: operations["get_current_user"];
  };
  "/user_settings": {
    /**
     * Get the current user's settings
     * @description Returns all the settings for the current user.
     */
    get: operations["get_user_settings"];
  };
  "/notifications": {
    /**
     * Get All Notifications
     * @description Returns all notifications in the authenticated user's account. Note that this only includes notifications generated to be displayed in the Nexla UI.
     */
    get: operations["get_notifications"];
  };
  "/notifications/{notification_id}": {
    /**
     * Get a Notification
     * @description Returns a notification if a valid ID is provided.
     */
    get: operations["get_notification"];
    /**
     * Delete a Notification
     * @description Deletes a notification if a valid ID is provided.
     */
    delete: operations["delete_notifications"];
  };
  "/notifications/all": {
    /**
     * Delete All Notifications
     * @description Deletes all notifications belonging to the authenticated user. Note that this is only the list of notifications generated to be displayed in the Nexla UI.
     */
    delete: operations["delete_all_notifications"];
  };
  "/notifications/count": {
    /**
     * Get Notifications Count
     * @description Returns the total number of notifications in the authenticated user's account. Note that this only includes notifications generated to be displayed in the Nexla UI.
     */
    get: operations["get_notification_count"];
  };
  "/notifications/mark_read": {
    /**
     * Mark Notification Read
     * @description Use this endpoint to mark one, multiple, or all notifications as read. To mark a list of notifications, send an array of notification IDs as the payload. To mark all notifications, send the notification_id query parameter with the value `all`.
     */
    put: operations["notifications_mark_read"];
  };
  "/notifications/mark_unread": {
    /**
     * Mark Notification Unread
     * @description Use this endpoint to mark one, multiple, or all notifications as read. To mark a list of notifications, send an array of notification IDs as the payload. To mark all notifications, send the notification_id query parameter with the value `all`.
     */
    put: operations["notifications_mark_unread"];
  };
  "/notification_types": {
    /**
     * Get All Notification Types
     * @description Fetches a list of all notifications supported by Nexla in this environment.
     *
     * When users choose whether or not some notifications are enabled, their choices are saved in `notification_settings` and linked to the ID of the relevant notification type.
     */
    get: operations["get_notification_types"];
  };
  "/notification_types/list": {
    /**
     * Get One Notification Type
     * @description Fetches details about a specific notification type supported by Nexla in this environment.
     */
    get: operations["list_notification_type"];
  };
  "/notification_channel_settings": {
    /**
     * List Notification Channel Settings
     * @description Notification channel settings contain configuration settings relevant to where notifications should be delivered. For example, the settings for the `EMAIL` channel contain the email addresses to which notifications can be sent.
     *
     * You can maintain multiple configuration settings for the same channel to route notifications for specific resources and types to different locations.
     *
     * This endpoint lists all notification channel settings in the authenticated user's account.
     */
    get: operations["list_notification_channel_settings"];
    /**
     * Create a Notification Channel Setting
     * @description Create a new configuration for a notification channel.
     *
     * You can maintain multiple configuration settings for the same channel to route notifications for specific resources and types to different locations.
     */
    post: operations["create_notification_channel_setting"];
  };
  "/notification_channel_settings/{notification_channel_setting_id}": {
    /**
     * Get a Notification Channel Setting
     * @description Returns a notification channel setting if a valid ID is provided.
     */
    get: operations["get_notification_channel_setting"];
    /**
     * Update a Notification Channel Setting
     * @description Update the configuration of a notification channel setting.
     */
    put: operations["update_notification_channel_setting"];
    /**
     * Delete a Notification Channel Setting
     * @description Deletes a notification channel setting if a valid ID is provided.
     */
    delete: operations["delete_notification_channel_setting"];
  };
  "/notification_settings": {
    /**
     * List Notification Settings
     * @description This endpoint lists all notification settings in the authenticated user's account.
     *
     *
     * Notification settings contain the following user settings:
     * 1. Whether the user wants to be notified about a specific event (`status` of a `notification_type` on a `notification_resource_type`)
     * 2. If yes, on what `channel` the user wants to be notified
     * 3. The configuration of the channel (`notification_channel_setting_id`)
     * 4. Configuration parameters affect when the notification should be fired. This is usually left empty to use platform defaults, but it is relevant when users want to override the default settings of some notifications, such as `Source Data Delayed`
     */
    get: operations["list_notification_settings"];
    /**
     * Create a Notification Setting
     * @description Create a setting to designate whether, when, and how a specific notification should be fired.
     */
    post: operations["create_notification_setting"];
  };
  "/notification_settings/{notification_setting_id}": {
    /**
     * Get a Notification Setting
     * @description Returns a notification if a valid ID is provided.
     */
    get: operations["get_notification_setting"];
    /**
     * Modify a Notification Setting
     * @description Modifies a notification if a valid ID and body are provided.
     */
    put: operations["update_notification_setting"];
    /**
     * Delete a Notification Setting
     * @description Delete a notification setting if a valid ID is provided.
     */
    delete: operations["delete_notification_setting"];
  };
  "/notification_settings/notification_types/{notification_type_id}": {
    /**
     * Get Notification Settings for an Event
     * @description Use this endpoint to fetch all notification settings of a specific type.
     *
     * This can be used as a filter that is easy to use to understand, which returns all notifications that a user can expect to receive for a specific event.
     */
    get: operations["list_notification_settings_by_type"];
  };
  "/notification_settings/{resource_type}/{resource_id}": {
    /**
     * Get Notification Settings For a Resource
     * @description Use this endpoint to fetch all notification settings for a given resource.
     *
     * This can be used as a filter that is easy to understand, which returns all notifications that a user can expect to receive for a specific resource.
     */
    get: operations["list_resource_notification_settings"];
  };
  "/orgs/{org_id}/flows/account_metrics": {
    /**
     * Get Total Account Metrics for An Organization
     * @description Retrieves total account utilization metrics for an organization. The result consists of aggregated information about records processed within the specified date range by all resources owned by users in the organization.
     */
    get: operations["org_account_metrics_total"];
  };
  "/users/{user_id}/flows/account_metrics": {
    /**
     * Get Total Account Metrics for a User
     * @description Retrieves total account utilization metrics for a user in an organization. The result consists of aggregated information about records processed within the specified date range by all resources owned by the user.
     */
    get: operations["user_account_metrics_total"];
  };
  "/users/{user_id}/flows/dashboard": {
    /**
     * Get 24 Hour Flow Stats for a User
     * @description Retrieves the metrics and processing status of each flow that processed data in the last 24 hours.
     *
     * Each item reflects the total number of records processed by each stage of all flows accessible by the user that processed any data in the specified time window.
     */
    get: operations["user_24_hour_flow_stats"];
  };
  "/users/{user_id}/metrics": {
    /**
     * Get Daily Data Processing Metrics for a User
     * @description Retrieves daily data processing metrics of all sources or all destinations owned by a user.
     */
    get: operations["user_metrics_daily"];
  };
  "/{resource_type}/{resource_id}/metrics": {
    /**
     * Get Daily Metrics for a Resource of a Flow
     * @description Retrieves daily data processing metrics of a `data_source`, `data_set`, or `data_sink`.
     */
    get: operations["get_resource_metrics_daily"];
  };
  "/{resource_type}/{resource_id}/metrics/run_summary": {
    /**
     * Get Metrics By Run ID for a Resource of a Flow
     * @description Retrieves data processing metrics of a `data_source`, `data_set`, or `data_sink`. The reported metrics are grouped by run id to indicate the number of records processed during each ingestion cycle of this flow.
     */
    get: operations["get_resource_metrics_by_run"];
  };
  "/data_flows/{resource_type}/{resource_id}/metrics": {
    /**
     * Get Metrics for a Flow
     * @description Retrieves data processing metrics of a flow. Metrics are aggregated for each node of the flow for the specified time range. They can be be further grouped by run id to indicate the number of records processed during each ingestion cycle of this flow.
     *
     * > Note: This is a variant of flow endpoints where the flow node can referenced not by its own ID, but by the ID of the unique resource that is linked to that flow node.
     */
    get: operations["get_flow_metrics"];
  };
  "/data_flows/{resource_type}/{resource_id}/logs": {
    /**
     * Get Flow Execution Logs for Run ID of a Flow
     * @description Retrieves flow execution logs for a specific run id of a flow.
     *
     * > Note: This is a variant of flow endpoints where the flow node can referenced not by its own ID, but by the ID of the unique resource that is linked to that flow node.
     */
    get: operations["get_flow_logs_for_run_id"];
  };
  "/data_sources/{source_id}/audit_log": {
    /**
     * Get Audit Log for a Data Source
     * @description Retrieves the history of changes made to the properties of a data source.
     */
    get: operations["get_data_source_audit_log"];
  };
  "/data_sinks/{sink_id}/audit_log": {
    /**
     * Get Audit Log for a Data Sink
     * @description Retrieves the history of changes made to the properties of a data sink.
     */
    get: operations["get_data_sink_audit_log"];
  };
  "/data_sets/{set_id}/audit_log": {
    /**
     * Get Audit Log for a Nexset
     * @description Retrieves the history of changes made to the properties of a Nexset.
     */
    get: operations["get_nexset_audit_log"];
  };
  "/data_credentials/{credential_id}/audit_log": {
    /**
     * Get Audit Log for a Data Credential
     * @description Retrieves the history of changes made to the properties of a data credential.
     */
    get: operations["get_data_credential_audit_log"];
  };
  "/data_maps/{data_map_id}/audit_log": {
    /**
     * Get Audit Log for a Data Map
     * @description Retrieves the history of changes made to the properties of a data map.
     */
    get: operations["get_data_map_audit_log"];
  };
  "/data_schemas/{schema_id}/audit_log": {
    /**
     * Get Audit Log for a Data Schema
     * @description Retrieves the history of changes made to the properties of a data schema.
     */
    get: operations["get_data_schema_audit_log"];
  };
  "/code_containers/{code_container_id}/audit_log": {
    /**
     * Get Audit Log for a Code Container
     * @description Retrieves the history of changes made to the properties of a code container. This endpoint can also be used to fetch the history of changes made to any transform object.
     */
    get: operations["get_code_container_audit_log"];
  };
  "/projects/{project_id}/audit_log": {
    /**
     * Get Audit Log for a Project
     * @description Retrieves the history of changes made to the properties of a project.
     */
    get: operations["get_project_audit_log"];
  };
  "/doc_containers/{doc_container_id}/audit_log": {
    /**
     * Get Audit Log for a Document
     * @description Retrieves the history of changes made to the properties of a document.
     */
    get: operations["get_doc_container_audit_log"];
  };
  "/users/{user_id}/audit_log": {
    /**
     * Get Audit Log for a User
     * @description Retrieves the history of changes made to the properties of a user.
     */
    get: operations["get_user_audit_log"];
  };
  "/orgs/{org_id}/audit_log": {
    /**
     * Get Audit Log for an Organization
     * @description Retrieves the history of changes made to the properties of an organization.
     */
    get: operations["get_org_audit_log"];
  };
  "/teams/{team_id}/audit_log": {
    /**
     * Get Audit Log for a Team
     * @description Retrieves the history of changes made to the properties of a team.
     */
    get: operations["get_team_audit_log"];
  };
  "/users/{user_id}/quarantine_settings": {
    /**
     * Get Quarantine Data Export Settings for A User
     * @description Retrieve Quarantine Data Export Settings for all resources owned by a user.
     *
     * Nexla detects errors during different stages of data flow such as ingestion, transformation, and output. Error records are quarantined and accessible to the user via APIs as well as files. With Quarantine Data Export Settings, you can configure Nexla to write files containing information about erroneous records across all resources owned by a user.
     *
     * > This endpoint returns a 404 status code if no Quarantine Data Export Settings have been configured for the user.
     */
    get: operations["get_user_quarantine_data_export_settings"];
    /**
     * Update Quarantine Data Export Settings for A User
     * @description Updates Quarantine Data Export Settings for all resources owned by a user so that all erroneous records can be automatically exported by the platform to a file system regularly.
     */
    put: operations["update_user_quarantine_data_export_settings"];
    /**
     * Set Quarantine Data Export Settings for A User
     * @description Sets Quarantine Data Export Settings for all resources owned by a user so that all erroneous records can be automatically exported by the platform to a file system regularly.
     */
    post: operations["create_quarantine_data_export_settings"];
    /**
     * Delete Quarantine Data Export Settings for A User
     * @description Deletes Updates Quarantine Data Export Settings for all resources owned by a user. Deleting this setting will ensure the platform stops exporting all erroneous records for resources owned by the user to a file storage.
     */
    delete: operations["delete_user_quarantine_data_export_settings"];
  };
  "/approval_requests/pending": {
    /**
     * Get all pending approval requests.
     * @description Use this endpoint to fetch all pending approval requests that are not assigned to any users.
     */
    get: operations["get_pending_approval_requests"];
  };
  "/approval_requests/requested": {
    /**
     * Get all requested approval requests by the user.
     * @description Use this endpoint to fetch all approval requests that are requested by the user.
     */
    get: operations["get_requested_approval_requests"];
  };
  "/approval_requests/{request_id}/approve": {
    /**
     * Approve pending approval requests
     * @description Use this endpoint to approve pending approval requests that are assigned to user or it's unassigned.
     */
    put: operations["approve_approval_request"];
  };
  "/approval_requests/{request_id}/reject": {
    /**
     * Reject pending approval requests
     * @description Use this endpoint to reject pending approval requests that are assigned to user or it's unassigned.
     */
    delete: operations["reject_approval_request"];
  };
  "/data_sources/{data_source_id}/accessors": {
    /**
     * Get Access Rules on Data Source
     * @description Returns a list of the access-control rules set for this data source.
     */
    get: operations["get_data_source_accessors"];
    /**
     * Add Access Rules on Data Source
     * @description Adds a list of accessors to a data source. The existing accessors list is retained and merged with the new accessors list.
     */
    put: operations["add_data_source_accessors"];
    /**
     * Replace Access Rules on Data Source
     * @description Replaces the list of accessors belonging to a data source. Existing accessors will be removed from the data source.
     */
    post: operations["replace_data_source_accessors"];
    /**
     * Delete Access Rules on Data Source
     * @description Removes access-control rules from a data source. If no request body is provided, all rules associated with the data source will be removed.
     */
    delete: operations["delete_data_source_accessors"];
  };
  "/data_sets/{data_set_id}/accessors": {
    /**
     * Get Access Rules on Nexset
     * @description Returns a list of the access-control rules set for this Nexset.
     */
    get: operations["get_nexset_accessors"];
    /**
     * Add Access Rules on Nexset
     * @description Adds new access-control rules to this Nexset.
     */
    put: operations["add_nexset_accessors"];
    /**
     * Replace Access Rules on Nexset
     * @description Replaces the list of access-control rules set for this Nexset. Existing rules will be removed from the Nexset, and only these new rules will be applied.
     */
    post: operations["replace_nexset_accessors"];
    /**
     * Delete Access Rules on Nexset
     * @description Removes access-control rules from a Nexset. If no request body is provided, all rules associated with the Nexset will be removed.
     */
    delete: operations["delete_nexset_accessors"];
  };
  "/data_sinks/{data_sink_id}/accessors": {
    /**
     * Get Access Rules on Data Sink
     * @description Returns a list of the access-control rules set for this data sink.
     */
    get: operations["get_data_sink_accessors"];
    /**
     * Add Access Rules on Data Sink
     * @description Adds new access-control rules to this data sink.
     */
    put: operations["add_data_sink_accessors"];
    /**
     * Replace Access Rules on Data Sink
     * @description Replaces the list of access-control rules set for this data sink. Existing rules will be removed from the data sink, and only these new rules will be applied.
     */
    post: operations["replace_data_sink_accessors"];
    /**
     * Delete Access Rules on Data Sink
     * @description Removes access-control rules from a data sink. If no request body is provided, all rules associated with the data sink will be removed.
     */
    delete: operations["delete_data_sink_accessors"];
  };
  "/data_maps/{data_map_id}/accessors": {
    /**
     * Get Access Rules on Data Map
     * @description Returns a list of the access-control rules set for this data map.
     */
    get: operations["get_data_map_accessors"];
    /**
     * Add Access Rules on Data Map
     * @description Adds new access-control rules to this data map.
     */
    put: operations["add_data_map_accessors"];
    /**
     * Replace Access Rules on Data Map
     * @description Replaces the list of access-control rules set for this data map. Existing rules will be removed from the data map, and only these new rules will be applied.
     */
    post: operations["replace_data_map_accessors"];
    /**
     * Delete Access Rules on Data Map
     * @description Removes access-control rules from a data map. If no request body is provided, all rules associated with the data map will be removed.
     */
    delete: operations["delete_data_map_accessors"];
  };
  "/data_credentials/{data_credential_id}/accessors": {
    /**
     * Get Access Rules on Data Credential
     * @description Returns a list of the access-control rules set for this data credential.
     */
    get: operations["get_data_credential_accessors"];
    /**
     * Add Access Rules on Data Credential
     * @description Adds new access-control rules to this data credential.
     */
    put: operations["add_data_credential_accessors"];
    /**
     * Replace Access Rules on Data Credential
     * @description Replaces the list of access-control rules set for this data credential. Existing rules will be removed from the data credential, and only these new rules will be applied.
     */
    post: operations["replace_data_credential_accessors"];
    /**
     * Delete Access Rules on Data Credential
     * @description Removes access-control rules from a data credential. If no request body is provided, all rules associated with the data credential will be removed.
     */
    delete: operations["delete_data_credential_accessors"];
  };
  "/projects/{project_id}/accessors": {
    /**
     * Get Project Accessors
     * @description Returns a list of the access-control rules set for this project.
     */
    get: operations["get_project_accessors"];
    /**
     * Add Project Accessors
     * @description Adds new access-control rules to this project.
     */
    put: operations["add_project_accessors"];
    /**
     * Replace Access Rules on Project
     * @description Replaces the list of access-control rules set for this project. Existing rules will be removed from the project, and only these new rules will be applied.
     */
    post: operations["replace_project_accessors"];
    /**
     * Delete Project Accessors
     * @description Removes access-control rules from a project. If no request body is provided, all rules associated with the project will be removed.
     */
    delete: operations["delete_project_accessors"];
  };
  "/flows/{flow_id}/accessors": {
    /**
     * Get Access Rules on Flow
     * @description Returns a list of the access-control rules set for this flow.
     */
    get: operations["get_flow_accessors"];
    /**
     * Add Access Rules on Flow
     * @description Adds new access-control rules to this data flow.
     */
    put: operations["add_flow_accessors"];
    /**
     * Replace Access Rules on Flow
     * @description Replaces the list of access-control rules set for this flow. Existing rules will be removed from the flow, and only these new rules will be applied.
     */
    post: operations["replace_flow_accessors"];
    /**
     * Delete Access Rules on Flow
     * @description Removes access-control rules from a data flow. If no request body is provided, all rules associated with the data flow will be removed.
     */
    delete: operations["delete_flow_accessors"];
  };
  "/data_flows/{data_flow_id}/accessors": {
    /**
     * Get Access Rules on Flow (Deprecated)
     * @description Returns a list of the access-control rules set for this data flow.
     *
     * > **Note**: This version of the endpoint has been deprecated. It uses a composite data flow id of the type `{resource_type}/{resource_id}`. See get_flow_accessors for a new version of this endpoint that uses unique `flow_id`.
     */
    get: operations["get_flow_accessors_(deprecated)"];
    /**
     * Add Access Rules on Flow (Deprecated)
     * @description Add new access-control rules to this data flow. This version uses a composite data flow id of the type `{resource_type}/{resource_id}`.
     *
     * > **Note**: This version of the endpoint has been deprecated. It uses a composite data flow id of the type `{resource_type}/{resource_id}`. See add_flow_accessors for a new version of this endpoint that uses unique `flow_id`.
     */
    put: operations["add_flow_accessors_(deprecated)"];
    /**
     * Replace Access Rules on Flow (Deprecated)
     * @description Replace the list of access-control rules set for this data flow. Existing rules will be removed from the data flow, and only these new rules will be applied. This version uses a composite data flow id of the type `{resource_type}/{resource_id}`.
     *
     * > **Note**: This version of the endpoint has been deprecated. It uses a composite data flow id of the type `{resource_type}/{resource_id}`. See replace_flow_accessors for a new version of this endpoint that uses unique `flow_id`.
     */
    post: operations["replace_flow_accessors_(deprecated)"];
    /**
     * Delete Access Rules on Flow (Deprecated)
     * @description Remove access-control rules from a data flow. If no request body is provided, all rules associated with the data flow will be removed. This version uses a composite data flow id of the type `{resource_type}/{resource_id}`.
     *
     * > **Note**: This version of the endpoint has been deprecated. It uses a composite data flow id of the type `{resource_type}/{resource_id}`. See delete_flow_accessors for a new version of this endpoint that uses unique `flow_id`.
     */
    delete: operations["delete_flow_accessors_(deprecated)"];
  };
  "/data_schemas/{data_schema_id}/accessors": {
    /**
     * Get Access Rules on Data Schema
     * @description Returns a list of the access-control rules set for this data schema.
     */
    get: operations["get_data_schema_accessors"];
    /**
     * Add Access Rules on Data Schema
     * @description Adds new access-control rules to this data schema.
     */
    put: operations["add_data_schema_accessors"];
    /**
     * Replace Access Rules on Data Schema
     * @description Replaces the list of access-control rules set for this data schema. Existing rules will be removed from the data schema, and only these new rules will be applied.
     */
    post: operations["replace_data_schema_accessors"];
    /**
     * Delete Access Rules on Data Schema
     * @description Removes access-control rules from a data schema. If no request body is provided, all rules associated with the data schema will be removed.
     */
    delete: operations["delete_data_schema_accessors"];
  };
  "/doc_containers/{doc_container_id}/accessors": {
    /**
     * Get Access Rules on Document
     * @description Returns a list of the access-control rules set for this document.
     */
    get: operations["get_doc_container_accessors"];
    /**
     * Add Access Rules on Document
     * @description Adds new access-control rules to this document.
     */
    put: operations["add_doc_container_accessors"];
    /**
     * Replace Access Rules on Document
     * @description Replaces the list of access-control rules set for this document. Existing rules will be removed from the document, and only these new rules will be applied.
     */
    post: operations["replace_doc_container_accessors"];
    /**
     * Delete Access Rules on Document
     * @description Removes access-control rules from a document. If no request body is provided, all rules associated with the document will be removed.
     */
    delete: operations["delete_doc_container_accessors"];
  };
  "/code_containers/{code_container_id}/accessors": {
    /**
     * Get Access Rules on Code Container
     * @description Returns a list of the access-control rules set for this code container.
     */
    get: operations["get_code_container_accessors"];
    /**
     * Add Access Rules on Code Container
     * @description Adds new access-control rules to this code container.
     */
    put: operations["add_code_container_accessors"];
    /**
     * Replace Access Rules on Code Container
     * @description Replaces the list of access-control rules set for this code container. Existing rules will be removed from the code container, and only these new rules will be applied.
     */
    post: operations["replace_code_container_accessors"];
    /**
     * Delete Access Rules on Code Container
     * @description Removes access-control rules from a code container. If no request body is provided, all rules associated with the code container will be removed.
     */
    delete: operations["delete_code_container_accessors"];
  };
  "/teams/{team_id}/accessors": {
    /**
     * Get Team Accessors
     * @description Returns a list of the access-control rules set for this team.
     */
    get: operations["get_team_accessors"];
    /**
     * Add Team Accessors
     * @description Adds new access-control rules to this team.
     */
    put: operations["add_team_accessors"];
    /**
     * Replace Team Accessors List
     * @description Replaces the list of access-control rules set for this team. Existing rules will be removed from the team, and only these new rules will be applied.
     */
    post: operations["replace_team_accessors"];
    /**
     * Delete Team Accessors
     * @description Removes access-control rules from a team. If no request body is provided, all rules associated with the team will be removed.
     */
    delete: operations["delete_team_accessors"];
  };
  "/marketplace/domains": {
    /**
     * Get marketplace domains.
     * @description Use this endpoint to fetch marketplace domains. You need a read permission for the org.
     */
    get: operations["get_domains"];
    /**
     * Create marketplace domains.
     * @description Use this endpoint to create marketplace domains. You need a manage permission for the org.
     */
    post: operations["create_domains"];
  };
  "/marketplace/domains/for_org": {
    /**
     * Get marketplace domains for organization.
     * @description Use this endpoint to fetch marketplace domains for a specific organization. You need a read permission for the org.
     */
    get: operations["get_domains_for_org"];
  };
  "/marketplace/domains/{domain_id}": {
    /**
     * Get a single marketplace domain.
     * @description Use this endpoint to fetch a marketplace domain. You need a read permission for the domain.
     */
    get: operations["get_domain"];
    /**
     * Update a single marketplace domain.
     * @description Use this endpoint to update a marketplace domain. You need a manage permission for the domain.
     */
    put: operations["update_domain"];
    /**
     * Create a single marketplace domain.
     * @description Use this endpoint to create a marketplace domain. You need a manage permission for the org.
     */
    post: operations["create_domain"];
    /**
     * Delete a single marketplace domain.
     * @description Use this endpoint to delete a marketplace domain. You need a manage permission for the domain to delete it.
     */
    delete: operations["delete_domain"];
  };
  "/marketplace/domains/{domain_id}/items": {
    /**
     * Get marketplace items for a domain.
     * @description Use this endpoint to fetch marketplace items for a domain. You need a read permission for the domain.
     */
    get: operations["get_domain_items"];
    /**
     * Create a marketplace item for a domain.
     * @description Use this endpoint to create a marketplace item for a domain. You need a manage permission for the domain.
     */
    post: operations["create_domain_item"];
  };
  "/marketplace/domains/{domain_id}/custodians": {
    /**
     * Get custodians for a marketplace domain.
     * @description Use this endpoint to fetch custodians for a marketplace domain. You need a read permission for the domain.
     */
    get: operations["get_domain_custodians"];
    /**
     * Update custodians for a marketplace domain.
     * @description Use this endpoint to update custodians for a marketplace domain. You need a manage permission for the domain.
     */
    put: operations["update_domain_custodians"];
    /**
     * Add custodians to a marketplace domain.
     * @description Use this endpoint to add custodians to a marketplace domain. You need a manage permission for the domain.
     */
    post: operations["add_domain_custodians"];
    /**
     * Remove custodians from a marketplace domain.
     * @description Use this endpoint to remove custodians from a marketplace domain. You need a manage permission for the domain.
     */
    delete: operations["remove_domain_custodians"];
  };
  "/orgs/{org_id}/custodians": {
    /**
     * Get organization custodians.
     * @description Use this endpoint to fetch custodians of organization. Org read permission is required to access this endpoint.
     */
    get: operations["get_org_custodians"];
    /**
     * Update organization custodians.
     * @description Users listed within the request body will be updated as custodians for the organization. Users can be identified by their email or id.
     */
    put: operations["update_org_custodians"];
    /**
     * Add organization custodians.
     * @description Users listed within the request body will be added as custodians to the organization. Users can be identified by their email or id.
     */
    post: operations["add_org_custodians"];
    /**
     * Remove organization custodians.
     * @description Users listed within the request body will be deleted as custodians from the organization. Users can be identified by their email or id.
     */
    delete: operations["remove_org_custodians"];
  };
  "/token": {
    /**
     * Login with Basic Authentication
     * @description Use this endpoint for authentication if your organization allows basic authentication. A successful authentication attempt will result in an `access_token` that can be used to make authenticated requests to other API endpoints. The `access_token` automatically expires after a fixed duration, but you can also call the `/logout` endpoint to invalidate the access token at the end of your session.
     *
     * Nexla supports various methods of authentication, including Basic (email/password), Google SSO, and custom SAML- or OIDC-based SSO. One or more of these methods might be allowed in any organization, depending on the configuration chosen by the administrators. Instead of using this endpoint to start a session programmatically, we recommend performing authentication through the Nexla UI and using the Nexla Session Token (available in Tools >> Nexla Session Token) to connect to the API programmatically.
     *
     * > Note: A user might belong to multiple organizations. This method initiates an authenticated session in their default organization.
     */
    post: operations["login_with_basic_auth"];
  };
  "/token/logout": {
    /**
     * Logout
     * @description Ends the current session and invalidates the `NexlaSessionToken` for future requests.
     */
    post: operations["logout"];
  };
  "/limits": {
    /**
     * Get current rate limit and usage
     * @description Returns the API rate limiting categories and the user's current usage
     */
    get: operations["limits"];
  };
  "/api_auth_configs": {
    /**
     * Get auth configs.
     * @description Get the authentication configurations for the API. This will return auth configs owned by current user.
     */
    get: operations["get_api_auth_configs"];
    /**
     * Create auth config.
     * @description Create a new authentication configuration for the API.
     */
    post: operations["create_api_auth_config"];
  };
  "/api_auth_configs/all": {
    /**
     * Get all auth configs.
     * @description Get the authentication configurations for the API. This will return all auth configs. Super-admin privilege is required.
     */
    get: operations["get_all_api_auth_configs"];
  };
  "/api_auth_configs/{auth_config_id}": {
    /**
     * Get auth configs.
     * @description Get the authentication configurations by it's ID.
     */
    get: operations["get_api_auth_configs"];
    /**
     * Update auth config.
     * @description Update an authentication configuration for the API.
     */
    put: operations["update_api_auth_config"];
    /**
     * Delete auth config.
     * @description Delete an authentication configuration for the API.
     */
    delete: operations["delete_api_auth_config"];
  };
  "/signup": {
    /**
     * Sign Up
     * @description This endpoint is used for users to register in the system. Once signup process is completed (email is verified, manual approval by admin may be required),
     * user can set a password and login to the system.
     * Email verification link is sent to the email provided by the user.
     *
     * Optionally, it allows for logged in user to be called. In this case, email verification will be skipped, and new org is created immediately.
     */
    post: operations["self_sign_up"];
  };
  "/signup/verify_email": {
    /**
     * Verify Email
     * @description This endpoint is used to verify the email address of the user.
     * The user will be able to set a password and login to the system after the email is verified (unless manual admin approval is required).
     */
    get: operations["verify_email"];
  };
  "/self_signup_requests": {
    /**
     * List Self Sign Up Requests
     * @description Returns a list of self sign up requests for an admin.
     */
    get: operations["get_self_signup_requests"];
  };
  "/self_signup_requests/{request_id}/approve": {
    /**
     * Approve Self Sign Up Request
     * @description This endpoint is used to approve a self sign up request. System admin access required.
     * The user will be able to set a password and login to the system after the request is approved.
     */
    put: operations["approve_self_sign_up_request"];
  };
  "/self_signup_blocked_domains": {
    /**
     * List self-sign-up blocked domains for admins.
     * @description Returns a list of domains that are blocked for self-sign-up. Requires admin access.
     */
    get: operations["get_self_signup_blocked_domains"];
    /**
     * Add self-sign-up blocked domain for admins.
     * @description Adds a domain to the list of domains that are blocked for self-sign-up. Requires admin access.
     */
    post: operations["add_self_signup_blocked_domain"];
  };
  "/self_signup_blocked_domains/{domain_id}": {
    /**
     * Update self-sign-up blocked domain for admins.
     * @description Updates a domain in the list of domains that are blocked for self-sign-up. Requires admin access.
     */
    put: operations["update_self_signup_blocked_domain"];
    /**
     * Delete self-sign-up blocked domain for admins.
     * @description Deletes a domain from the list of domains that are blocked for self-sign-up. Requires admin access.
     */
    delete: operations["delete_self_signup_blocked_domain"];
  };
  "/orgs/{org_id}/auth_settings": {
    /**
     * Get auth settings for org.
     * @description Get the authentication settings for the given org. This allows to enable or disable specific auth configs for the org.
     */
    get: operations["get_api_auth_settings"];
  };
  "/orgs/{org_id}/auth_settings/{auth_setting_id}": {
    /**
     * Update auth config (enable/disable).
     * @description Update an authentication configuration for the API.
     */
    put: operations["update_api_auth_config"];
  };
  "/async_tasks": {
    /**
     * Get async operations list for current user.
     * @description Get a list of async operations for current user. Returns type, arguments, status, results etc.
     */
    get: operations["get_async_tasks"];
    /**
     * Create an async operation.
     * @description Create an async operation. Returns the task id and other related data. Checks if the user has permission to create the task with all entities, and other preconditions.
     */
    post: operations["create_async_task"];
  };
  "/async_tasks/of_type/{task_type}": {
    /**
     * Get async operations list for current user of a specific type.
     * @description Get a list of async operations for current user of a specific type. Returns type, arguments, status, results etc.
     */
    get: operations["get_async_tasks_of_type"];
  };
  "/async_tasks/by_status/{status}": {
    /**
     * Get async operations list for current user by status
     * @description Get a list of async operations for current user of a specific type. Returns type, arguments, status, results etc.
     */
    get: operations["get_async_tasks_by_status"];
  };
  "/async_tasks/types": {
    /**
     * Get async operation types
     * @description Get a list of async operation types. Returns type, arguments, status, results etc.
     */
    get: operations["get_async_task_types"];
  };
  "/async_tasks/explain_arguments/{task_type}": {
    /**
     * Get async operation arguments for a specific type with descriptions
     * @description Get a list of async operation arguments for a specific type with descriptions.
     */
    get: operations["get_async_tasks_explain_arguments"];
  };
  "/async_tasks/{task_id}": {
    /**
     * Get async operation by ID
     * @description Get an async operation by ID. Returns type, arguments, status, results and other fields.
     */
    get: operations["get_async_task"];
    /**
     * Delete async operation by ID
     * @description Delete an async operation by ID. Returns the task id and other related data.
     */
    delete: operations["delete_async_task"];
  };
  "/async_tasks/{task_id}/rerun": {
    /**
     * Rerun async operation
     * @description Rerun an async operation. This is used to re-run an async operation. The task will be re-created and executed with the same arguments.
     */
    post: operations["rerun_async_task"];
  };
  "/async_tasks/{task_id}/result": {
    /**
     * Get async operation result
     * @description Get the result of an async operation.
     */
    get: operations["get_async_task_result"];
  };
  "/async_tasks/{task_id}/download_link": {
    /**
     * Get download link for async operation result
     * @description Get a download link for the result of an async operation.
     */
    get: operations["get_async_task_download_link"];
  };
  "/async_tasks/{task_id}/acknowledge": {
    /**
     * Acknowledge async operation
     * @description Acknowledge an async operation. This is used to confirm that the user has seen the results of the async operation. After that, if tasks has stored results, they will be deleted.
     */
    post: operations["acknowledge_async_task"];
  };
  "/runtimes": {
    /**
     * Get all Custom Runtimes
     * @description Retrieves a list of all custom runtimes defined for the organization.
     */
    get: operations["get_runtimes"];
    /**
     * Create a Custom Runtime
     * @description Creates a custom runtime with the specified configuration.
     */
    post: operations["create_runtime"];
  };
  "/runtimes/{runtime_id}": {
    /**
     * Get a custom runtime by ID
     * @description Retrieves a custom runtime
     */
    get: operations["get_runtime"];
    /**
     * Update a Custom Runtime
     * @description Updates a custom runtime.
     */
    put: operations["update_runtime"];
    /**
     * Delete a Custom Runtime
     * @description Creates a custom runtime with the specified configuration.
     */
    delete: operations["delete_runtime"];
  };
  "/runtimes/{runtime_id}/activate": {
    /**
     * Activate a Custom Runtime
     * @description Activates a custom runtime with the specified ID.
     */
    put: operations["activate_runtime"];
  };
  "/runtimes/{runtime_id}/pause": {
    /**
     * Pause a Custom Runtime
     * @description Pause a custom runtime with the specified ID.
     */
    put: operations["pause_runtime"];
  };
  "/gen_ai_integration_configs": {
    /**
     * Get all GenAI configs in org
     * @description Retrieves all GenAI configurations accessible to the authenticated user.
     */
    get: operations["get_gen_ai_configs"];
    /**
     * Create a GenAI config
     * @description Creates a GenAI configuration.
     */
    post: operations["create_gen_ai_config"];
  };
  "/gen_ai_integration_configs/{gen_ai_config_id}": {
    /**
     * Get GenAI Integration Config
     * @description Retrieves a GenAI integration configuration by ID.
     */
    get: operations["get_gen_ai_integration_config"];
    /**
     * Update GenAI Integration Config
     * @description Updates a GenAI integration configuration by ID.
     */
    put: operations["update_gen_ai_integration_config"];
    /**
     * Delete GenAI Integration Config
     * @description Deletes a GenAI integration configuration by ID.
     */
    delete: operations["delete_gen_ai_integration_config"];
  };
  "/gen_ai_org_settings": {
    /**
     * Get all bindings of GenAI configs of the org for specified usages.
     * @description Retrieves all activated GenAI configurations for the org.
     */
    get: operations["get_gen_ai_org_settings"];
    /**
     * Create a binding of GenAI config for the org for specific usage.
     * @description Activates a GenAI configuration for specific usage. All other bindings for the same usage will be deactivated.
     */
    post: operations["create_gen_ai_org_setting"];
  };
  "/gen_ai_org_settings/{gen_ai_org_setting_id}": {
    /**
     * Get Org GenAI binding
     * @description Retrieves a GenAI configuration binding by ID.
     */
    get: operations["get_gen_ai_org_setting"];
    /**
     * Delete GenAI Config binding for org.
     * @description Delete GenAI config binding for an org (disables a GenAI configuration usage).
     */
    delete: operations["delete_gen_ai_org_setting"];
  };
  "/gen_ai_org_settings/active_config": {
    /**
     * Shows active GenAI Configuration for specific usage
     * @description Shows active GenAI Configuration for specific usage
     */
    get: operations["gen_ai_org_settings_show_active"];
  };
}

export interface webhooks {
  "send_one_record": {
    /** Send one record to Webhook */
    post: operations["send_one_record"];
  };
  "send_many_records": {
    /**
     * Send many records to Webhook
     * @description Send an array of JSON objects. Nexla will treat each object as a unique record for the webhook.
     */
    post: operations["send_many_records"];
  };
}

export interface components {
  schemas: {
    owner: {
      id?: number;
      full_name?: string;
      /** Format: email */
      email?: string;
    };
    org: {
      id?: number;
      name?: string;
      email_domain?: string;
      email?: null;
      client_identifier?: null;
    };
    /**
     * @description This property reflects all the permissions the user/team/organization has to this resource.
     *
     * 1. `collaborator`: The user/team/organization can view the resource but not make any modifications to it.
     * 2. `operator`: The user/team/organization can view the resource and can activate/pause it, but not make any other modifications to it.
     * 3. `administrator`: The user/team/organization has complete administrative rights to this resource.
     * 4. `owner`: This user created the resource and so has complete administrative rights to it.
     */
    AccessRoles: ("owner" | "collaborator" | "operator" | "admin")[];
    data_credential: {
      name?: string;
      description?: string;
      credentials_type?: string;
    };
    database_data_credential: {
      credentials?: {
        /**
         * @description __Requires SSH Tunnel for access?__: If your database is not publicly accessible, Nexla enables connecting via an SSH tunnel. When using this method, Nexla will connect to a bastion host via SSH, and the database connection will occur from the SSH host.
         *
         * Default value: `false`
         */
        has_ssh_tunnel?: boolean;
        /**
         * @description __SSH Tunnel Host__: To connect via an SSH tunnel, you need to use a bastion host running an SSH tunnel server with access to your database. Enter the SSH tunnel hostname or IP address of the bastion host.
         *
         * __Required__ if `has_ssh_tunnel` is `true`
         */
        "tunnel.bastion.host"?: string;
        /**
         * @description __SSH Tunnel Port__: Enter the port of the tunnel bastion host to which Nexla can connect.
         *
         * __Required__ if `has_ssh_tunnel` is `true`
         *
         * Default Value: `22`
         */
        "tunnel.bastion.port"?: number;
        /**
         * @description __Username for tunnel__: As part of setting up the bastion host, you also need to create an SSH user for Nexla. Enter that username here. Usually, this is set to `nexla`.
         *
         * __Required__ if `has_ssh_tunnel` is `true`
         */
        "tunnel.bastion.user"?: string;
      };
    };
    as400_data_credential: {
      credentials_type: "as400";
    } & Omit<components["schemas"]["data_credential"], "credentials_type"> & {
      credentials?: {
        /** @description __Host__: Enter the hostname for your database. This is usually an IP address or text in the format __company.domain.com__. Do not include the connection protocol. */
        host: string;
        /** @description __Port__: Enter the port used to access your database. */
        port: number;
        /** @description __Username__: Enter the username used to access your database. */
        username: string;
        /** @description __Password__: Enter the password used to access your database. */
        password: string;
        /** @description __Database Name__: Enter the database name if you want to connect to a specific database. */
        database_name?: string;
      };
    } & components["schemas"]["database_data_credential"];
    aws_athena_data_credential: {
      credentials_type: "aws_athena";
    } & Omit<components["schemas"]["data_credential"], "credentials_type"> & {
      credentials?: {
        /**
         * @description __Authentication Method__: Credentials can be configured to grant access via various AWS permission mechanisms. Please select the authentication method you wish to use.
         *
         * @default Access Key
         * @enum {string}
         */
        "aws.auth.type": "Access Key";
        /** @description __AWS Access Key__: AWS Access Key ID for Athena database access. */
        "access.key.id": string;
        /** @description __AWS Secret Key__: AWS Secret Key ID for Athena database access. */
        "secret.key": string;
        /**
         * @description __AWS Region__: AWS region of the Athena database.
         *
         * @default us-east-1
         */
        "aws.region": string;
        /**
         * @description __Schema Name__: Specify the schema or database containing the tables you wish to query.
         *
         * @default default
         */
        schema_name: string;
        /** @description __S3 Path For Query Results__: Specify an S3 path in the current region to save query results. Use the format `s3://bucket-name/path/to/object/`. */
        "s3.output.location": string;
      };
    } & components["schemas"]["database_data_credential"];
    file_data_credential: {
      credentials?: {
        /**
         * @description __Handle File Encryption/Decryption?__: The platform can be configured to process encrypted files such that a Source will decrypt files before scanning, and a Destination will encrypt the generated files before uploading them to your storage.
         *
         * Default value: `false`
         */
        file_encryption_enabled?: boolean;
        /**
         * @description __File Encryption Protocol__: The type of file encryption protocol that should be used be used for encrypting/decrypting files.
         *
         * __Required__ if `file_encryption_enabled` is `true`
         *
         * Default value: `pgp`
         *
         * @enum {string}
         */
        "encrypt.standard"?: "pgp";
        /**
         * @description __External User ID__: The ID of the user whose public key is to be used for encryption/decryption.
         *
         * __Required__ if `file_encryption_enabled` is `true` and `encrypt.standard` is `pgp`
         */
        "external.user.id"?: string;
        /**
         * @description __External User's Public Key__: The external user's public key that will be used for the encryption/decryption of files.
         *
         * __Required__ if `file_encryption_enabled` is `true` and `encrypt.standard` is `pgp`
         */
        "external.public.key"?: string;
        /**
         * @description __Your User ID for Private Key__: Set this to the user ID used to generate the PGP private key.
         *
         * __Required__ if `file_encryption_enabled` is `true` and `encrypt.standard` is `pgp`
         */
        "encrypt.user.id"?: string;
        /**
         * @description __Your Password for Private Key__: Set this to the password of the user ID used to generate the PGP private key.
         *
         * __Required__ if `file_encryption_enabled` is `true` and `encrypt.standard` is `pgp`
         */
        "encrypt.private.password"?: string;
        /**
         * @description __Your Private Key__: Enter your PGP private key. This private key (and the associated user id and password) will be used for encrypting/decrypting files.
         *
         * __Required__ if `file_encryption_enabled` is `true` and `encrypt.standard` is `pgp`
         */
        "encrypt.private.key"?: string;
      };
    };
    azure_blb_data_credential: {
      credentials_type: "azure_blb";
    } & Omit<components["schemas"]["data_credential"], "credentials_type"> & ({
      credentials?: {
        /**
         * @description __Azure Storage Account Name__: The name of the storage account that you wish to access.
         *
         * __Applicable and required__ if `azure_blb.auth.type` is `SAS Token` or `Storage Account Key`
         */
        "storage.account.name"?: string;
        /**
         * @description __Authentication Mechanism__: Credentials can be configured to allow Azure access through different authentication mechanisms. Select the type of Authentication method you wish to use.
         *
         * * `SAS Token` for Shared Access Signature Token authentication.
         *
         * * `Connection String` for Key Connection String authentication.
         *
         * * `Storage Account Key` for Storage Account Key authentication.
         *
         * @enum {string}
         */
        "azure_blb.auth.type": "SAS Token" | "Connection String" | "Storage Account Key";
        /**
         * @description __Shared Access Signature Token__: Enter the shared access signature token for the Azure storage that you wish to access.
         *
         * __Required__ if `azure_blb.auth.type` is `SAS Token`
         */
        "sas.token"?: string;
        /**
         * @description __Key Connection String__: Enter the Azure connection string for the Azure storage that you wish to access.
         *
         * __Required__ if `azure_blb.auth.type` is `Connection String`
         */
        "key.connection.string"?: string;
        /**
         * @description __Storage Account Key__: Enter the Azure storage account key for the Azure storage that you wish to access.
         *
         * __Required__ if `azure_blb.auth.type` is `Storage Account Key`
         */
        "storage.account.key"?: string;
      };
    }) & components["schemas"]["file_data_credential"];
    azure_data_lake_data_credential: {
      credentials_type: "azure_data_lake";
    } & Omit<components["schemas"]["data_credential"], "credentials_type"> & ({
      credentials?: {
        /** @description __Azure Storage Account Name__: The name of the storage account that you wish to access. */
        "storage.account.name": string;
        /**
         * @description __Authentication Mechanism__: Credentials can be configured to allow Azure access through different authentication mechanisms. Select the type of Authentication method you wish to use.
         *
         * * `SAS Token` for Shared Access Signature Token authentication.
         *
         * * `Connection String` for Key Connection String authentication.
         *
         * * `Storage Account Key` for Storage Account Key authentication.
         *
         * @enum {string}
         */
        "azure_dl.auth.type": "SAS Token" | "Connection String" | "Storage Account Key";
        /**
         * @description __Shared Access Signature Token__: Enter the shared access signature token for the Azure storage that you wish to access.
         *
         * __Required__ if `azure_dl.auth.type` is `SAS Token`
         */
        "sas.token"?: string;
        /**
         * @description __Key Connection String__: Enter the Azure connection string for the Azure storage that you wish to access.
         *
         * __Required__ if `azure_dl.auth.type` is `Connection String`
         */
        "key.connection.string"?: string;
        /**
         * @description __Storage Account Key__: Enter the Azure storage account key for the Azure storage that you wish to access.
         *
         * __Required__ if `azure_dl.auth.type` is `Storage Account Key`
         */
        "storage.account.key"?: string;
      };
    }) & components["schemas"]["file_data_credential"];
    azure_synapse_data_credential: {
      credentials_type: "azure_synapse";
    } & Omit<components["schemas"]["data_credential"], "credentials_type"> & ({
      credentials?: {
        /** @description __Host__: Enter the hostname for your database. This is usually an IP address or text in the format __company.domain.com__. Do not include the connection protocol. */
        host: string;
        /** @description __Port__: Enter the port used to access your database. */
        port: number;
        /** @description __Username__: Enter the username used to access your database. */
        username: string;
        /** @description __Password__: Enter the password used to access your database. */
        password: string;
        /** @description __Database Name__: Enter the database name if you want to connect to a specific database. */
        database_name?: string;
        /** @description __Schema Name__: Enter the schema name for the database to which you wish to connect. */
        schema_name?: string;
        /**
         * @description __Connection Mode / Application Intent__: You can restrict database connectivity capabilities by specifying the connection mode. Select __Read Only__ to connect to the database in __readonly__ mode.
         *
         * * `readonly`: Connect in read-only mode.
         *
         * * `readwrite`: Connect in read-write mode.
         *
         * Default value: `readwrite`
         *
         * @enum {string}
         */
        "database.field.applicationIntent"?: "readonly" | "readwrite";
      };
    }) & components["schemas"]["database_data_credential"];
    bigquery_data_credential: {
      credentials_type: "bigquery";
    } & Omit<components["schemas"]["data_credential"], "credentials_type"> & {
      credentials?: {
        /**
         * @description __Is Service Account Authentication?__ We support multiple ways of authenticating your BigQuery account. We recommend using the Google Service Account (System User Authentication) method, as it is best suited for accessing your data and is tied to the service account instead of the individual user account.
         * * Set to `true` if you wish to choose Google Service Account (System User Authentication).
         * * Set this to `false` if you wish to authenticate using 3-legged OAuth.
         * Default Value: `false`
         */
        is_service_account: boolean;
        /** @description __Project ID__: The Project ID to which the database you wish to access belongs. */
        project_id: string;
        /**
         * @description __Service Account JSON credentials content__: This is the content of the service account credentials JSON file generated by Google Cloud IAM, which is added to the payload as a JSON object.
         *
         * __Required__ if `is_service_account` is `true`
         */
        json_creds?: Record<string, never>;
        /**
         * @description __End User Authentication Type__: This must be set to `OAUTH2` if you are choosing the 3-legged OAuth authentication mechanism.
         *
         * __Required__ if `is_service_account` is `false`
         *
         * @enum {string}
         */
        "auth.type"?: "OAUTH2";
        /**
         * @description __Client ID__: The Client ID of your OAuth 2.0 client.
         *
         * __Required__ if `is_service_account` is `false`
         */
        "oauth2.client.id"?: string;
        /**
         * @description __Client Secret__: The Client Secret of your OAuth 2.0 client.
         *
         * __Required__ if `is_service_account` is `false`
         */
        "oauth2.client.secret"?: string;
        /**
         * @description __Access Token URL__: The OAuth 2.0 Token URL used for fetching the token from the API token server. This must be `https://www.googleapis.com/oauth2/v4/token`.
         *
         * __Required__ if `is_service_account` is `false`
         *
         * @enum {string}
         */
        "oauth2.access.token.url"?: "https://www.googleapis.com/oauth2/v4/token";
        /**
         * @description __Token Type__: The token type that should be used when attaching the OAuth2.0 token to the request. This must be `Bearer`.
         *
         * __Required__ if `is_service_account` is `false`
         *
         * @enum {string}
         */
        "oauth2.token.type.override"?: "Bearer";
        /**
         * @description __Access Token URL method__: The request method used for the OAuth 2.0 Token URL. This must be `POST`.
         *
         * __Required__ if `is_service_account` is `false`
         *
         * @enum {string}
         */
        "oauth2.access.token.method"?: "POST";
        /**
         * @description __Nexla OAuth 2.0 connector codename__: Unique codename for the Nexla token refresh mechanism, which is used to identify this connector. This must be `bigquery`.
         *
         * __Required__ if `is_service_account` is `false`
         *
         * @enum {string}
         */
        "vendor.name"?: "bigquery";
        /**
         * @description __Token Type__: The token type that should be used when attaching the OAuth2.0 token to the request. This must be `Bearer`.
         *
         * __Required__ if `is_service_account` is `false`
         *
         * @enum {string}
         */
        "vendor.token_type"?: "Bearer";
        /**
         * @description __Authentication Payload Mode__: Set how the OAuth 2.0 Client ID and Client Secret should be sent with the Token URL. This must be set to `header`.
         *
         * __Required__ if `is_service_account` is `false`
         *
         * @enum {string}
         */
        "vendor.auth_scheme"?: "header";
        /**
         * @description __API Scopes__: Scopes that should be added to the OAuth token calls. This should be `https://www.googleapis.com/auth/bigquery https://www.googleapis.com/auth/devstorage.read_write`.
         *
         * __Required__ if `is_service_account` is `false`
         *
         * @enum {string}
         */
        "vendor.scopes"?: "https://www.googleapis.com/auth/bigquery https://www.googleapis.com/auth/devstorage.read_write";
        /**
         * @description __Refresh Token URL__: The OAuth 2.0 Token Refresh URL that is used for fetching a new access token using the current access token and refresh token. This must be `https://www.googleapis.com/oauth2/v4/token`.
         *
         * __Required__ if `is_service_account` is `false`
         *
         * @enum {string}
         */
        "vendor.refresh_url"?: "https://www.googleapis.com/oauth2/v4/token";
        /**
         * @description __Requires Auto-Refresh of Token__: Access tokens are short-lived, and the platform should automatically continuously refresh the token to retain a valid access token. This must be `true`.
         *
         * __Required__ if `is_service_account` is `false`
         *
         * @enum {boolean}
         */
        "vendor.has_token_expiration_ts"?: true;
        /**
         * @description __Access token expiration time__: Set this to the expiration time (in seconds) of the access token received when you made the first token request as part of the 3-legged OAuth 2.0 token fetching sequence. This is usually `3599` for a 3-legged OAuth workflow.
         *
         * __Required__ if `is_service_account` is `false`
         */
        "vendor.token_expires_in"?: number;
        /**
         * @description __Access Token__: Set this to the access token received when you made the first token request as part of the the 3-legged OAuth 2.0 token fetching sequence.
         *
         * __Required__ if `is_service_account` is `false`
         */
        access_token?: string;
        /**
         * @description __Access Token__: Set this to the access token received when you made the first token request as part of the the 3-legged OAuth 2.0 token fetching sequence. Note that this is the same as `access_token` above but is required in the payload to allow Nexla to automatically continuously refresh tokens.
         *
         * __Required__ if `is_service_account` is `false`
         */
        "vendor.access_token"?: string;
        /**
         * @description __Refresh Token__: Set this to the refresh token received when you made the first token request as part of the the 3-legged OAuth 2.0 token fetching sequence.
         *
         * __Required__ if `is_service_account` is `false`
         */
        "vendor.refresh_token"?: string;
        /**
         * @description __GCS Location for staging data__: Before loading data from/to Bigquery, we might need to stage the data in a temporary GCS location. This temporary location is created by the platform automatically if the user has permission to create a bucket/path.
         *
         * But you can override bucket creation and instead name a specific GCS location where temporary staging files will be created.
         */
        "gcs.location"?: string;
        /**
         * @description __Temporary Dataset__: Before loading data from/to BigQuery we might need to stage the data in a temporary dataset. This temporary dataset is created by the platform automatically if the user has permission to create a dataset.
         *
         * However, you can override dataset creation and instead name a specific existing dataset as the temporary dataset to be used.
         */
        "temp.table.dataset"?: string;
      };
    } & components["schemas"]["file_data_credential"];
    box_data_credential: {
      credentials_type: "box";
    } & Omit<components["schemas"]["data_credential"], "credentials_type"> & {
      credentials?: {
        /**
         * @description __End User Authentication Type__: This must be set to `OAUTH2` if you are choosing the 3-legged OAuth authentication mechanism.
         *
         * @enum {string}
         */
        "auth.type": "OAUTH2";
        /** @description __Client ID__: The Client ID of your OAuth 2.0 client. */
        "oauth2.client.id": string;
        /** @description __Client Secret__: The Client Secret of your OAuth 2.0 client. */
        "oauth2.client.secret": string;
        /**
         * @description __Access Token URL__: The OAuth 2.0 Token URL used for fetching the token from the API token server. This must be `https://api.box.com/oauth2/token`.
         *
         * @enum {string}
         */
        "oauth2.access.token.url": "https://api.box.com/oauth2/token";
        /**
         * @description __Token Type__: The token type that should be used when attaching the OAuth2.0 token to the request. This must be `Bearer`.
         *
         * @enum {string}
         */
        "oauth2.token.type.override": "Bearer";
        /**
         * @description __Access Token URL method__: The request method used for the OAuth 2.0 Token URL. This must be `POST`.
         *
         * @enum {string}
         */
        "oauth2.access.token.method": "POST";
        /**
         * @description __Nexla OAuth 2.0 connector codename__: Unique codename for the Nexla token refresh mechanism, which is used to identify this connector. This must be `box`.
         *
         * @enum {string}
         */
        "vendor.name": "box";
        /**
         * @description __Token Type__: The token type that should be used when attaching the OAuth2.0 token to the request. This must be `Bearer`.
         *
         * @enum {string}
         */
        "vendor.token_type": "Bearer";
        /**
         * @description __Authentication Payload Mode__: Set how the OAuth 2.0 Client ID and Client Secret should be sent with the Token URL. This must be set to `query`.
         *
         * @enum {string}
         */
        "vendor.auth_scheme": "query";
        /**
         * @description __Refresh Token URL__: The OAuth 2.0 Token Refresh URL that is used for fetching a new access token using the current access token and refresh token. This must be `https://api.box.com/oauth2/token`.
         *
         * @enum {string}
         */
        "vendor.refresh_url": "https://www.googleapis.com/oauth2/v4/token";
        /**
         * @description __Requires Auto-Refresh of Token__:  Access tokens are short-lived, and the platform should automatically continuously refresh the token to retain a valid access token. This must be `true`.
         *
         * @enum {boolean}
         */
        "vendor.has_token_expiration_ts": true;
        /** @description __Access token expiration time__: Set this to the expiration time (in seconds) of the access token received when you made the first token request as part of the 3-legged OAuth 2.0 token fetching sequence. This is usually `3599` for a 3-legged OAuth workflow. */
        "vendor.token_expires_in": number;
        /** @description __Access Token__: Set this to the access token received when you made the first token request as part of the the 3-legged OAuth 2.0 token fetching sequence. */
        access_token: string;
        /** @description __Access Token__: Set this to the access token received when you made the first token request as part of the the 3-legged OAuth 2.0 token fetching sequence. Note that this is the same as `access_token` above but is required in the payload to allow Nexla to automatically continuously refresh tokens. */
        "vendor.access_token": string;
        /** @description __Refresh Token__: Set this to the refresh token received when you made the first token request as part of the the 3-legged OAuth 2.0 token fetching sequence. */
        "vendor.refresh_token": string;
      };
    } & components["schemas"]["file_data_credential"];
    cloudsql_mysql_data_credential: {
      credentials_type: "cloudsql_mysql";
    } & Omit<components["schemas"]["data_credential"], "credentials_type"> & {
      credentials?: {
        /** @description __Host__: Enter the hostname for your database. This is usually an IP address or text in the format `company.domain.com`. Do not include the connection protocol. */
        host: string;
        /** @description __Port__: Enter the port used to access your database. */
        port: number;
        /** @description __Username__: Enter the username used to access your database. */
        username: string;
        /** @description __Password__: Enter the password used to access your database. */
        password: string;
        /** @description __Database Name__: Enter the database name if you want to connect to a specific database. */
        database_name?: string;
      };
    } & components["schemas"]["database_data_credential"];
    cloudsql_postgres_data_credential: {
      credentials_type: "cloudsql_postgres";
    } & Omit<components["schemas"]["data_credential"], "credentials_type"> & {
      credentials?: {
        /** @description __Host__: Enter the hostname for your database. This is in the format `company.domain.com`. Do not include the connection protocol. */
        host: string;
        /** @description __Port__: Enter the port used to access your database. */
        port: number;
        /** @description __Username__: Enter the username used to access your database. */
        username: string;
        /** @description __Password__: Enter the password used to access your database. */
        password: string;
        /** @description __Database Name__: Enter the database name if you want to connect to a specific database. */
        database_name: string;
        /** @description __Schema Name__: Enter the schema name for the tables in which you are interested. */
        schema_name?: string;
      };
    } & components["schemas"]["database_data_credential"];
    cloudsql_sqlserver_data_credential: {
      credentials_type: "cloudsql_sqlserver";
    } & Omit<components["schemas"]["data_credential"], "credentials_type"> & ({
      credentials?: {
        /** @description __Host__: Enter the hostname for your database. This is usually an IP address or text in the format __company.domain.com__. Do not include the connection protocol. */
        host: string;
        /** @description __Port__: Enter the port used to access your database. */
        port: number;
        /** @description __Username__: Enter the username used to access your database. */
        username: string;
        /** @description __Password__: Enter the password used to access your database. */
        password: string;
        /** @description __Database Name__: Enter the database name if you want to connect to a specific database. */
        database_name?: string;
        /** @description __Schema Name__: Enter the schema name for the database to which you wish to connect. */
        schema_name?: string;
        /**
         * @description __Connection Mode / Application Intent__: You can restrict database connectivity capabilities by specifying the connection mode. Select __Read Only__ to connect to the database in __readonly__ mode.
         *
         * * `readonly`: Connect in read-only mode.
         *
         * * `readwrite`: Connect in read-write mode.
         *
         * Default value: `readwrite`
         *
         * @enum {string}
         */
        "database.field.applicationIntent"?: "readonly" | "readwrite";
      };
    }) & components["schemas"]["database_data_credential"];
    stream_data_credential: {
      credentials?: {
        /**
         * @description __Requires SSH Tunnel for access?__: If your server is not publicly accessible, Nexla enables connecting via an SSH tunnel. When using this method, Nexla will connect to a bastion host via SSH, and the server connection will occur from the SSH host.
         *
         * Default value: `false`
         */
        has_ssh_tunnel?: boolean;
        /**
         * @description __SSH Tunnel Host__: To connect via an SSH tunnel, you need to use a bastion host running an SSH tunnel server with access to your database. Enter the SSH tunnel hostname or IP address of the bastion host.
         *
         * __Required__ if `has_ssh_tunnel` is `true`
         */
        "tunnel.bastion.host"?: string;
        /**
         * @description __SSH Tunnel Port__: Enter the port of the tunnel bastion host to which Nexla can connect.
         *
         * __Required__ if `has_ssh_tunnel` is `true`
         *
         * Default Value: `22`
         */
        "tunnel.bastion.port"?: number;
        /**
         * @description __Username for tunnel__: As part of setting up the bastion host, you also need to create an SSH user for Nexla. Enter that username here. Usually, this is set to `nexla`.
         *
         * __Required__ if `has_ssh_tunnel` is `true`
         */
        "tunnel.bastion.user"?: string;
      };
    };
    confluent_kafka_data_credential: {
      credentials_type: "confluent_kafka";
    } & Omit<components["schemas"]["data_credential"], "credentials_type"> & {
      credentials?: {
        /** @description __Kafka Bootstrap Servers__: Enter the addresses of the Kafka brokers. These are usually in the form of Virtual IP addresses. */
        "target.bootstrap.servers": string;
        /**
         * @description __Security Protocol__: Choose the appropriate security protocol for your Kafka channels.
         *
         * * `SASL_SSL`: SASL-authenticated SSL channel
         *
         * @enum {string}
         */
        "security.protocol": "SASL_SSL";
        /** @description __Confluent Cloud API Key__: Enter the API Key for the Confluent Cloud cluster. */
        "sasl.jaas.username": string;
        /** @description __Confluent Cloud API Secret__: Enter the API Secret required to connect to the Confluent Cloud cluster. */
        "sasl.jaas.password": string;
        /**
         * @description __Consumer Group ID__: Enter the  Group ID of the group to which Nexla consumers will belong.
         *
         * This is usually set to `nexla-consumer`.
         */
        "group.id.prefix"?: string;
      };
    } & components["schemas"]["stream_data_credential"];
    databricks_data_credential: {
      credentials_type: "databricks";
    } & Omit<components["schemas"]["data_credential"], "credentials_type"> & ({
      credentials?: {
        /**
         * @description __Authentication Type__: Select the authentication type for your databricks instance.
         *
         * * `token` - Token Based Authentication: Use this authentication method if you are using a personal access token to authenticate with Databricks. See https://docs.databricks.com/aws/en/dev-tools/auth/pat#pat-user for more information.
         *
         * * `oidc` -  OAuth Authentication: Use this authentication method if you are using OAuth2.0 to authenticate with Databricks. This method is recommended for production environments.
         *
         * @enum {string}
         */
        databricks_auth_type: "token" | "oidc";
        /**
         * @description __URL Format__: You can set the Databricks authentication information as a JDBC URL or as parts that will be combined by Nexla to create the connection string.
         *
         * * `jdbc_url` - JDBC URL: Set the JDBC URL to your databricks location. This should be in the form `jdbc:spark:/...` or `jdbc:databricks:/...`.
         *
         * * `http_path_parts` - HTTP Path Parts: Set the HTTP Path for the SQL Endpoint. This is usually in the form `sql/protocolv1/o/<id>/0916-102516-naves603` and available in __JDBC settings__ in your databricks console.
         *
         * @enum {string}
         */
        "ui.url_format": "jdbc_url" | "http_path_parts";
        /**
         * @description __JDBC URL__: Enter the JDBC URL to your databricks location. This should be in the form `jdbc:databricks:/...` or `jdbc:spark:/...`.
         *
         * **Note**: For **OAuth Authentication** please ensure that the URL does not include the `AuthMech` and `Auth_Flow` parameters. The Databricks Console for copying connection strings often includes these parameters, so you may need to remove them before using the connection string in Nexla.
         *
         * __Required__ if `ui.url_format` is `jdbc_url`.
         */
        url?: string;
        /**
         * @description __Host__: Enter the hostname for your database. This is in the format `company.domain.com`. Do not include the connection protocol.
         * __Required__ if `ui.url_format` is `http_path_parts`.
         */
        host?: string;
        /**
         * @description __Port__: Enter the port used to access your database.
         * __Required__ if `ui.url_format` is `http_path_parts`.
         */
        port?: number;
        /**
         * @description __HTTP Path__: Enter the HTTP Path of the SQL Endpoint.
         * This is usually in the form `sql/protocolv1/o/<id>/0916-102516-naves603` and is available in __JDBC settings__ in your Databricks console.
         * __Required__ if `ui.url_format` is `http_path_parts`.
         */
        http_path?: string;
        /**
         * @description __Username__: Enter the username used to access your database.
         * __Required__ if `ui.url_format` is `http_path_parts`.
         */
        username?: string;
        /**
         * @description __Password__: Enter the password used to access your database.
         * __Required__ if `databricks_auth_type` is `token` and `ui.url_format` is `http_path_parts`.
         */
        password?: string;
        /**
         * @description __OAuth2 Authentication Mechanism__: Set the authentication mechanism for your databricks instance.
         * __Required__ if `databricks_auth_type` is `oidc`.
         * __Applicable__ only if `databricks_auth_type` is `oidc`.
         *
         * @enum {string}
         */
        "databricks.field.AuthMech"?: 11;
        /**
         * @description __OAuth2 Authentication Flow__: Set the authentication flow for your databricks instance.
         * __Required__ if `databricks_auth_type` is `oidc`.
         * __Applicable__ only if `databricks_auth_type` is `oidc`.
         *
         * @enum {string}
         */
        "databricks.field.Auth_Flow"?: 1;
        /**
         * @description __Service Principal UUID/Application ID__: Enter the Service Principal UUID/Application ID for the Databricks warehouse you wish to connect to.
         * __Required__ if `databricks_auth_type` is `oidc`.
         * __Applicable__ only if `databricks_auth_type` is `oidc`.
         */
        "databricks.field.OAuth2ClientId"?: string;
        /**
         * @description __Service Principal Secret__: Enter the Service Principal Secret for the Databricks you wish to connect to.
         * __Required__ if `databricks_auth_type` is `oidc`.
         * __Applicable__ only if `databricks_auth_type` is `oidc`.
         */
        "databricks.field.OAuth2Secret"?: string;
        /**
         * @description __Database Name__: Enter the database name if you want to connect to a specific database.
         * Usually, this is set to: `spark`.
         */
        database_name?: string;
        /**
         * @description __Schema Name__: Enter the schema name for the database to which you wish to connect.
         * Usually, this is set to `default`.
         */
        schema_name?: string;
        /**
         * @description __Databricks Cloud Type__: Select the cloud environment type of your Databricks instance.
         * Usually, this is the Databricks cloud environment, but we also support connecting to Databricks instances running in other cloud environments.
         *
         * @enum {string}
         */
        "databricks.cloud.type": "AWS" | "Azure" | "databricks" | "GCP";
        /**
         * @description __Nexla Credential ID for temporary data staging__: Before loading data to Databricks we need to stage the data temporarily. In the default configuration, the staging data is stored in a Nexla private location, but you can configure the platform to stage data in your custom Cloud storage location.
         * Enter the __Nexla Credential ID__ of your S3 or Azure Blob storage account where you want Nexla to write temporary and final data. Leave this blank if you want Nexla to handle temporary data storage.
         * __Applicable__ if `databricks.cloud.type` is `AWS` or `Azure`.
         * Ignore this property if you do not want to use your custom data-staging area.
         */
        "databricks.cloud.credentials.id"?: number;
        /**
         * @description __S3 Path for Temporary Data Staging__: If you are choosing to store temporary data in your own AWS S3 location, please configure the S3 path where the temporary data should be staged. Note that this path must be accessible to the Nexla Credential ID entered in the previous field.
         * __Applicable and required__ only if `databricks.cloud.type` is `AWS` and you are setting a valid credential ID for `databricks.cloud.credentials.id`.
         */
        "databricks.temp.s3.bucket"?: string;
        /**
         * @description __S3 Path for Delta Tables__: If you are choosing to store temporary data in your own AWS S3 location, please configure the S3 path where the delta tables should be staged. Note that this path must be to Nexla Credential ID provided earlier.
         * Leave this blank for creating Delta tables in DBFS.
         * __Applicable and required__ only if `databricks.cloud.type` is `AWS` and you are setting a valid credential ID for `databricks.cloud.credentials.id`.
         */
        "databricks.destination.s3.bucket"?: string;
        /**
         * @description __Azure Path for Temporary Data Staging__: If you are choosing to store temporary data in your own Azure Blob location, please configure the path where the temporary data should be created. Note that this path must be accessible to the Nexla Credential ID entered in the previous field.
         * __Applicable and required__ only if `databricks.cloud.type` is `Azure` and you are setting a valid credential ID for `databricks.cloud.credentials.id`.
         */
        "databricks.temp.azure.bucket"?: string;
        /**
         * @description __Azure Path for Delta Tables__: If you are choosing to store temporary data in your own Azure Blob location, please configure the path where the delta tables should be created. Note that this path must be accessible to the Nexla Credential ID provided earlier.
         * Leave this blank for creating Delta tables in DBFS.
         * __Applicable and required__ only if `databricks.cloud.type` is `Azure` and you are setting a valid credential ID for `databricks.cloud.credentials.id`.
         */
        "databricks.destination.azure.bucket"?: string;
      };
    }) & components["schemas"]["database_data_credential"];
    db2_data_credential: {
      credentials_type: "db2";
    } & Omit<components["schemas"]["data_credential"], "credentials_type"> & {
      credentials?: {
        /** @description __Host__: Enter the hostname for your database. This is in the format `company.domain.com`. Do not include the connection protocol. */
        host: string;
        /** @description __Port__: Enter the port used to access your database. */
        port: number;
        /** @description __Username__: Enter the username used to access your database. */
        username: string;
        /** @description __Password__: Enter the password used to access your database. */
        password: string;
        /** @description __Database Name__: Enter the database name if you want to connect to a specific database. */
        database_name?: string;
      };
    } & components["schemas"]["database_data_credential"];
    delta_lake_azure_blb_data_credential: {
      credentials_type: "delta_lake_azure_blb";
    } & Omit<components["schemas"]["data_credential"], "credentials_type"> & ({
      credentials?: {
        /**
         * @description __Azure Storage Account Name__: The name of the storage account that you wish to access.
         *
         * __Applicable and required__ if `azure_blb.auth.type` is `SAS Token` or `Storage Account Key`
         */
        "storage.account.name"?: string;
        /**
         * @description __Authentication Mechanism__: Credentials can be configured to allow Azure access through different authentication mechanisms. Select the type of Authentication method you wish to use.
         *
         * * `SAS Token` for Shared Access Signature Token authentication.
         *
         * * `Connection String` for Key Connection String authentication.
         *
         * * `Storage Account Key` for Storage Account Key authentication.
         *
         * @enum {string}
         */
        "azure_blb.auth.type": "SAS Token" | "Connection String" | "Storage Account Key";
        /**
         * @description __Shared Access Signature Token__: Enter the shared access signature token for the Azure storage that you wish to access.
         *
         * __Required__ if `azure_blb.auth.type` is `SAS Token`
         */
        "sas.token"?: string;
        /**
         * @description __Key Connection String__: Enter the Azure connection string for the Azure storage that you wish to access.
         *
         * __Required__ if `azure_blb.auth.type` is `Connection String`
         */
        "key.connection.string"?: string;
        /**
         * @description __Storage Account Key__: Enter the Azure storage account key for the Azure storage that you wish to access.
         *
         * __Required__ if `azure_blb.auth.type` is `Storage Account Key`
         */
        "storage.account.key"?: string;
      };
    }) & components["schemas"]["file_data_credential"];
    delta_lake_azure_data_lake_data_credential: {
      credentials_type: "delta_lake_azure_data_lake";
    } & Omit<components["schemas"]["data_credential"], "credentials_type"> & ({
      credentials?: {
        /** @description __Azure Storage Account Name__: The name of the storage account that you wish to access. */
        "storage.account.name": string;
        /**
         * @description __Authentication Mechanism__: Credentials can be configured to allow Azure access through different authentication mechanisms. Select the type of Authentication method you wish to use.
         *
         * * `SAS Token` for Shared Access Signature Token authentication.
         *
         * * `Connection String` for Key Connection String authentication.
         *
         * * `Storage Account Key` for Storage Account Key authentication.
         *
         * @enum {string}
         */
        "azure_dl.auth.type": "SAS Token" | "Connection String" | "Storage Account Key";
        /**
         * @description __Shared Access Signature Token__: Enter the shared access signature token for the Azure storage that you wish to access.
         *
         * __Required__ if `azure_dl.auth.type` is `SAS Token`
         */
        "sas.token"?: string;
        /**
         * @description __Key Connection String__: Enter the Azure connection string for the Azure storage that you wish to access.
         *
         * __Required__ if `azure_dl.auth.type` is `Connection String`
         */
        "key.connection.string"?: string;
        /**
         * @description __Storage Account Key__: Enter the Azure storage account key for the Azure storage that you wish to access.
         *
         * __Required__ if `azure_dl.auth.type` is `Storage Account Key`
         */
        "storage.account.key"?: string;
      };
    }) & components["schemas"]["file_data_credential"];
    delta_lake_s3_data_credential: {
      credentials_type: "delta_lake_s3";
    } & Omit<components["schemas"]["data_credential"], "credentials_type"> & ({
      credentials?: {
        /**
         * @description __Authentication Mechanism__ Credentials can be configured to allow S3 access through different AWS permissions mechanisms. Select the type of Authentication method you wish to use.
         * * `Access Key` - Select this option if you wish to use AWS Access and Secret keys for your S3 access.
         * * `ARN` - Select this option if you wish to use IAM ARN for authentication.
         * * `Instance Role` - Select this option if you wish to access S3 using an IAM Instance Role.
         * @enum {string}
         */
        s3_auth_type: "Access Key" | "ARN" | "Instance Role";
        /**
         * @description __AWS Access Key__
         *
         * __Required__ if `s3_auth_type` is `Access Key`
         */
        access_key?: string;
        /**
         * @description __AWS Secret Key__
         *
         * __Required__ if `s3_auth_type` is `Access Key`
         */
        secret_key?: string;
        /**
         * @description __External Id__: The external ID if S3 has been configured for federated access.
         *
         * __Required__ if `s3_auth_type` is `ARN`
         */
        external_id?: string;
        /**
         * @description Region for AWS S3 Account.
         *
         * Default value: `us-east-1`
         */
        region?: string;
        /** @description __IAM ARN__: The IAM Amazon Resource Name (ARN) for which these permissions are applicable. This should be entered in the format `arn:partition:service:region:account:resource`. */
        arn?: string;
        /** @description __S3 Path list access is limited to__: Set this property to `<bucket-name>` or `<bucket-name>/<folder-name>` if your AWS admin has restricted access to only a specific bucket or a path inside a bucket. */
        "test.path"?: string;
        /**
         * @description __Enable Client Side Encryption?__: The platform can be configured to encrypt/decrypt S3 objects that require client-side encryption using the AWS Key Management System (KMS). Set this option if KMS encryption is applicable.
         *
         * Default value: `false`
         */
        has_client_encryption?: boolean;
        /**
         * @description __Client Side Encryption Mode__ : Select the type of KMS encryption mode that is applicable for this credential.
         *
         * __Required__ if `has_client_encryption` is `true`
         *
         * @enum {string}
         */
        encryption_mode?: "EncryptionOnly" | "AuthenticatedEncryption" | "StrictAuthenticatedEncryption";
        /**
         * @description __Amazon KMS Key for Encryption__: The KMS Key used for encrypting/decrypting objects. Please ensure that this user has appropriate KMS permissions.
         *
         * __Required__ if `has_client_encryption` is `true`
         */
        kms_key?: string;
        /**
         * @description __Enable Server Side Encryption?__: The platform can be configured to encrypt/decrypt S3 objects that require server-side encryption.
         *
         * This can be achieved using either __Amazon S3-managed encryption keys (SSE-S3)__ or the __AWS Key Management Service (SSE-KMS)__. Set this option if server-side encryption is applicable.
         *
         * Default value: `false`
         */
        "sse.enabled"?: boolean;
        /**
         * @description __Key ARN for SSE with KMS__: The Key ARN if you want server-side encryption to be performed via the AWS Key Management System. You can leave this blank if you want to use Amazon S3-managed encryption keys.
         *
         * __Required__ if `sse.enabled` is `true`
         */
        "sse.kms_key.arn"?: string;
      };
    }) & components["schemas"]["file_data_credential"];
    dropbox_data_credential: {
      credentials_type: "dropbox";
    } & Omit<components["schemas"]["data_credential"], "credentials_type"> & {
      credentials?: {
        /** @description __Access Token__: Access token used to connect to your Dropbox account. See the Dropbox developer documentation for instructions on how to generate an access token. */
        access_token: string;
      };
    } & components["schemas"]["file_data_credential"];
    nosql_data_credential: {
      credentials?: Record<string, never>;
    };
    dynamodb_data_credential: {
      credentials_type: "dynamodb";
    } & Omit<components["schemas"]["data_credential"], "credentials_type"> & {
      credentials?: {
        /**
         * @description __Authentication Mechanism__: Credentials can be configured to allow access through different AWS permissions mechanisms. Select the type of Authentication method you wish to use.
         *
         * - __Access Key__: Use your AWS Access Key and Secret Key to authenticate.
         *
         * @enum {string}
         */
        auth_type: "Access Key";
        /**
         * @description __DynamoDB Endpoint__: Endpoint for accessing your DynamoDB instance. Usually of the form `dynamodb.us-east-2.amazonaws.com`.
         *
         * __Applicable and required__ if `auth_type` is `Access Key`.
         */
        "dynamodb.endpoint"?: string;
        /**
         * @description __AWS Access Key__: Your AWS Access Key.
         *
         * __Applicable and required__ if `auth_type` is `Access Key`.
         */
        "access.key"?: string;
        /**
         * @description __AWS Secret Key__: Your AWS Secret Key.
         *
         * __Applicable and required__ if `auth_type` is `Access Key`.
         */
        "secret.key"?: string;
        /**
         * @description __Region__: AWS Region for DynamoDB. Defaults to `us-east-1`.
         *
         * __Applicable__ if `auth_type` is `Access Key`.
         */
        "dynamodb.region"?: string;
      };
    } & components["schemas"]["nosql_data_credential"];
    firebase_data_credential: {
      credentials_type: "firebase";
    } & Omit<components["schemas"]["data_credential"], "credentials_type"> & ({
      credentials?: {
        /**
         * @description __Authentication Type__: We currently only support __System User Authentication__ method as it is best suited for accessing your own data and is tied to a service account instead of an individual user account. Please contact your Nexla support team if you need __End User Authentication__ mechanism.
         *
         * * `true`: __System User Authentication__
         * * `false`: __End User Authentication__ (Currently not supported)
         *
         * @enum {string}
         */
        is_service_account?: true | false;
        /**
         * @description __Project ID__: Enter the Project ID that the Firebase store you wish to access belongs to.
         *
         * __Applicable and required__ if `is_service_account` is `false`.
         */
        project_id?: string;
        /**
         * @description __Credentials File Content__: Enter the content of the JSON file that contains the Firebase service account credentials. This file is usually downloaded from the Firebase console.
         *
         * __Applicable and required__ if `is_service_account` is `true`.
         */
        json_creds?: string;
      };
    }) & components["schemas"]["nosql_data_credential"];
    firebolt_data_credential: {
      credentials_type: "firebolt";
    } & Omit<components["schemas"]["data_credential"], "credentials_type"> & {
      credentials?: {
        /** @description __Host__: Enter the hostname for your database. */
        host: string;
        /** @description __Port__: Enter the port used to access your database. */
        port: number;
        /** @description __Username__: Enter the username used to access your database. */
        username: string;
        /** @description __Password__: Enter the password used to access your database. */
        password: string;
        /** @description __Database Name__: Enter the database name if you want to connect to a specific database. */
        database_name: string;
      };
    } & components["schemas"]["database_data_credential"];
    ftp_data_credential: {
      credentials_type: "ftp";
    } & Omit<components["schemas"]["data_credential"], "credentials_type"> & ({
      credentials?: {
        /** @description __Host__: Enter the FTP server URL. Do not include the connection protocol. */
        host: string;
        /**
         * @description __Port__: Enter the port used to access your FTP server.
         *
         * This is usually 21 for FTP and 22 for secure FTP.
         */
        port: number;
        /**
         * @description __FTP Type__: Select the type of FTP protocol that is applicable for this connection.
         *
         * @enum {string}
         */
        "ftp.type": "ftp" | "ftps" | "sftp";
        /**
         * @description __Anonymous Access?__: Select this option if the connection should be made as an anonymous user.
         *
         * Only applicable if `ftp.type` is `ftp` or `ftps`
         *
         * Default value: `false`
         */
        anonymous?: boolean;
        /**
         * @description __Username__: Enter the username used to access your FTP server.
         *
         * Only applicable if `ftp.type` is `ftp` or `ftps` or `anonymous` is `false`.
         */
        username: string;
        /**
         * @description __Password__: Enter the password used to access your FTP server.
         *
         * Only applicable if `ftp.type` is `ftp` or `ftps` or `anonymous` is `false` and you are not using `private.key` for authentication
         */
        password: string;
        /**
         * @description __Private Key__: You can use a private key for authentication instead of a password.
         *
         * Only applicable if you are not using `password` for authentication
         */
        "private.key"?: string;
        /**
         * @description __Passphrase for Private Key__: Enter the passphrase for the private key file if it was generated with one.
         *
         * Only applicable if `ftp.type` is `sftp` and the `private.key` has a passphrase
         */
        passphrase?: string;
        /**
         * @description __FTP mode__: Select whether the connection should be established in active or passive FTP connection mode. Usually, the default setting should be sufficient.
         *
         * Default value: `passive.local`
         *
         * @enum {string}
         */
        "ftp.mode"?: "active" | "passive.local" | "passive.remote";
      };
    }) & components["schemas"]["file_data_credential"];
    gcp_alloydb_data_credential: {
      credentials_type: "gcp_alloydb";
    } & Omit<components["schemas"]["data_credential"], "credentials_type"> & {
      credentials?: {
        /** @description __Host__: Enter the hostname for your database. This is in the format `company.domain.com`. Do not include the connection protocol. */
        host: string;
        /** @description __Port__: Enter the port used to access your database. */
        port: number;
        /** @description __Username__: Enter the username used to access your database. */
        username: string;
        /** @description __Password__: Enter the password used to access your database. */
        password: string;
        /** @description __Database Name__: Enter the database name if you want to connect to a specific database. */
        database_name: string;
        /** @description __Schema Name__: Enter the schema name for the tables in which you are interested. */
        schema_name?: string;
      };
    } & components["schemas"]["database_data_credential"];
    gcp_spanner_data_credential: {
      credentials_type: "gcp_spanner";
    } & Omit<components["schemas"]["data_credential"], "credentials_type"> & {
      credentials?: {
        /**
         * @description __Is Service Account Authentication?__ We currently only support the __System User Authentication__ method, as it is best suited for accessing your data and is tied to the service account instead of the individual user account. Please contact your Nexla support team if you need the __End User Authentication__ mechanism.
         * * Set to `true` if you wish to choose Google Service Account (System User Authentication).
         */
        is_service_account: boolean;
        /** @description __Project ID__: Enter the Project ID to which the GCP Spanner database that you wish to access belongs. */
        project_id: string;
        /**
         * @description __Service Account JSON credentials content__: This is the content of the service account credentials JSON file generated by Google Cloud IAM, which is added to the payload as a JSON object.
         *
         * __Required__ if `is_service_account` is `true`
         */
        json_creds: Record<string, never>;
        /** @description __Instance ID__: Enter the Instance ID to which the GCP Spanner database that you wish to access belongs. */
        instance_id: string;
        /** @description Enter the Schema to which the GCP Spanner database that you wish to access belongs. Leave this field blank to use the default schema. */
        schema_name: string;
        /** @description Enter the Database name of the GCP Spanner database that you wish to access. */
        database_name: string;
      };
    } & components["schemas"]["database_data_credential"];
    gcs_data_credential: {
      credentials_type: "gcs";
    } & Omit<components["schemas"]["data_credential"], "credentials_type"> & {
      credentials?: {
        /**
         * @description __Is Service Account Authentication?__ We support multiple ways of authenticating your GCS account. We recommend using the Google Service Account (System User Authentication) method, as it is best suited for accessing your data and is tied to the service account instead of the individual user account.
         * * Set to `true` if you wish to choose Google Service Account (System User Authentication).
         * * Set this to `false` if you wish to authenticate using 3-legged OAuth.
         * Default Value: `false`
         */
        is_service_account: boolean;
        /** @description __Project ID__: The Project ID to which the GCS paths you wish to access belong. */
        project_id: string;
        /**
         * @description __Service Account JSON credentials content__: This is the content of the service account credentials JSON file generated by Google Cloud IAM, which is added to the payload as a JSON object.
         *
         * __Required__ if `is_service_account` is `true`
         */
        json_creds?: Record<string, never>;
        /**
         * @description __End User Authentication Type__: This must be set to `OAUTH2` if you are choosing the 3-legged OAuth authentication mechanism.
         *
         * __Required__ if `is_service_account` is `false`
         *
         * @enum {string}
         */
        "auth.type"?: "OAUTH2";
        /**
         * @description __Client ID__: The Client ID of your OAuth 2.0 client.
         *
         * __Required__ if `is_service_account` is `false`
         */
        "oauth2.client.id"?: string;
        /**
         * @description __Client Secret__: The Client Secret of your OAuth 2.0 client.
         *
         * __Required__ if `is_service_account` is `false`
         */
        "oauth2.client.secret"?: string;
        /**
         * @description __Access Token URL__: The OAuth 2.0 Token URL used for fetching the token from the API token server. This must be `https://www.googleapis.com/oauth2/v4/token`.
         *
         * __Required__ if `is_service_account` is `false`
         *
         * @enum {string}
         */
        "oauth2.access.token.url"?: "https://www.googleapis.com/oauth2/v4/token";
        /**
         * @description __Token Type__: The token type that should be used when attaching the OAuth2.0 token to the request. This must be `Bearer`.
         *
         * __Required__ if `is_service_account` is `false`
         *
         * @enum {string}
         */
        "oauth2.token.type.override"?: "Bearer";
        /**
         * @description __Access Token URL method__: The request method used for the OAuth 2.0 Token URL. This must be `POST`.
         *
         * __Required__ if `is_service_account` is `false`
         *
         * @enum {string}
         */
        "oauth2.access.token.method"?: "POST";
        /**
         * @description __Nexla OAuth 2.0 connector codename__: Unique codename for the Nexla token refresh mechanism, which is used to identify this connector. This must be `gcs`.
         *
         * __Required__ if `is_service_account` is `false`
         *
         * @enum {string}
         */
        "vendor.name"?: "gcs";
        /**
         * @description __Token Type__: The token type that should be used when attaching the OAuth2.0 token to the request. This must be `Bearer`.
         *
         * __Required__ if `is_service_account` is `false`
         *
         * @enum {string}
         */
        "vendor.token_type"?: "Bearer";
        /**
         * @description __Authentication Payload Mode__: Set how the OAuth 2.0 Client ID and Client Secret should be sent with the Token URL. This must be set to `header`.
         *
         * __Required__ if `is_service_account` is `false`
         *
         * @enum {string}
         */
        "vendor.auth_scheme"?: "header";
        /**
         * @description __API Scopes__: Scopes that should be added to the OAuth token calls. This should be `https://www.googleapis.com/auth/devstorage.read_write`.
         *
         * __Required__ if `is_service_account` is `false`
         *
         * @enum {string}
         */
        "vendor.scopes"?: "https://www.googleapis.com/auth/devstorage.read_write";
        /**
         * @description __Refresh Token URL__: The OAuth 2.0 Token Refresh URL used for fetching a new access token using the current access token and refresh token. This must be `https://www.googleapis.com/oauth2/v4/token`.
         *
         * __Required__ if `is_service_account` is `false`
         *
         * @enum {string}
         */
        "vendor.refresh_url"?: "https://www.googleapis.com/oauth2/v4/token";
        /**
         * @description __Requires Auto-Refresh of Token__: GCS Access tokens are short-lived, and the platform should automatically continuously refresh the token to retain a valid access token. This must be `true`.
         *
         * __Required__ if `is_service_account` is `false`
         *
         * @enum {boolean}
         */
        "vendor.has_token_expiration_ts"?: true;
        /**
         * @description __Access token expiration time__: Set this to the expiration time (in seconds) of the access token received when you made the first token request as part of the 3-legged OAuth 2.0 token fetching sequence. This is usually `3599` for a GCS 3-legged OAuth workflow.
         *
         * __Required__ if `is_service_account` is `false`
         */
        "vendor.token_expires_in"?: number;
        /**
         * @description __Access Token__: Set this to the access token received when you made the first token request as part of the 3-legged OAuth 2.0 token fetching sequence.
         *
         * __Required__ if `is_service_account` is `false`
         */
        access_token?: string;
        /**
         * @description __Access Token__: Set this to the access token received when you made the first token request as part of the 3-legged OAuth 2.0 token fetching sequence. Note that this is the same as `access_token` above but is required in the payload to allow Nexla to automatically continuously refresh tokens.
         *
         * __Required__ if `is_service_account` is `false`
         */
        "vendor.access_token"?: string;
        /**
         * @description __Refresh Token__: Set this to the refresh token received when you made the first token request as part of the 3-legged OAuth 2.0 token fetching sequence.
         *
         * __Required__ if `is_service_account` is `false`
         */
        "vendor.refresh_token"?: string;
        /** @description __GCS Path list access is limited to__ : Set this property to `<bucket-name>` or `<bucket-name>/<folder-name>` if your GCS admin has restricted access to only a specific bucket or a path inside a bucket. */
        "test.path"?: string;
      };
    } & components["schemas"]["file_data_credential"];
    gdrive_data_credential: {
      credentials_type: "gdrive";
    } & Omit<components["schemas"]["data_credential"], "credentials_type"> & {
      credentials?: {
        /**
         * @description __Is Service Account Authentication?__ We support multiple ways of authenticating your account. We recommend using the Google Service Account (System User Authentication) method, as it is best suited for accessing your data and is tied to the service account instead of the individual user account.
         * * Set to `true` if you wish to choose Google Service Account (System User Authentication).
         * * Set this to `false` if you wish to authenticate using 3-legged OAuth.
         * Default Value: `false`
         */
        is_service_account: boolean;
        /** @description __Project ID__: The Project ID to which the GCS paths that you wish to access belong. */
        project_id: string;
        /**
         * @description __Service Account JSON credentials content__: This is the content of the service account credentials JSON file generated by Google Cloud IAM, which is added to the payload as a JSON object.
         *
         * __Required__ if `is_service_account` is `true`
         */
        json_creds?: Record<string, never>;
        /**
         * @description __End User Authentication Type__: This must be set to `OAUTH2` if you are choosing the 3-legged OAuth authentication mechanism.
         *
         * __Required__ if `is_service_account` is `false`
         *
         * @enum {string}
         */
        "auth.type"?: "OAUTH2";
        /**
         * @description __Client ID__: The Client ID of your OAuth 2.0 client.
         *
         * __Required__ if `is_service_account` is `false`
         */
        "oauth2.client.id"?: string;
        /**
         * @description __Client Secret__: The Client Secret of your OAuth 2.0 client.
         *
         * __Required__ if `is_service_account` is `false`
         */
        "oauth2.client.secret"?: string;
        /**
         * @description __Access Token URL__: The OAuth 2.0 Token URL used for fetching the token from the API token server. This must be `https://www.googleapis.com/oauth2/v4/token`.
         *
         * __Required__ if `is_service_account` is `false`
         *
         * @enum {string}
         */
        "oauth2.access.token.url"?: "https://www.googleapis.com/oauth2/v4/token";
        /**
         * @description __Token Type__: The token type that should be used when attaching the OAuth2.0 token to the request. This must be `Bearer`.
         *
         * __Required__ if `is_service_account` is `false`
         *
         * @enum {string}
         */
        "oauth2.token.type.override"?: "Bearer";
        /**
         * @description __Access Token URL method__: The request method used for the OAuth 2.0 Token URL. This must be `POST`.
         *
         * __Required__ if `is_service_account` is `false`
         *
         * @enum {string}
         */
        "oauth2.access.token.method"?: "POST";
        /**
         * @description __Nexla OAuth 2.0 connector codename__: Unique codename for the Nexla token refresh mechanism, which is used to identify this connector. This must be `gdrive`.
         *
         * __Required__ if `is_service_account` is `false`
         *
         * @enum {string}
         */
        "vendor.name"?: "gdrive";
        /**
         * @description __Token Type__: The token type that should be used when attaching the OAuth2.0 token to the request. This must be `Bearer`.
         *
         * __Required__ if `is_service_account` is `false`
         *
         * @enum {string}
         */
        "vendor.token_type"?: "Bearer";
        /**
         * @description __Authentication Payload Mode__: Set how the OAuth 2.0 Client ID and Client Secret should be sent with the Token URL. This must be set to `header`.
         *
         * __Required__ if `is_service_account` is `false`
         *
         * @enum {string}
         */
        "vendor.auth_scheme"?: "header";
        /**
         * @description __API Scopes__: Scopes that should be added to the OAuth token calls. This should be `https://www.googleapis.com/auth/drive`.
         *
         * __Required__ if `is_service_account` is `false`
         *
         * @enum {string}
         */
        "vendor.scopes"?: "https://www.googleapis.com/auth/drive";
        /**
         * @description __Refresh Token URL__: The OAuth 2.0 Token Refresh URL that is used for fetching a new access token using the current access token and refresh token. This must be `https://www.googleapis.com/oauth2/v4/token`.
         *
         * __Required__ if `is_service_account` is `false`
         *
         * @enum {string}
         */
        "vendor.refresh_url"?: "https://www.googleapis.com/oauth2/v4/token";
        /**
         * @description __Requires Auto-Refresh of Token__:  Access tokens are short-lived, and the platform should automatically continuously refresh the token to retain a valid access token. This must be `true`.
         *
         * __Required__ if `is_service_account` is `false`
         *
         * @enum {boolean}
         */
        "vendor.has_token_expiration_ts"?: true;
        /**
         * @description __Access token expiration time__: Set this to the expiration time (in seconds) of the access token received when you made the first token request as part of the 3-legged OAuth 2.0 token fetching sequence. This is usually `3599` for a 3-legged OAuth workflow.
         *
         * __Required__ if `is_service_account` is `false`
         */
        "vendor.token_expires_in"?: number;
        /**
         * @description __Access Token__: Set this to the access token received when you made the first token request as part of the 3-legged OAuth 2.0 token fetching sequence.
         *
         * __Required__ if `is_service_account` is `false`
         */
        access_token?: string;
        /**
         * @description __Access Token__: Set this to the access token received when you made the first token request as part of the 3-legged OAuth 2.0 token fetching sequence. Note that this is the same as `access_token` above but is required in the payload to allow Nexla to automatically continuously refresh tokens.
         *
         * __Required__ if `is_service_account` is `false`
         */
        "vendor.access_token"?: string;
        /**
         * @description __Refresh Token__: Set this to the refresh token received when you made the first token request as part of the 3-legged OAuth 2.0 token fetching sequence.
         *
         * __Required__ if `is_service_account` is `false`
         */
        "vendor.refresh_token"?: string;
      };
    } & components["schemas"]["file_data_credential"];
    google_pubsub_data_credential: {
      credentials_type: "google_pubsub";
    } & Omit<components["schemas"]["data_credential"], "credentials_type"> & {
      credentials?: {
        /**
         * @description __Is Service Account Authentication?__ We support multiple ways of authenticating your account. We recommend using the Google Service Account (System User Authentication) method, as it is best suited for accessing your data and is tied to the service account instead of the individual user account.
         * * Set to `true` if you wish to choose Google Service Account (System User Authentication).
         * * Set this to `false` if you wish to authenticate using 3-legged OAuth.
         * Default Value: `false`
         */
        is_service_account: boolean;
        /** @description __Project ID__: The Project ID to which the resources that wish to access belong. */
        project_id: string;
        /**
         * @description __Service Account JSON credentials content__: This is the content of the service account credentials JSON file generated by Google Cloud IAM, which is added to the payload as a JSON object.
         *
         * __Required__ if `is_service_account` is `true`
         */
        json_creds?: Record<string, never>;
        /**
         * @description __End User Authentication Type__: This must be set to `OAUTH2` if you are choosing the 3-legged OAuth authentication mechanism.
         *
         * __Required__ if `is_service_account` is `false`
         *
         * @enum {string}
         */
        "auth.type"?: "OAUTH2";
        /**
         * @description __Client ID__: The Client ID of your OAuth 2.0 client.
         *
         * __Required__ if `is_service_account` is `false`
         */
        "oauth2.client.id"?: string;
        /**
         * @description __Client Secret__: The Client Secret of your OAuth 2.0 client.
         *
         * __Required__ if `is_service_account` is `false`
         */
        "oauth2.client.secret"?: string;
        /**
         * @description __Access Token URL__: The OAuth 2.0 Token URL used for fetching the token from the API token server. This must be `https://www.googleapis.com/oauth2/v4/token`.
         *
         * __Required__ if `is_service_account` is `false`
         *
         * @enum {string}
         */
        "oauth2.access.token.url"?: "https://www.googleapis.com/oauth2/v4/token";
        /**
         * @description __Token Type__: The token type that should be used when attaching the OAuth2.0 token to the request. This must be `Bearer`.
         *
         * __Required__ if `is_service_account` is `false`
         *
         * @enum {string}
         */
        "oauth2.token.type.override"?: "Bearer";
        /**
         * @description __Access Token URL method__: The request method used for the OAuth 2.0 Token URL. This must be `POST`.
         *
         * __Required__ if `is_service_account` is `false`
         *
         * @enum {string}
         */
        "oauth2.access.token.method"?: "POST";
        /**
         * @description __Nexla OAuth 2.0 connector codename__: The unique codename for the Nexla token refresh mechanism, which is used to identify this connector. This must be `google_pubsub`.
         *
         * __Required__ if `is_service_account` is `false`
         *
         * @enum {string}
         */
        "vendor.name"?: "google_pubsub";
        /**
         * @description __Token Type__: The token type that should be used when attaching the OAuth2.0 token to the request. This must be `Bearer`.
         *
         * __Required__ if `is_service_account` is `false`
         *
         * @enum {string}
         */
        "vendor.token_type"?: "Bearer";
        /**
         * @description __Authentication Payload Mode__: Set how the OAuth 2.0 Client ID and Client Secret should be sent with the Token URL. This must be set to `header`.
         *
         * __Required__ if `is_service_account` is `false`
         *
         * @enum {string}
         */
        "vendor.auth_scheme"?: "header";
        /**
         * @description __API Scopes__: Scopes that should be added to the OAuth token calls. This should be `https://www.googleapis.com/auth/pubsub`.
         *
         * __Required__ if `is_service_account` is `false`
         *
         * @enum {string}
         */
        "vendor.scopes"?: "https://www.googleapis.com/auth/pubsub";
        /**
         * @description __Refresh Token URL__: The OAuth 2.0 Token Refresh URL that is used for fetching a new access token using the current access token and refresh token. This must be `https://www.googleapis.com/oauth2/v4/token`.
         *
         * __Required__ if `is_service_account` is `false`
         *
         * @enum {string}
         */
        "vendor.refresh_url"?: "https://www.googleapis.com/oauth2/v4/token";
        /**
         * @description __Requires Auto-Refresh of Token__:  Access tokens are short-lived, and the platform should automatically continuously refresh the token to retain a valid access token. This must be `true`.
         *
         * __Required__ if `is_service_account` is `false`
         *
         * @enum {boolean}
         */
        "vendor.has_token_expiration_ts"?: true;
        /**
         * @description __Access token expiration time__: Set this to the expiration time (in seconds) of the access token received when you made the first token request as part of the 3-legged OAuth 2.0 token fetching sequence. This is usually `3599` for a 3-legged OAuth workflow.
         *
         * __Required__ if `is_service_account` is `false`
         */
        "vendor.token_expires_in"?: number;
        /**
         * @description __Access Token__: Set this to the access token received when you made the first token request as part of the 3-legged OAuth 2.0 token fetching sequence.
         *
         * __Required__ if `is_service_account` is `false`
         */
        access_token?: string;
        /**
         * @description __Access Token__: Set this to the access token received when you made the first token request as part of the 3-legged OAuth 2.0 token fetching sequence. Note that this is the same as `access_token` above but is required in the payload to allow Nexla to automatically continuously refresh tokens.
         *
         * __Required__ if `is_service_account` is `false`
         */
        "vendor.access_token"?: string;
        /**
         * @description __Refresh Token__: Set this to the refresh token received when you made the first token request as part of the 3-legged OAuth 2.0 token fetching sequence.
         *
         * __Required__ if `is_service_account` is `false`
         */
        "vendor.refresh_token"?: string;
      };
    } & components["schemas"]["stream_data_credential"];
    hana_jdbc_data_credential: {
      credentials_type: "hana_jdbc";
    } & Omit<components["schemas"]["data_credential"], "credentials_type"> & {
      credentials?: {
        /** @description __Host__: Enter the hostname for your database. This is usually an IP address or text in the format `company.domain.com`. Do not include the connection protocol. */
        host: string;
        /** @description __Port__: Enter the port used to access your database. */
        port: number;
        /** @description __Username__: Enter the username used to access your database. */
        username: string;
        /** @description __Password__: Enter the password used to access your database. */
        password: string;
        /** @description __Database Name__: Enter the database name if you want to connect to a specific database. */
        database_name?: string;
      };
    } & components["schemas"]["database_data_credential"];
    hive_data_credential: {
      credentials_type: "hive";
    } & Omit<components["schemas"]["data_credential"], "credentials_type"> & {
      credentials?: {
        /** @description __Host__: Enter the hostname for your database. This is usually an IP address or text in the format `company.domain.com`. Do not include the connection protocol. */
        host: string;
        /**
         * @description __Port__: Enter the port used to access your database.
         *
         * Default value: `10000`
         */
        port: number;
        /** @description __Username__: Enter the username used to access your database. */
        username: string;
        /** @description __Password__: Enter the password used to access your database. */
        password: string;
        /** @description __Schema Name__: Enter the schema name for your database. */
        schema_name: string;
      };
    } & components["schemas"]["database_data_credential"];
    jms_data_credential: {
      credentials_type: "jms";
    } & Omit<components["schemas"]["data_credential"], "credentials_type"> & ({
      credentials?: {
        /**
         * @description __JMS Vendor__: Select the type of vendor for this JMS connector.
         *
         * @enum {string}
         */
        "jms.vendor": "tibco" | "activemq";
        /** @description __Server URL__: Enter the address of the JMS Server. This is usually a Virtual IP address. */
        url: string;
        /** @description __Username__: Enter the username used to access this server. */
        username: string;
        /** @description __Password__: Enter the password used to access this server. */
        password: string;
      };
    }) & components["schemas"]["stream_data_credential"];
    kafka_data_credential: {
      credentials_type: "kafka";
    } & Omit<components["schemas"]["data_credential"], "credentials_type"> & ({
      credentials?: {
        /** @description __Kafka Bootstrap Servers__: Enter the addresses of the Kafka brokers. These are usually in the form of Virtual IP addresses. */
        "target.bootstrap.servers": string;
        /**
         * @description __Security Protocol__: Choose the appropriate security protocol for your Kafka channels.
         *
         * * `PLAINTEXT`: Un-authenticated, non-encrypted channel
         *
         * * `SASL_PLAINTEXT`: SASL-authenticated non-encrypted channel
         *
         * * `SASL_SSL`: SASL-authenticated SSL channel
         *
         * * `SSL`: SSL channel
         *
         * @enum {string}
         */
        "security.protocol": "PLAINTEXT" | "SASL_PLAINTEXT" | "SASL_SSL" | "SSL";
        /**
         * @description __Authentication Configuration (SASL JAAS format)__: Enter the Java Authentication and Authorization Service (JAAS) configuration to be used for SASL Authentication. This is usually in the format `org.apache.kafka.common.security.plain.PlainLoginModule required username=<user_in_quotes> password=<pwd_in_quotes>;`.
         *
         * __Required__ if `security.protocol` is `SASL_PLAINTEXT` or `SASL_SSL`
         */
        "sasl.jaas.config"?: string;
        /**
         * @description __Consumer Group ID__: Enter the  Group ID of the group to which Nexla consumers will belong.
         *
         * This is usually set to `nexla-consumer`.
         */
        "group.id.prefix"?: string;
      };
    }) & components["schemas"]["stream_data_credential"];
    min_io_s3_data_credential: {
      credentials_type: "min_io_s3";
    } & Omit<components["schemas"]["data_credential"], "credentials_type"> & ({
      credentials?: {
        /** @description __MinIO Host__: The custom host URL for MinIO. */
        nx_external_host: string;
        /**
         * @description __Authentication Type__: The authentication mechanism for MinIO.
         *
         * * `min_io_s3`: Use this option to authenticate with MinIO S3.
         *
         * @enum {string}
         */
        "nx_external.auth.type": "min_io_s3";
        /** @description __MinIO S3 Credentials__: Authentication credentials as a JSON string. Should include 'access_key_id' and 'secret_key'. */
        "nx_external.auth.props": string;
        /** @description MinIO Access Key for accessing the MinIO S3 bucket. */
        access_key?: string;
        /** @description MinIO Secret Key for accessing the MinIO S3 bucket. */
        secret_key?: string;
        /** @description __S3 Path list access is limited to__: Set this property to `<bucket-name>` or `<bucket-name>/<folder-name>` if your AWS admin has restricted access to only a specific bucket or a path inside a bucket. */
        "test.path"?: string;
        /**
         * @description __Enable Client Side Encryption?__: The platform can be configured to encrypt/decrypt S3 objects that require client-side encryption using the AWS Key Management System (KMS). Set this option if KMS encryption is applicable.
         *
         * Default value: `false`
         */
        has_client_encryption?: boolean;
        /**
         * @description __Client Side Encryption Mode__: Select the type of KMS encryption mode that is applicable for this credential.
         *
         * __Required__ if `has_client_encryption` is `true`
         *
         * @enum {string}
         */
        encryption_mode?: "EncryptionOnly" | "AuthenticatedEncryption" | "StrictAuthenticatedEncryption";
        /**
         * @description __Amazon KMS Key for Encryption__: The KMS Key used for encrypting/decrypting objects. Please ensure that this user has appropriate KMS permissions.
         *
         * __Required__ if `has_client_encryption` is `true`
         */
        kms_key?: string;
        /**
         * @description __Enable Server Side Encryption?__: The platform can be configured to encrypt/decrypt S3 objects that require server-side encryption.
         *
         * This can be done using either __Amazon S3-managed encryption keys (SSE-S3)__ or the __AWS Key Management Service (SSE-KMS)__. Set this option if server-side encryption is applicable.
         *
         * Default value: `false`
         */
        "sse.enabled"?: boolean;
        /**
         * @description __Key ARN for SSE with KMS__: The Key ARN if you want server-side encryption to be performed via the AWS Key Management System. You can leave this field blank if you want to use Amazon S3-managed encryption keys.
         *
         * __Required__ if `sse.enabled` is `true`
         */
        "sse.kms_key.arn"?: string;
      };
    }) & components["schemas"]["file_data_credential"];
    mongo_data_credential: {
      credentials_type: "mongo";
    } & Omit<components["schemas"]["data_credential"], "credentials_type"> & ({
      credentials?: {
        /**
         * @description __URL Format__: You can enter the MongoDB authentication information as a MongoDB Java Connection URL (Version 3.4 or later) or as parts that will be combined by Nexla to create the connection string.
         *
         * * `connection_url`: __MongoDB Connection URL__ - Enter the MongoDB Java connection URL. For example, in MongoDB Atlas, please select connect your application  Driver: Java  version 3.4 or later.
         *
         * * `http_path_parts`: __HTTP Path Parts__
         *
         * @enum {string}
         */
        "ui.url_format"?: "connection_url" | "http_path_parts";
        /**
         * @description __Connection URL__: Enter the MongoDB Connection URL of your MongoDB instance location. This should be in the form `mongodb://...`.
         *
         * For example, in MongoDB Atlas, please select connect your application  Driver: Java  version 3.4 or later.
         *
         * Note that currently, we only support connection URLs that direct to a specific database, so your connection string must be in the form `mongodb://<user>:<password>@.../<database>?ssl=true...`.
         *
         * __Applicable and Required__ if `ui.url_format` is `connection_url`.
         */
        url?: string;
        /**
         * @description __Host__: Enter the hostname for your database. This is usually an IP address or text in the format __company.domain.com__. Do not include the connection protocol.
         *
         * __Applicable and Required__ if `ui.url_format` is `http_path_parts`.
         */
        host?: string;
        /**
         * @description __Port__: Enter the port number for your database.
         *
         * Default value: `27017`.
         *
         * __Applicable and Required__ if `ui.url_format` is `http_path_parts`.
         */
        port?: number;
        /**
         * @description __Username__: Enter the username for your database.
         *
         * __Applicable and Required__ if `ui.url_format` is `http_path_parts`.
         */
        username?: string;
        /**
         * @description __Password__: Enter the password for your database.
         *
         * __Applicable and Required__ if `ui.url_format` is `http_path_parts`.
         */
        password?: string;
        /**
         * @description __Database__: Limit access to a specific database.
         *
         * __Applicable__ if `ui.url_format` is `http_path_parts`.
         */
        database?: string;
      };
    }) & components["schemas"]["nosql_data_credential"];
    mysql_data_credential: {
      credentials_type: "mysql";
    } & Omit<components["schemas"]["data_credential"], "credentials_type"> & {
      credentials?: {
        /** @description __Host__: Enter the hostname for your database. This is usually an IP address or text in the format `company.domain.com`. Do not include the connection protocol. */
        host: string;
        /** @description __Port__: Enter the port used to access your database. */
        port: number;
        /** @description __Username__: Enter the username used to access your database. */
        username: string;
        /** @description __Password__: Enter the password used to access your database. */
        password: string;
        /** @description __Database Name__: Enter the database name if you want to connect to a specific database. */
        database_name?: string;
      };
    } & components["schemas"]["database_data_credential"];
    netsuite_jdbc_data_credential: {
      credentials_type: "netsuite_jdbc";
    } & Omit<components["schemas"]["data_credential"], "credentials_type"> & {
      credentials?: {
        /** @description __URL__: The database connection URL for Netsuite. */
        url: string;
        /**
         * @description __Access using Token-Based Authentication?__ Enable this checkbox to configure a token-based authentication mechanism. See https://docs.oracle.com/en/cloud/saas/netsuite/ns-online-help/article_163239884825.html for more information.
         *
         * Default value: `false`
         */
        tba_enabled: boolean;
        /**
         * @description __Username__: Enter the username used to access your database.
         *
         * __Applicable and required__  if `tba_enabled` is `false`
         */
        username?: string;
        /**
         * @description __Password__: Enter the password used to access your database.
         *
         * __Applicable and required__  if `tba_enabled` is `false`
         */
        password?: string;
        /**
         * @description __NetSuite account ID__: Your NetSuite account ID. You can find this value on the SuiteAnalytics Connect Driver Download Page under Your Configuration.
         *
         * __Applicable and required__  if `tba_enabled` is `true`
         */
        account_id?: string;
        /**
         * @description __Consumer key__: The consumer key for the integration record. This string was created when you created the integration record.
         *
         * __Applicable and required__  if `tba_enabled` is `true`
         */
        consumer_key?: string;
        /**
         * @description __Consumer Secret__: The consumer secret for the integration record. This string was created when you created the integration record.
         *
         * __Applicable and required__  if `tba_enabled` is `true`
         */
        consumer_secret?: string;
        /**
         * @description __Token__: This is a string identifier or ID of a token that represents a unique combination of a user, a role, and an integration record.
         *
         * __Applicable and required__  if `tba_enabled` is `true`
         */
        token?: string;
        /**
         * @description __Token Secret__: Token Secret generated when the Access Token was created.
         *
         * __Applicable and required__  if `tba_enabled` is `true`
         */
        token_secret?: string;
        /**
         * @description __Server Zone ID__: A timestamp is needed to generate a token password. This timestamp must be within plus or minus five (+ or  5) minutes of the server time. If your server is not in the UTC zone, please specify the correct server time zone.
         *
         * Default value: `UTC`
         *
         * __Applicable__  if `tba_enabled` is `true`
         */
        server_zone_id?: string;
        /** @description __Database Name__: Enter the database name if you want to connect to a specific database. */
        database_name?: string;
        /** @description __Schema Name__: Enter the schema name for the tables in which you are interested. */
        schema_name?: string;
      };
    } & components["schemas"]["database_data_credential"];
    nexla_monitor_data_credential: {
      credentials_type: "nexla_monitor";
    } & Omit<components["schemas"]["data_credential"], "credentials_type">;
    oracle_data_credential: {
      credentials_type: "oracle";
    } & Omit<components["schemas"]["data_credential"], "credentials_type"> & {
      credentials?: {
        /** @description __Host__: Enter the hostname for your database. This is usually an IP address or text in the format `company.domain.com`. Do not include the connection protocol. */
        host: string;
        /** @description __Port__: Enter the port used to access your database. */
        port: number;
        /** @description __Username__: Enter the username used to access your database. */
        username: string;
        /** @description __Password__: Enter the password used to access your database. */
        password: string;
        /** @description __Database Name__: Enter the database name if you want to connect to a specific database. */
        database_name: string;
        /** @description __Schema Name__: Enter the schema name for the tables in which you are interested. */
        schema_name?: string;
      };
    } & components["schemas"]["database_data_credential"];
    oracle_autonomous_data_credential: {
      credentials_type: "oracle_autonomous";
    } & Omit<components["schemas"]["data_credential"], "credentials_type"> & {
      credentials?: {
        /**
         * @description __Oracle Wallet__: Oracle Autonomous connections require a wallet that contains a collection of files, including key and other information required to connect to your database.
         *
         *   Add the content of your Oracle wallet file downloaded from the database. This wallet is a zip file. Encode the zip file content as a Base64-encoded string in the request.
         */
        oracle_wallet: string;
        /** @description __Username__: Enter the username used to access your database. */
        username: string;
        /** @description __Password__: Enter the password used to access your database. */
        password: string;
        /** @description __Database Name__: Enter the database name if you want to connect to a specific database. */
        database_name?: string;
        /** @description __Schema Name__: Enter the schema name for the tables in which you are interested. */
        schema_name?: string;
      };
    } & components["schemas"]["database_data_credential"];
    vector_db_data_credential: {
      credentials?: Record<string, never>;
    };
    pinecone_data_credential: {
      credentials_type: "pinecone";
    } & Omit<components["schemas"]["data_credential"], "credentials_type"> & {
      credentials?: {
        /** @description __API Key__: Enter the API key for your Pinecone account. */
        api_key: string;
      };
    } & components["schemas"]["vector_db_data_credential"];
    postgres_data_credential: {
      credentials_type: "postgres";
    } & Omit<components["schemas"]["data_credential"], "credentials_type"> & {
      credentials?: {
        /** @description __Host__: Enter the hostname for your database. This is in the format `company.domain.com`. Do not include the connection protocol. */
        host: string;
        /** @description __Port__: Enter the port used to access your database. */
        port: number;
        /** @description __Username__: Enter the username used to access your database. */
        username: string;
        /** @description __Password__: Enter the password used to access your database. */
        password: string;
        /** @description __Database Name__: Enter the database name if you want to connect to a specific database. */
        database_name: string;
        /** @description __Schema Name__: Enter the schema name for the tables in which you are interested. */
        schema_name?: string;
      };
    } & components["schemas"]["database_data_credential"];
    redshift_data_credential: {
      credentials_type: "redshift";
    } & Omit<components["schemas"]["data_credential"], "credentials_type"> & {
      credentials?: {
        /** @description __Host__: Enter the hostname for your database. This is usually in the format `[name].[id].[region].redshift.amazonaws.com`. Do not include the connection protocol. */
        host: string;
        /** @description __Port__: Enter the port used to access your database. */
        port: number;
        /** @description __Username__: Enter the username used to access your database. */
        username: string;
        /** @description __Password__: Enter the password used to access your database. */
        password: string;
        /** @description __Database Name__: Enter the database name if you want to connect to a specific database. */
        database_name: string;
        /** @description __Schema Name__: Enter the schema name for the tables in which you are interested. */
        schema_name?: string;
      };
    } & components["schemas"]["database_data_credential"];
    rest_data_credential: {
      credentials_type: "rest";
    } & Omit<components["schemas"]["data_credential"], "credentials_type"> & ({
      credentials?: {
        /**
         * @description __Authentication Mechanism__: Credentials can be configured to allow API access through different rest connector authentication mechanisms supported by the API. Select the authentication mechanism that is best suited for your use case.
         *
         * __Tips__:
         *
         * 1. Select `NONE` if it is a public API.
         *
         * 2. Select `NONE` and set appropriate `request.headers` if the API requires hardcoded headers.
         *
         * 3. If the API requires API Key in header, while the option above will work, we recommend selecting `API_KEY` and setting appropriate options for how API Key is included in Header.
         *
         * 3. Select `OAUTH2` for 2-legged or 3-legged Oauth2 Authentication.
         *
         * 4. Choose appropriate settings if the API also requires `JWT` or `HMAC` signature verification.
         *
         * __Values__:
         * * `NONE`: __No Auth Mode__ Use this mode if the API does not require any authentication, or if the authentication information is sent as custom request headers or url query parameters.
         *
         * * `BASIC`: __Basic Auth__ - Use this mode for any API that requires a verified username and password to be sent with every request. This username password is sent as `Basic <base-64 encoded username:password>` on the Authorization request header.
         *
         * * `API_KEY`: __Api Key__ - Use this mode for any API that a key-value api key pair to be sent with every request, either as a Request Header or a Query parameter.
         *
         * * `TOKEN`: __Token__ - Use this mode for any API that requires fetching a short-lived token before authenticated calls can be made for other endpoints.
         *
         * * `OAUTH1`: __OAuth 1.0__ - Use this mode for any API that requires multi-step OAuth1.0 based authentication workflow. Nexla supports 2-legged and 3-legged OAuth workflows and has ability to automatically refresh short-lived tokens.
         *
         * * `OAUTH2`: __OAuth 2.0__ - Use this mode for any API that requires multi-step OAuth2.0 based authentication workflow. Nexla supports 2-legged and 3-legged OAuth workflows and has ability to automatically refresh short-lived tokens.
         *
         * * `AWS_SIGNATURE`: __AWS Signature__ - Use this authorization workflow for Amazon Web Services requests. This is a special type of HMAC (Hash Message Authentication Code) authentication specifically for AWS.
         *
         * * `gcp_service_account`: __Google Service Account__ - Use this authorization workflow for Google Service Account authentication.
         *
         * @enum {string}
         */
        "auth.type": "NONE" | "BASIC" | "API_KEY" | "TOKEN" | "OAUTH1" | "OAUTH2" | "AWS_SIGNATURE" | "gcp_service_account";
        /**
         * @description __Username__: Enter the username field for basic authentication. Nexla will automatically combine this with the password and Base64-encode the pair.
         *
         * __Applicable and required__ if `auth.type` is `BASIC` or `TOKEN`
         */
        "basic.username"?: string;
        /**
         * @description __Password__: Enter the password field for basic authentication. Nexla will automatically combine this with the username and Base64-encode the pair.
         *
         * __Applicable and required__ if `auth.type` is `BASIC` or `TOKEN`
         */
        "basic.password"?: string;
        /**
         * @description __Where to add api key on API requests__: Configure how the api key should be included in subsequent requests.
         *
         * __Applicable and required__ if `auth.type` is `API_KEY`
         *
         * @enum {string}
         */
        "api.key.include.mode"?: "HEADER" | "URL_PARAMETER";
        /**
         * @description __API Key Parameter Name__: If the API Key is sent as __URL_PARAMETER__: Enter the URL query parameter name that is used for sending the API Key as a URL parameter.
         *
         * If the API Key is sent as __Header__: Enter the request header name that should be used for sending the API Key.
         *
         * __Applicable and required__ if `auth.type` is `API_KEY`
         */
        "api.key.auth.key"?: string;
        /**
         * @description __API Key Parameter Value__: If the API Key is sent as __URL_PARAMETER__: Enter the value that should be sent with the API Key Parameter Name query parameter.
         *
         * If the API Key is sent as __Header__: Enter the Header value that should be sent with the API Key Parameter Name request header.
         *
         *
         * __Applicable and required__ if `auth.type` is `API_KEY`
         */
        "api.key.auth.value"?: string;
        /**
         * @description __Fetch Token URL: URL to get token__: Enter the Token URL that should be accessed to fetch a token from the API token server.
         *
         * __Applicable and required__ if `auth.type` is `TOKEN`
         */
        "token.auth.url"?: string;
        /**
         * @description __Fetch Token URL: HTTP method__: URL to get token__: Enter the request method for the Token URL. This is usually `POST`.
         *
         * __Applicable and required__ if `auth.type` is `TOKEN`
         *
         * @enum {string}
         */
        "token.auth.method"?: "GET" | "POST" | "PUT";
        /**
         * @description __Fetch Token URL: Header name for user/pwd__: Enter the name of the request header if the token URL requires authentication information like the username/password to be sent in a header when requesting a token.
         *
         * __Applicable and required__ if `auth.type` is `TOKEN`
         */
        "token.auth.token.header.name"?: string;
        /**
         * @description __Fetch Token URL: Request Body__: Enter the request body in JSON-object format if the token URL requires a payload to be sent when fetching a token.
         *
         * __Applicable and required__ if `auth.type` is `TOKEN`
         */
        "token.auth.body"?: string;
        /**
         * @description __Fetch Token URL: Response format__: Select the response format of the Token URL request.
         *
         * This is usually `json`
         *
         * __Applicable and required__ if `auth.type` is `TOKEN`
         *
         * @enum {string}
         */
        "token.auth.response.format"?: "xml" | "json" | "plain";
        /**
         * @description __Fetch Token URL Response: Path to Token__: Enter the path of the token property in the response.
         *
         * This should be a valid __JSON Path__ or __XPath__ input depending on the __Fetch Token URL: Response format__
         *
         *
         * __Applicable and required__ if `auth.type` is `TOKEN` and `token.auth.response.format` is `xml` or `json`
         */
        "token.auth.token.path"?: string;
        /**
         * @description __Where to add token on API requests__: Configure how the generated token should be included in subsequent requests.
         *
         * This is usually `HEADER`
         *
         * __Applicable and required__ if `auth.type` is `TOKEN`
         *
         * @enum {string}
         */
        "token.auth.token.include.mode"?: "HEADER" | "URL_PARAMETER";
        /**
         * @description __URL Parameter for Token in API Requests__: If the token is sent as a __URL_PARAMETER__, enter the URL parameter name used to send the token as a URL parameter.
         *
         * __Applicable and required__ if `auth.type` is `TOKEN` and  `token.auth.token.include.mode` is `URL_PARAMETER`
         */
        "token.auth.token.url.parameter"?: string;
        /**
         * @description __Header Name for Token in API Requests__: If the token is sent as a __Header__, enter the header name used to send the token.
         *
         * __Applicable and required__ if `auth.type` is `TOKEN` and  `token.auth.token.include.mode` is `HEADER`
         *
         * Usually, this is `Authorization`
         */
        "token.auth.request.header.name"?: string;
        /**
         * @description __Send cookie in a header?__: If the `token.auth.token.include.mode` is set to `Header`, the platform can be configured to send a cookie together with a token in a request header. Set this option if the vendor requires a cookie for generating a token.
         *
         * __Applicable__ if `auth.type` is `TOKEN` and  `token.auth.token.include.mode` is `HEADER`.
         *
         * Default: `false`
         */
        "token.auth.token.include.cookie"?: boolean;
        /**
         * @description __Header Prefix for Token in API Requests__: If the token is sent as a __Header__, enter the prefix (if applicable) that should be prepended to the header value.
         *
         * __Applicable and required__ if `auth.type` is `TOKEN` and  `token.auth.token.include.mode` is `HEADER`.
         *
         * Usually, this is `Bearer`.
         */
        "token.auth.request.header.prefix"?: string;
        /**
         * @description __Type of OAuth1 Exchange__: Choose whether the OAuth token exchange should be 2-legged (i.e., server-server) or 3-legged (i.e., involving end-user authentication from the UI).
         *
         * __Note__: 3-legged OAuth clients require a Redirect URL when setting up the client. Make sure you have set `<your-nexla-ui-url>/oauth1Auth` as the redirect URL when setting up the client. Replace  `<your-nexla-ui-url>` with the root URL of your Nexla site.
         *
         * __Applicable and required__ if `auth.type` is `OAUTH1`
         *
         * @enum {string}
         */
        "oauth1.token_exchange_type"?: "2-legged" | "3-legged";
        /**
         * @description __URL for Request Token__: Enter the OAuth 1.0 Request URL used for fetching the request token. This is the first step of the 3-legged OAuth1.0 flow.
         *
         * __Applicable and required__ if `auth.type` is `OAUTH1` and `oauth1.token_exchange_type` is `3-legged`
         */
        "oauth1.request.url"?: string;
        /**
         * @description __(Optional) Request Token URL Parameters__: Enter any optional parameters that should be attached to the Request URL.
         *
         * This should be in the form `key1=value1&key2=value2`. You __do not__ need to include the `oauth_callback` and `oauth_consumer_key`.
         *
         * __Applicable__ if `auth.type` is `OAUTH1` and `oauth1.token_exchange_type` is `3-legged`
         */
        "oauth1.request_url.req_url_params"?: string;
        /**
         * @description __Authorization URL__: Enter the OAuth 1.0 Authorization URL used to initiate user authorization. This is the second step of the 3-legged OAuth1.0 flow.
         *
         * __Applicable and required__ if `auth.type` is `OAUTH1` and `oauth1.token_exchange_type` is `3-legged`
         */
        "oauth1.auth.url"?: string;
        /**
         * @description __(Optional) Authorization URL Parameters__: Enter any optional parameters that should be attached to the Authorization URL.
         *
         * This should be in the form `key1=value1&key2=value2`. You __do not__ need to include properties that are autogenerated or received in previous steps.
         *
         * __Applicable__ if `auth.type` is `OAUTH1` and `oauth1.token_exchange_type` is `3-legged`
         */
        "oauth1.auth_url.auth_url_params"?: string;
        /**
         * @description __Access Token URL__: Enter the OAuth 1.0 Token URL used to convert the request token into an access token. This is the final step of the 3-legged OAuth1.0 flow.
         *
         * __Applicable and required__ if `auth.type` is `OAUTH1` and `oauth1.token_exchange_type` is `3-legged`
         */
        "oauth1.token.url"?: string;
        /**
         * @description __(Optional) Access Token URL Parameters__: Enter any optional parameters that should be attached to the Token URL.
         *
         * This should be in the form `0key1=value1&key2=value2`. You __do not__ need to include properties that are autogenerated or received in previous steps.
         *
         * __Applicable__ if `auth.type` is `OAUTH1` and `oauth1.token_exchange_type` is `3-legged`
         */
        "oauth1.token_url.token_url_params"?: string;
        /**
         * @description __Signature Method__: Some API vendors require requests to be signed with a dynamic signature algorithm. Select the signature method that should be used to sign the requests.
         *
         * Default Value: `PLAINTEXT`
         *
         * __Applicable and required__ if `auth.type` is `OAUTH1`
         *
         * @enum {string}
         */
        "oauth1.signature.method"?: "PLAINTEXT" | "HMAC-SHA1" | "HMAC-SHA256";
        /**
         * @description __Consumer Key__: Enter the consumer key for your OAuth 1.0 client.
         *
         * __Applicable and required__ if `auth.type` is `OAUTH1`
         */
        "oauth1.consumer.key"?: string;
        /**
         * @description __Consumer Secret__: Enter the consumer secret for your OAuth 1.0 client.
         *
         * __Applicable and required__ if `auth.type` is `OAUTH1`
         */
        "oauth1.consumer.secret"?: string;
        /**
         * @description __Access Token__: Enter the access token for your OAuth 1.0 client.
         *
         * __Applicable and required__ if `auth.type` is `OAUTH1`
         */
        "oauth1.access.token"?: string;
        /**
         * @description __Access Token Secret__: Enter the access token secret for your OAuth 1.0 client.
         *
         * __Applicable and required__ if `auth.type` is `OAUTH1`
         */
        "oauth1.access.token.secret"?: string;
        /**
         * @description __OAuth1 Advanced Configuration (JSON)__: Enter any other advanced configuration parameters like Realm, Version, etc. that might be required. This information should be entered as a valid JSON object.
         *
         * Default Value: `{}`
         *
         * __Applicable__ if `auth.type` is `OAUTH1`
         */
        "oauth1.extra.parameters"?: string;
        /**
         * @description __Type of OAuth2 Exchange__: Choose whether the OAuth token exchange should be 2-legged (i.e., server-server) or 3-legged (i.e., involving end-user authentication from the UI).
         *
         * __Note__: 3-legged OAuth clients require a Redirect URL when setting up the client. Make sure you have set `<your-nexla-ui-url>/oauth2Auth` as the redirect URL when setting up the client. Replace `<your-nexla-ui-url>` with the root URL of this site.
         *
         * __Applicable and required__ if `auth.type` is `OAUTH2`
         */
        "oauth2.token_exchange_type"?: string;
        /**
         * @description __Client ID__: Enter the Client ID for your OAuth 2.0 client.
         *
         * __Applicable and required__ if `auth.type` is `OAUTH2`
         */
        "oauth2.client.id"?: string;
        /**
         * @description __Client Secret__: Enter the Client Secret for your OAuth 2.0 client.
         *
         * __Applicable and required__ if `auth.type` is `OAUTH2`
         */
        "oauth2.client.secret"?: string;
        /**
         * @description __Authorization URL__: Enter the OAuth 2.0 Authorization URL used to initiate user authorization. This is the first step of the 3-legged OAuth1.0 flow.
         *
         * __Applicable and required__ if `auth.type` is `OAUTH2` and `oauth2.token_exchange_type` is `3-legged`
         */
        "oauth2.auth.url"?: string;
        /**
         * @description __(Optional) Authorization Parameters__: Enter any optional parameters that should be attached to the Authorization URL.
         *
         * This should be in the form `key1=value1&key2=value2`. You __do not__ need to include properties like the __client_id__, __grant_type__, or __client_secret__.
         *
         * __Applicable__ if `auth.type` is `OAUTH2` and `oauth2.token_exchange_type` is `3-legged`
         */
        "oauth2.auth_url.auth_url_params"?: string;
        /**
         * @description __Access Token URL__: Enter the OAuth 2.0 Token URL used for fetching tokens from the API token server.
         *
         * __Applicable and required__ if `auth.type` is `OAUTH2`
         */
        "oauth2.access.token.url"?: string;
        /**
         * @description __(Optional) Access Token URL Parameters__: Enter any optional parameters that should be attached to the Authorization URL.
         *
         * This should be in the form `key1=value1&key2=value2`. You __do not__ need to include properties like the __client_id__, __grant_type__, or __client_secret__.
         *
         * __Applicable__ if `auth.type` is `OAUTH2` and `oauth2.token_exchange_type` is `3-legged`
         */
        "oauth2.token_url.token_url_params"?: string;
        /**
         * @description __Token Type__: Enter the token type that should be used when attaching the OAuth2.0 token to the request.
         *
         * This is usually set to `Bearer` to indicate a Bearer token, although some API vendors might use a different name or case.
         *
         * __Applicable and required__ if `auth.type` is `OAUTH2`
         */
        "oauth2.token.type.override"?: string;
        /**
         * @description __Access Token URL method__: Enter the request method used for the OAuth 2.0 Token URL. This is usually `POST`.
         *
         * __Applicable and required__ if `auth.type` is `OAUTH2`
         *
         * @enum {string}
         */
        "oauth2.access.token.method"?: "GET" | "POST";
        /**
         * @description __Authentication Payload Mode__: Select how the OAuth2 Client ID and Client Secret should be sent with the Token URL.
         *
         * * `header`: __Encoded Header__ - The OAuth client ID and secret information is attached to the Authentication header as a Base-64 encoded pair.
         *
         * * `form`: __Form Data__ - The OAuth client ID and secret information are attached in the form of data payload parameters.
         *
         * *  `query`: __Query Parameters__ - The OAuth client ID and secret information are attached to the Token query as query parameters.
         *
         * __Applicable and required__ if `auth.type` is `OAUTH2`. Usually, this is `header`.
         *
         * @enum {string}
         */
        "oauth2.client.auth.scheme"?: "header" | "form" | "query";
        /**
         * @description __OAuth2: Token Request Body__: Nexla automatically includes standard OAuth2 token URL payload properties like __grant_type__, __client_id__ and __client_secret__. However, sometimes, OAuth servers require additional custom payload properties to be sent with the token URL request.
         *
         * Enter these __additional__ properties in the form of a JSON dictionary.
         *
         *  __Applicable__ if `auth.type` is `OAUTH2`and `oauth2.token_exchange_type` is `2-legged`
         */
        "oauth2.auth.body"?: string;
        /**
         * @description __OAuth2: Token Request Headers__: Sometimes OAuth servers require additional custom headers to be sent with the token URL request.
         *
         * Add any additional request headers that must be sent as part of token obtaining request. Please input as comma-separated values e.g header1:value1,header2:value2.
         *
         *  __Applicable__ if `auth.type` is `OAUTH2`and `oauth2.token_exchange_type` is `2-legged`
         */
        "oauth2.auth.headers"?: string;
        /**
         * @description __Access Token__: Set this to the access token received when you made the first token request as part of the 3-legged OAuth 2.0 token fetching sequence.
         *
         * __Applicable and required__ if `auth.type` is `OAUTH2`
         */
        "oauth2.access.token"?: string;
        /**
         * @description __Requires Auto-Refresh of Token__: Enable this option if the access tokens are short-lived and the platform should automatically continuously refresh the token to retain a valid access token.
         *
         *  __Applicable __ if `auth.type` is `OAUTH2`
         *
         *  Default value: `false`
         */
        "vendor.has_token_expiration_ts"?: boolean;
        /**
         * @description __Nexla OAuth 2.0 connector codename__: Codename for the Nexla token refresh mechanism, which is used to identify this connector. Give any string value if this is a custom OAuth2.0 connector.
         *
         * __Applicable and required__ if `auth.type` is `OAUTH2` and `vendor.has_token_expiration_ts` is `true`
         */
        "vendor.name"?: string;
        /**
         * @description __Access token expiration time__: Set this to the expiration time (in seconds) of the access token received when you made the first token request as part of the 3-legged OAuth 2.0 token fetching sequence. This is usually `3599` for a GCS 3-legged OAuth workflow.
         *
         * __Applicable and required__ if `auth.type` is `OAUTH2` and `vendor.has_token_expiration_ts` is `true`
         */
        "vendor.token_expires_in"?: number;
        /**
         * @description __Token Type__: Enter the token type that should be used when attaching the OAuth2.0 token to the request.
         *
         * This is usually set to `Bearer` to indicate a Bearer token, although some API vendors might use a different name or case.
         *
         *  __Applicable __ if `auth.type` is `OAUTH2` and `oauth2.token_exchange_type` is `3-legged`
         */
        "vendor.token_type"?: string;
        /** @description __(Optional) API Scopes__: Enter any additional scopes that should be added to the OAuth token calls. These should be added as space-separated values (`scope1 scope2 scope3`). Nexla will automatically attach them to the request as the `scope` payload property. */
        "vendor.scopes"?: string;
        /**
         * @description __Refresh Token URL__: Enter the OAuth 2.0 Token Refresh URL used for fetching a new access token using the current access token and refresh token. This is usually the same as the OAuth2.0 Token URL.
         *
         * __Applicable and required__ if `auth.type` is `OAUTH2` and `vendor.has_token_expiration_ts` is `true`
         */
        "vendor.refresh_url"?: string;
        /**
         * @description __Authentication Payload Mode__: Select how the OAuth2 Client ID and Client Secret should be sent with the Token URL.
         *
         * * `header`: __Encoded Header__ - The OAuth client ID and secret information are attached to the Authentication header as a Base-64 encoded pair.
         *
         * * `form`: __Form Data__ -  The OAuth client ID and secret information are attached in the form of data payload parameters.
         *
         * *  `query`: __Query Parameters__ - The OAuth client ID and secret information are attached to the Token query as query parameters.
         *
         * __Applicable and required__ if `auth.type` is `OAUTH2` and `vendor.has_token_expiration_ts` is `true`
         *
         * @enum {string}
         */
        "vendor.auth_scheme"?: "header" | "form" | "query";
        /**
         * @description __Access Token__: Set this to the access token received when you made the first token request as part of the 3-legged OAuth 2.0 token fetching sequence. Note that this is the same as `access_token` above but is required in the payload to allow Nexla to automatically continuously refresh tokens.
         *
         * __Applicable and required__ if `auth.type` is `OAUTH2` and `vendor.has_token_expiration_ts` is `true`
         */
        "vendor.access_token"?: string;
        /**
         * @description __Refresh Token__: Set this to the refresh token received when you made the first token request as part of the 3-legged OAuth 2.0 token fetching sequence.
         *
         * __Applicable and required__ if `auth.type` is `OAUTH2` and `vendor.has_token_expiration_ts` is `true`
         */
        "vendor.refresh_token"?: string;
        /**
         * @description __AWS Access Key__: The access key id of the Access Key pair that is used for verifying the identity of the requesting user.
         *
         * __Applicable and required__ if `auth.type` is `AWS_SIGNATURE`.
         */
        "aws.access.key"?: string;
        /**
         * @description __AWS Secret Key__: The access secret of the Access Key pair that is used for verifying the identity of the requesting user.
         *
         * __Applicable and required__ if `auth.type` is `AWS_SIGNATURE`.
         */
        "aws.secret.key"?: string;
        /**
         * @description __AWS Region__: The region that is receiving the request.
         *
         * __Applicable and required__ if `auth.type` is `AWS_SIGNATURE`.
         */
        "aws.region"?: string;
        /**
         * @description __Service Name__: The service that is receiving the request.
         *
         * __Applicable and required__ if `auth.type` is `AWS_SIGNATURE`.
         */
        "aws.service"?: string;
        /**
         * @description __Session Token__: Optional session token if the request requires temporary security credentials. This is added to the request as `x-amz-access-token` request header.
         *
         * __Applicable__ if `auth.type` is `AWS_SIGNATURE`.
         */
        "aws.session.token"?: string;
        /**
         * @description __Google Service Account Credentials JSON__: Enter the content of the Service Content JSON file that was was generated by Google Cloud IAM. This should be a valid JSON object
         *
         * __Applicable and required__ if `auth.type` is `gcp_service_account`.
         */
        "gcp.service.account.credentials.json"?: string;
        /**
         * @description __Google Service Account OAuth Scopes__: Enter the OAuth 2.0 Scopes for Google APIs when using GCP Service Account authentication. This should be a comma separated string of one or more scopes.
         *
         * __Applicable__ if `auth.type` is `gcp_service_account`.
         */
        "gcp.service.account.oauth.scopes"?: string;
        /**
         * @description __Skip Credential Validation__: Turn this option on to skip validation of credential when the credential is being created. Note that credential validation is still done when the credential is used as part of a source/destination. However, sometimes some APIs don't have a good endpoint that can be used for just testing if the credential information is accurate or not. This optional property helps avoid setting `test.url` properties for such API vendors.
         *
         * __Default__: `false`
         */
        "skip.validation"?: boolean;
        /**
         * @description __Credential Validation: URL__: Enter a URL from this API vendor that should be used to check whether or not the authentication mechanism works.
         *
         * 1. This does not need to be the same URL as the final endpoint that you wish to use.
         *
         * 2. We recommend using an endpoint that does not incur a noticeable response delay from the API server. For example, fetch only one item if accessing an endpoint that sends an array of items.
         *
         * 3. Use any public endpoint if you want to bypass credential validation.
         *
         * __Applicable and required__ if `skip.validation` is `false` or not specified.
         */
        "test.url": string;
        /**
         * @description __Credential Validation: API Method__: Enter the API method used to execute the __Credential Validation: URL__. Usually, you should set this to GET for record fetching.
         *
         * __Applicable and required__ if `skip.validation` is `false` or not specified.
         *
         * @enum {string}
         */
        "test.method": "GET" | "POST";
        /**
         * @description __Credential Validation: Request Body__: Enter the request body in JSON-object format if the __Credential Validation: URL__ requires a payload.
         *
         * __Applicable and required__ if `skip.validation` is `false` or not specified.
         */
        "test.body"?: string;
        /**
         * @description Credential Validation: Content type
         *
         * Usually, this is `application/json`.
         *
         * __Applicable and required__ if `skip.validation` is `false` or not specified.
         *
         * @enum {string}
         */
        "test.content.type": "application/atom+xml" | "application/x-www-form-urlencoded" | "application/json" | "application/json;charset=UTF-8" | "application/octet-stream" | "application/pdf" | "application/problem+json" | "application/problem+json;charset=UTF-8" | "application/problem+xml" | "application/rss+xml" | "application/stream+json" | "application/xhtml+xml" | "application/xml";
        /** @description __Additional Request Headers__: Add any additional request headers that must be sent as part of every request. Please input these headers as comma-separated values. E.g., `header1:value1,header2:value2`. */
        "request.headers"?: string;
        /**
         * @description __Ignore SSL certificate validation?__: Enable this option if you need to allow an insecure SSL server connection by bypassing the SSL certificate validation of the API endpoint.
         *
         * This is only needed if the API vendor's SSL Certificate has expired.
         *
         * Default value: `false`
         */
        "ignore.ssl.cert.validation"?: boolean;
        /**
         * @description __Enable JWT Authentication?__: Sometimes, API vendors require JWT-based authorization as an added security layer in addition to the normal authentication methods. For example, vendors requiring __OAuth authentication__ might use the additional __JWT assertion__ part of the OAuth specification.
         *
         * Select this option and configure the associated properties only if the API vendor requires this authentication mechanism.
         *
         * Default value: `false`
         */
        "jwt.enabled"?: boolean;
        /**
         * @description __JWT: Token URL__: Enter the token URL that must be called to initiate JWT authentication.
         *
         * __Required__ if `jwt.enabled` is `true`
         */
        "jwt.auth.url"?: string;
        /**
         * @description __JWT: Token URL Request Body__: Enter the request body for the JWT token URL. This must be entered as a valid JSON object.
         *
         * You can use the `{token}` macro to dynamically substitute the JWT value.
         *
         * __Applicable__ if `jwt.enabled` is `true`
         */
        "jwt.auth.body"?: string;
        /**
         * @description __JWT: Token URL Content type__: Enter the content type for the JWT Token URL.
         *
         * Usually, this is `application/x-www-form-urlencoded`.
         *
         * __Applicable__ if `jwt.enabled` is `true`
         *
         * @enum {string}
         */
        "jwt.auth.content.type"?: "application/atom+xml" | "application/x-www-form-urlencoded" | "application/json" | "application/json;charset=UTF-8" | "application/octet-stream" | "application/pdf" | "application/problem+json" | "application/problem+json;charset=UTF-8" | "application/problem+xml" | "application/rss+xml" | "application/stream+json" | "application/xhtml+xml" | "application/xml";
        /**
         * @description __JWT: Token Response Format__: Enter the response format of the JWT Token URL request.
         *
         * This is usually `json` or `xml`.
         *
         * __Applicable__ if `jwt.enabled` is `true`
         *
         * @enum {string}
         */
        "jwt.auth.response.format"?: "xml" | "json" | "plain";
        /**
         * @description __JWT: Path to Token__: Enter the path of the token property in the response.
         *
         * This should be a valid __JSON Path__ or __XPath__ input depending on the __JWT: Token Response Format__.
         *
         * __Applicable__ if `jwt.enabled` is `true`
         */
        "jwt.auth.token.path"?: string;
        /**
         * @description __JWT: Path to Token Type__: Enter the path of the token-type property in the response.
         *
         * This should be a valid __JSON Path__ or __XPath__ input depending on the __JWT: Token Response Format__.
         *
         * __Applicable__ if `jwt.enabled` is `true`
         */
        "jwt.auth.token.type.path"?: string;
        /**
         * @description __JWT: Token Include Mode__: Configure how the generated JWT token should be included in subsequent requests.
         *
         * __Applicable__ if `jwt.enabled` is `true`
         *
         * @enum {string}
         */
        "jwt.token.include.mode"?: "HEADER" | "URL_PARAMETER";
        /**
         * @description __JWT: Token URL parameter__: If the __Token Include Mode__ is __URL_PARAMETER__, enter the URL parameter name used to send the JWT token as a URL parameter.
         *
         * __Applicable__ if `jwt.enabled` is `true` and `jwt.token.include.mode` is `URL_PARAMETER`
         */
        "jwt.token.url.parameter"?: string;
        /**
         * @description __JWT: Token Header Name__: If the __Token Include Mode__ is __Header__, enter the request header name used to send the JWT token as a header.
         *
         * __Applicable__ if `jwt.enabled` is `true` and `jwt.token.include.mode` is `HEADER`
         */
        "jwt.token.header"?: string;
        /** @description __JWT: Token Header Type Prefix__: If the __Token Include Mode__ is __Header__, enter the prefix (if applicable) that should be prepended to the header value. */
        "jwt.token.header.type"?: string;
        /**
         * @description __JWT: Token Expiration Duration(sec)__: Enter the duration in seconds over which the JWT token is valid.
         *
         * __Applicable__ if `jwt.enabled` is `true`
         */
        "jwt.claim.expiration.sec"?: number;
        /**
         * @description __JWT: Token Secret__: Enter the secret key used to sign the JWT request and payload.
         *
         * This is not always required.
         *
         * __Applicable__ if `jwt.enabled` is `true`
         */
        "jwt.token.secret"?: string;
        /**
         * @description __JWT: Signature Algorithm__: Select the algorithm used to generate the JWT token signature.
         *
         * This is usually `HS256`.
         *
         * __Applicable__ if `jwt.enabled` is `true`
         *
         * @enum {string}
         */
        "jwt.token.algorithm"?: "NONE" | "HS256" | "HS384" | "HS512" | "RS256" | "RS384" | "RS512" | "ES256" | "ES384" | "ES512" | "PS256" | "PS384" | "PS512";
        /**
         * @description __JWT: Scope Claim__: Enter the value of the scope claim used for token generation.
         *
         * __Applicable__ if `jwt.enabled` is `true`
         */
        "jwt.claim.scope"?: string;
        /**
         * @description __JWT: Audience Claim__: Enter the value of the audience claim used for token generation.
         *
         * __Applicable__ if `jwt.enabled` is `true`
         */
        "jwt.claim.audience"?: string;
        /**
         * @description __JWT: Issuer Claim__: Enter the value of the issuer claim used for token generation.
         *
         * __Applicable__ if `jwt.enabled` is `true`
         */
        "jwt.claim.issuer"?: string;
        /**
         * @description __JWT: Extra Claims__: In addition to the standard claims of __audience__, __scope__ and __issuer__, you can also configure extra claims that must be verified.
         *
         * Enter any extra claims here. The input should be entered in the form of a valid JSON object.
         *
         * __Applicable__ if `jwt.enabled` is `true`
         */
        "jwt.claim.extra.json"?: string;
        /**
         * @description __Enable HMAC Signature Based Authentication?__: Select this mode if the API vendor requires requests to be signed with a Signature generated using a custom HMAC algorithm.
         *
         * Provide details about the signature-generation algorithm in the associated input fields.
         *
         * Default value: `false`
         */
        "hmac.enabled"?: boolean;
        /**
         * @description __HMAC: API Key__: Enter the API key that will be used to sign requests. This is provided by the API vendor.
         *
         * __Applicable__ if `hmac.enabled` is `true`
         */
        "hmac.api.key"?: string;
        /**
         * @description __HMAC: API Secret__: API vendors often require an API secret to also be used for HMAC signature authentication. Check the vendor's API documentation for more information.
         *
         * __Applicable__ if `hmac.enabled` is `true`
         */
        "hmac.api.secret"?: string;
        /**
         * @description __HMAC: Signature Generator Function__: Enter the signature generator function that will generate the appropriate signature for each request.
         *
         * We currently support the __Base64-Encoded Scala function__ for generating HMAC signatures.
         *
         * Please contact your Nexla Account Manager for assistance with this input.
         *
         * __Applicable__ if `hmac.enabled` is `true`
         */
        "hmac.func"?: string;
        /**
         * @description __Sign Requests with Certificates?__: Select this mode if the API vendor requires requests to be signed with a shared certificate.
         *
         * Provide details about the certificate in the associated input fields.
         *
         * Default value: `false`
         */
        "ui.cert_signed"?: boolean;
        /**
         * @description __Client Certificate in P12 format__: Enter the content of the P12-formatted certificate file that will be used to sign the API requests.
         *
         * The P12 file typically consists of the private key and certificate chain. You can open the file in any text editor and copy its content here.
         *
         *
         * __Applicable and required__ if `ui.cert_signed` is `true`
         */
        "client.p12"?: string;
        /**
         * @description __P12 PassPhrase__: Enter the passphrase associated with the certificate file.
         *
         * __Applicable__ if `ui.cert_signed` is `true`
         */
        "client.p12.password"?: string;
      };
    });
    s3_data_credential: {
      credentials_type: "s3";
    } & Omit<components["schemas"]["data_credential"], "credentials_type"> & ({
      credentials?: {
        /**
         * @description __Authentication Mechanism__ Credentials can be configured to allow S3 access through different AWS permissions mechanisms. Select the type of Authentication method you wish to use.
         * * `Access Key` - Select this option if you wish to use AWS Access and Secret keys for your S3.
         * * `ARN` - Select this option if you wish to use IAM ARN for authentication.
         * * `Instance Role` - Select this option if you wish to access S3 using an IAM Instance Role.
         * @enum {string}
         */
        s3_auth_type: "Access Key" | "ARN" | "Instance Role";
        /**
         * @description __AWS Access Key__
         *
         * __Required__ if `s3_auth_type` is `Access Key`
         */
        access_key?: string;
        /**
         * @description __AWS Secret Key__
         *
         * __Required__ if `s3_auth_type` is `Access Key`
         */
        secret_key?: string;
        /**
         * @description __External Id__: The external ID if S3 has been configured for federated access.
         *
         * __Required__ if `s3_auth_type` is `ARN`
         */
        external_id?: string;
        /**
         * @description Region for AWS S3 Account.
         *
         * Default value: `us-east-1`
         */
        region?: string;
        /** @description __IAM ARN__: The IAM Amazon Resource Name (ARN) for which these permissions are applicable. This should be entered in the format `arn:partition:service:region:account:resource`. */
        arn?: string;
        /** @description __S3 Path list access is limited to__: Set this property to `<bucket-name>` or `<bucket-name>/<folder-name>` if your AWS admin has restricted access to only a specific bucket or a path inside a bucket. */
        "test.path"?: string;
        /**
         * @description __Enable Client Side Encryption?__: The platform can be configured to encrypt/decrypt S3 objects that require client-side encryption using the AWS Key Management System (KMS). Set this option if KMS encryption is applicable.
         *
         * Default value: `false`
         */
        has_client_encryption?: boolean;
        /**
         * @description __Client Side Encryption Mode__: Select the type of KMS encryption mode that is applicable for this credential.
         *
         * __Required__ if `has_client_encryption` is `true`
         *
         * @enum {string}
         */
        encryption_mode?: "EncryptionOnly" | "AuthenticatedEncryption" | "StrictAuthenticatedEncryption";
        /**
         * @description __Amazon KMS Key for Encryption__: The KMS Key used for encrypting/decrypting objects. Please ensure that this user has appropriate KMS permissions.
         *
         * __Required__ if `has_client_encryption` is `true`
         */
        kms_key?: string;
        /**
         * @description __Enable Server Side Encryption?__: The platform can be configured to encrypt/decrypt S3 objects that require server-side encryption.
         *
         * This can be done using either __Amazon S3-managed encryption keys (SSE-S3)__ or the __AWS Key Management Service (SSE-KMS)__. Set this option if server-side encryption is applicable.
         *
         * Default value: `false`
         */
        "sse.enabled"?: boolean;
        /**
         * @description __Key ARN for SSE with KMS__: The Key ARN if you want server-side encryption to be performed via the AWS Key Management System. You can leave this field blank if you want to use Amazon S3-managed encryption keys.
         *
         * __Required__ if `sse.enabled` is `true`
         */
        "sse.kms_key.arn"?: string;
      };
    }) & components["schemas"]["file_data_credential"];
    s3_iceberg_data_credential: {
      credentials_type: "s3_iceberg";
    } & Omit<components["schemas"]["data_credential"], "credentials_type"> & ({
      credentials?: {
        /**
         * @description __Authentication Mechanism__
         * Credentials can be configured to allow S3 access through different AWS permissions mechanisms. Select the type of Authentication method you wish to use.
         *
         * * `Access Key` - Select this option if you wish to use AWS Access and Secret keys for your S3.
         * * `ARN` - Select this option if you wish to use IAM ARN for authentication.
         * * `Instance Role` - Select this option if you wish to access S3 using an IAM Instance Role.
         *
         * @enum {string}
         */
        s3_auth_type: "Access Key" | "ARN" | "Instance Role";
        /**
         * @description __AWS Access Key__
         * __Required__ if `s3_auth_type` is `Access Key`
         */
        access_key_id?: string;
        /**
         * @description __AWS Secret Key__
         * __Required__ if `s3_auth_type` is `Access Key`
         */
        secret_key?: string;
        /** @description __IAM ARN__: The IAM Amazon Resource Name (ARN) for which these permissions are applicable. This should be entered in the format `arn:partition:service:region:account:resource`. */
        arn?: string;
        /**
         * @description __External Id__: The external ID if S3 has been configured for federated access.
         * __Required__ if `s3_auth_type` is `ARN`
         */
        external_id?: string;
        /**
         * @description Region for AWS S3 Account.
         * Default value: `us-east-1`
         */
        region?: string;
        /** @description __S3 Path list access is limited to__: Set this property to `<bucket-name>` or `<bucket-name>/<folder-name>` if your AWS admin has restricted access to only a specific bucket or a path inside a bucket. */
        "test.path"?: string;
      };
    });
    sharepoint_data_credential: {
      credentials_type: "sharepoint";
    } & Omit<components["schemas"]["data_credential"], "credentials_type"> & ({
      credentials?: {
        /**
         * @description __Authentication Type__: Select the type of OAuth2 authentication mechanism you wish to use.
         *
         * * `3-legged`: Use 3-legged OAuth for authentication.
         * * `2-legged`: Use 2-legged OAuth for authentication.
         *
         * @enum {string}
         */
        "oauth2.token_exchange_type": "3-legged" | "2-legged";
        /** @description __Tenant ID__: The Tenant ID for your SharePoint account. */
        tenant_id: string;
        /**
         * @description __Access Token__: Click the button above to fetch a new token.
         *
         * __Required__ if `oauth2.token_exchange_type` is `3-legged`
         */
        access_token?: string;
        /**
         * @description __API Vendor__: The API vendor for SharePoint.
         *
         * __Required__ if `oauth2.token_exchange_type` is `3-legged`
         *
         * @enum {string}
         */
        "vendor.name"?: "sharepoint";
        /**
         * @description __Vendor Token Type__: The token type for the vendor.
         *
         * __Required__ if `oauth2.token_exchange_type` is `3-legged`
         */
        "vendor.token_type"?: string;
        /**
         * @description __Vendor Access Token__: The access token for the vendor.
         *
         * __Required__ if `oauth2.token_exchange_type` is `3-legged`
         */
        "vendor.access_token"?: string;
        /**
         * @description __Vendor Refresh Token__: The refresh token for the vendor.
         *
         * __Required__ if `oauth2.token_exchange_type` is `3-legged`
         */
        "vendor.refresh_token"?: string;
        /**
         * @description __Vendor Refresh Time UTC__: The last refresh time for the vendor token.
         *
         * __Required__ if `oauth2.token_exchange_type` is `3-legged`
         */
        "vendor.last_refreshed_at"?: string;
        /**
         * @description __Vendor info contains expiration__: Indicates whether the vendor token contains expiration information.
         *
         * __Required__ if `oauth2.token_exchange_type` is `3-legged`
         */
        "vendor.has_token_expiration_ts"?: boolean;
        /**
         * @description __Vendor Token Expiration Time__: The expiration time for the vendor token.
         *
         * __Required__ if `oauth2.token_exchange_type` is `3-legged`
         */
        "vendor.token_expires_in"?: number;
        /**
         * @description __Other Vendor Info__: Additional information for the vendor.
         *
         * __Required__ if `oauth2.token_exchange_type` is `3-legged`
         */
        "vendor.other_info"?: string;
        /**
         * @description __Client ID__: The Client ID of your OAuth 2.0 client.
         *
         * __Required__ if `oauth2.token_exchange_type` is `2-legged`
         */
        "oauth2.client.id"?: string;
        /**
         * @description __Client Secret__: The Client Secret of your OAuth 2.0 client.
         *
         * __Required__ if `oauth2.token_exchange_type` is `2-legged`
         */
        "oauth2.client.secret"?: string;
        /**
         * @description __Authentication Type__: The type of authentication used.
         *
         * Default Value: `OAUTH2`
         *
         * @enum {string}
         */
        "auth.type"?: "OAUTH2";
        /**
         * @description __Access Token URL method__: The request method used for the OAuth 2.0 Token URL.
         *
         * Default Value: `POST`
         *
         * @enum {string}
         */
        "oauth2.access.token.method"?: "POST";
        /**
         * @description __Client Authentication Scheme__: The authentication scheme used for the OAuth 2.0 client.
         *
         * Default Value: `form`
         *
         * @enum {string}
         */
        "oauth2.client.auth.scheme"?: "form";
        /**
         * @description __Token Type__: The token type that should be used when attaching the OAuth2.0 token to the request.
         *
         * Default Value: `Bearer`
         *
         * @enum {string}
         */
        "oauth2.token.type.override"?: "Bearer";
        /**
         * @description __Skip Validation__: Indicates whether to skip validation.
         *
         * Default Value: `false`
         */
        "skip.validation"?: boolean;
        /**
         * @description __Test Content Type__: The content type used for testing.
         *
         * Default Value: `application/json`
         */
        "test.content.type"?: string;
        /**
         * @description __Test Method__: The request method used for testing.
         *
         * Default Value: `GET`
         */
        "test.method"?: string;
        /**
         * @description __Test URL__: The URL used for testing.
         *
         * Recommended Value: `https://graph.microsoft.com/v1.0/sites`
         */
        "test.url"?: string;
        /**
         * @description __API Scopes__: The scopes that should be added to the OAuth token calls.
         *
         * Recommended Value: `https://graph.microsoft.com/.default`
         */
        "vendor.scopes"?: string;
      };
    }) & components["schemas"]["file_data_credential"];
    snowflake_data_credential: {
      credentials_type: "snowflake";
    } & Omit<components["schemas"]["data_credential"], "credentials_type"> & ({
      credentials?: {
        /** @description __Host__: Enter the hostname for your database. This is usually in the format `<account_name>.snowflakecomputing.com`. Do not include the connection protocol. */
        host: string;
        /** @description __Port__: Enter the port used to access your database. */
        port: number;
        /**
         * @description __Snowflake Authentication Type__: Credentials can be configured to allow Snowflake access through different Snowflake permissions mechanisms. Select the type of authentication method you wish to use.
         *
         * * `basic`: __Basic Authentication__: Select this option if you wish to use the Username and Password for Snowflake access.
         *
         * * `key_pair`: __Key Pair Authentication__: Select this option if you wish to use the Key Pair authentication mechanism to connect to your Snowflake account.
         *
         * @enum {string}
         */
        "snowflake.auth.type": "basic" | "key_pair";
        /** @description __Username__: Enter the username used to access your database. */
        username: string;
        /**
         * @description __Password__: Enter the password used to access your database.
         *
         * __Applicable and required__ if `snowflake.auth.type` is `basic`
         */
        password?: string;
        /**
         * @description __Private Key__: Enter the file content of the private key file as a `base64` encoded string. To retrieve the file content, open the PEM file in any text editor, and copy over its content as the payload. Then `base64`-encode that content before adding it to the payload.
         *
         * __Applicable and required__ if `snowflake.auth.type` is `key_pair`
         */
        "snowflake.privateKey"?: string;
        /**
         * @description __Passphrase for Private Key__: If the private key file was generated with a passphrase, please enter the passphrase here.
         *
         * __Applicable__ if `snowflake.auth.type` is `key_pair`
         */
        "snowflake.privateKey.passphrase"?: string;
        /** @description __Warehouse__: The Snowflake warehouse to which you wish to connect. */
        warehouse_name: string;
        /** @description __Database Name__: Enter the database name if you want to connect to a specific database. */
        database_name: string;
        /** @description __Schema Name__: Enter the schema name for the database to which you wish to connect. */
        schema_name: string;
        /**
         * @description __Access Control Roles__: Snowflake uses roles to control access to objects in the system. Roles are granted access privileges for objects in the system.
         *
         * Usually, you can leave this field blank. However, if your Snowflake configuration requires a special, non-default role to be applied to access the objects in which you are interested, you can set the Role here.
         */
        "database.field.role"?: string;
        /** @description __Query Tag__: Snowflake query tags allow users to associate arbitrary metadata with each query. This can be used to identify the query in the query history for enhanced observability. */
        "database.field.QUERY_TAG": string;
        /** @description __Additional Connection Parameters__: Enter any additional connection parameters you need to pass to the warehouse while establishing the connection. The format should be `key1:value1,key2:value2` */
        "jdbc.parameters"?: string;
      };
    }) & components["schemas"]["database_data_credential"];
    snowflake_dcr_data_credential: {
      credentials_type: "snowflake_dcr";
    } & Omit<components["schemas"]["data_credential"], "credentials_type"> & ({
      credentials?: {
        /** @description __Host__: Enter the hostname for your database. This is usually in the format `<account_name>.snowflakecomputing.com`. Do not include the connection protocol. */
        host: string;
        /** @description __Port__: Enter the port used to access your database. */
        port: number;
        /**
         * @description __Snowflake Authentication Type__: Credentials can be configured to allow Snowflake access through different Snowflake permissions mechanisms. Select the type of authentication method you wish to use.
         *
         * * `basic`: __Basic Authentication__: Select this option if you wish to use the Username and Password for Snowflake access.
         *
         * * `key_pair`: __Key Pair Authentication__: Select this option if you wish to use the Key Pair authentication mechanism to connect to your Snowflake account.
         *
         * @enum {string}
         */
        "snowflake.auth.type": "basic" | "key_pair";
        /** @description __Username__: Enter the username used to access your database. */
        username: string;
        /**
         * @description __Password__: Enter the password used to access your database.
         *
         * __Applicable and required__ if `snowflake.auth.type` is `basic`
         */
        password?: string;
        /**
         * @description __Private Key__: Enter the file content of the private key file as a `base64` encoded string. To retrieve the file content, open the PEM file in any text editor, and copy over its content as the payload. Then `base64`-encode that content before adding it to the payload.
         *
         * __Applicable and required__ if `snowflake.auth.type` is `key_pair`
         */
        "snowflake.privateKey"?: string;
        /**
         * @description __Passphrase for Private Key__: If the private key file was generated with a passphrase, please enter the passphrase here.
         *
         * __Applicable__ if `snowflake.auth.type` is `key_pair`
         */
        "snowflake.privateKey.passphrase"?: string;
        /** @description __Warehouse__: The Snowflake warehouse to which you wish to connect. */
        warehouse_name: string;
        /** @description __Database Name__: Enter the database name if you want to connect to a specific database. */
        database_name: string;
        /** @description __Schema Name__: Enter the schema name for the database to which you wish to connect. */
        schema_name: string;
        /**
         * @description __Access Control Role__: Snowflake uses roles to control access to objects in the system. Roles are granted access privileges for objects in the system.
         *
         *   Usually, you can leave this field blank. However, if your Snowflake configuration requires a special, non-default role to be applied to access the objects in which you are interested, you can set the Role here.
         */
        "database.field.role"?: string;
      };
    }) & components["schemas"]["database_data_credential"];
    soap_data_credential: {
      credentials_type: "soap";
    } & Omit<components["schemas"]["data_credential"], "credentials_type"> & ({
      credentials?: {
        /**
         * @description __Authentication Mechanism__: Credentials can be configured to allow API access through different authentication mechanisms supported by the API.
         *
         * @enum {string}
         */
        "auth.type": "NONE" | "BASIC";
        /**
         * @description __Username__: Enter the username field for basic authentication. Nexla will automatically combine this with the password and Base64-encode the pair.
         *
         * __Required__ if `auth.type` is `BASIC`
         */
        "basic.username"?: string;
        /**
         * @description __Password__: Enter the password field for basic authentication. Nexla will automatically combine this with the username and Base64-encode the pair.
         *
         * __Required__ if `auth.type` is `BASIC`
         */
        "basic.password"?: string;
      };
    });
    sqlserver_data_credential: {
      credentials_type: "sqlserver";
    } & Omit<components["schemas"]["data_credential"], "credentials_type"> & ({
      credentials?: {
        /** @description __Host__: Enter the hostname for your database. This is usually an IP address or text in the format __company.domain.com__. Do not include the connection protocol. */
        host: string;
        /** @description __Port__: Enter the port used to access your database. */
        port: number;
        /** @description __Username__: Enter the username used to access your database. */
        username: string;
        /** @description __Password__: Enter the password used to access your database. */
        password: string;
        /** @description __Database Name__: Enter the database name if you want to connect to a specific database. */
        database_name?: string;
        /** @description __Schema Name__: Enter the schema name for the database to which you wish to connect. */
        schema_name?: string;
        /**
         * @description __Connection Mode / Application Intent__: You can restrict database connectivity capabilities by specifying the connection mode. Select __Read Only__ to connect to the database in __readonly__ mode.
         *
         * * `readonly`: Connect in read-only mode.
         *
         * * `readwrite`: Connect in read-write mode.
         *
         * Default value: `readwrite`
         *
         * @enum {string}
         */
        "database.field.applicationIntent"?: "readonly" | "readwrite";
      };
    }) & components["schemas"]["database_data_credential"];
    sybase_data_credential: {
      credentials_type: "sybase";
    } & Omit<components["schemas"]["data_credential"], "credentials_type"> & {
      credentials?: {
        /** @description __Host__: Enter the hostname for your database. This is in the format `company.domain.com`. Do not include the connection protocol. */
        host: string;
        /** @description __Port__: Enter the port used to access your database. */
        port: number;
        /** @description __Username__: Enter the username used to access your database. */
        username: string;
        /** @description __Password__: Enter the password used to access your database. */
        password: string;
        /** @description __Database Name__: Enter the database name if you want to connect to a specific database. */
        database_name: string;
        /**
         * @description __Schema Name__: Enter the schema name for the tables you are interested in.
         *
         * Leave this input empty `` if you wish to access tables that do not belong to any schema.
         */
        schema_name?: string;
      };
    } & components["schemas"]["database_data_credential"];
    teradata_data_credential: {
      credentials_type: "teradata";
    } & Omit<components["schemas"]["data_credential"], "credentials_type"> & {
      credentials?: {
        /** @description __Host__: Enter the hostname for your database. This is usually an IP address or text in the format __company.domain.com__. Do not include the connection protocol. */
        host: string;
        /** @description __Port__: Enter the port used to access your database. */
        port: number;
        /** @description __Username__: Enter the username used to access your database. */
        username: string;
        /** @description __Password__: Enter the password used to access your database. */
        password: string;
        /** @description __Database Name__: Enter the database name if you want to connect to a specific database. */
        database_name: string;
      };
    } & components["schemas"]["database_data_credential"];
    tibco_data_credential: {
      credentials_type: "tibco";
    } & Omit<components["schemas"]["data_credential"], "credentials_type"> & ({
      credentials?: {
        /**
         * @description __JMS Vendor__: Select the type of vendor for this JMS connector.
         *
         * @enum {string}
         */
        "jms.vendor": "tibco" | "activemq";
        /** @description __Server URL__: Enter the address of the JMS Server. This is usually a Virtual IP address. */
        url: string;
        /** @description __Username__: Enter the username used to access this server. */
        username: string;
        /** @description __Password__: Enter the password used to access this server. */
        password: string;
      };
    }) & components["schemas"]["stream_data_credential"];
    webdav_data_credential: {
      credentials_type: "webdav";
    } & Omit<components["schemas"]["data_credential"], "credentials_type"> & {
      credentials?: {
        /** @description __WebDAV Server URL__: Enter the server URL for accessing the WebDAV server. This should be a fully formatted URL that includes the connection protocol. */
        url: string;
        /**
         * @description __Anonymous access?__: Set this to `true` if the connection should be made as an anonymous user.
         *
         * Default value: `false`
         */
        anonymous?: boolean;
        /**
         * @description __Username__: Enter the username used to access your database.
         *
         * __Applicable and required__ if `anonymous` is `false`
         */
        username?: string;
        /**
         * @description __Password__: Enter the password used to access your database.
         *
         * __Applicable and required__ if `anonymous` is `false`
         */
        password?: string;
      };
    } & components["schemas"]["file_data_credential"];
    /** @description This object represents the response of an asynchronous operation. The response can be a dictionary or an array of dictionaries. The format of the response depends on the operation that was executed. */
    AsyncResponse: {
      /** @description The unique ID of the request that was executed. This ID can be used to track the status of the request. */
      request_id?: number;
      /** @enum {string} */
      status?: "pending" | "running" | "completed" | "failed" | "cancelled";
      /**
       * Format: date-time
       * @description The date and time when the request was started.
       */
      request_started_at?: string;
      /** @description The progress of the request (value from 0 to 100). This value is a percentage of the total progress of the request. Applicable only to certain types of async operations. */
      progress?: number;
      /** @description The result of the async operation. Format depends on the task type. */
      result?: {
        [key: string]: unknown;
      };
      /**
       * Format: date-time
       * @description The date and time when the request was stopped. This field is only present if the request has been stopped (due to cancellation or error).
       */
      request_stopped_at?: string;
      /**
       * Format: date-time
       * @description The date and time when the request was completed. This field is only present if the request has been completed successfully.
       */
      request_completed_at?: string;
    };
    probe_response_with_async_results: OneOf<[components["schemas"]["AsyncResponse"], {
      /** @description The output of the probe operation. */
      output?: {
        [key: string]: unknown;
      };
    }]>;
    probe_tree_common: {
      /**
       * @description Response status code from the third-party storage system to which this credential connects. `Ok` indicates that the request resulted in a valid response from the storage system.
       *
       * @enum {string}
       */
      status?: "ok";
      /**
       * @description Message string indicating response validity from the underlying storage system. `Ok` indicates that the request resulted in a valid response from the storage system.
       * Errors are returned as relevant message strings indicating the failure reasons.
       *
       * @enum {string}
       */
      message?: "Ok";
      /** @description __Connector Type__: Connector codename. */
      connection_type?: string;
    };
    file_probe_tree: {
      connection_type: "azure_blb";
    } & Omit<components["schemas"]["probe_tree_common"], "connection_type"> & {
      /**
       * @description This object reports the folder-file structure in a nested JSON format for visualizing the file storage hierarchy tree.
       *
       * The unique name/identifier of any element in the storage system is set as the key of the relevant node. Each node entry contains the following:
       * 1. a `type` property that defines whether the element is a `folder`, `file`, or `meta` (Nexla probe response meta-data).
       * 2. the top-level node has a special `meta` key that contains response metadata (of the type `meta`) and a key that indicates the name/unique ID of the root folder.
       *   - for storage systems like `s3` that have a bucket concept, the top-level keys are all bucket names to which this credential has access.
       *   - for storage systems like `gdrive` that have a unique ID and synthetic display names, the keys represent unique IDs instead of folder names.
       *   - for storage systems like `ftp`, `dropbox`, and `box` that do not have buckets, the top-level entry is `/` to signify the credential root folder.
       * 2. a `value` property that defines the children of that node.
       *   - For a folder, the `value` is an object, with each subfolder and file as an entry.
       *   - For a file, the `value` is an empty object `{}` because files do not have any children.
       * 3. `file`-type nodes have `created_at`, `updated_at`, and `size` properties that indicate the corresponding values for that file.
       * 4. For Google Drive-type systems, wherein the storage assigns a unique identifier instead of constraining the display name to be unique, the `value` object contains a `display_name` property to indicate the name of that entry.
       *
       * __Example__ Sample value of `output` in the probe tree response:
       * ```
       * {
       *   "/": {
       *     "type": "folder",
       *     "value": {
       *       "subfolder_1": {
       *         "type": "folder",
       *         "value": {
       *           "subfolder_1a": {
       *             "type": "folder"
       *             "value": {}
       *           }
       *         },
       *       "subfolder_2": {
       *         "type": "folder",
       *         "value": {
       *           "subfolder_2a": {
       *             "type": "folder"
       *             "value": {}
       *           },
       *           "file_1": {
       *             "type": "file",
       *             "created_at": 1664998398000,
       *             "updated_at": 1664998398000,
       *             "size": 152,
       *             "value": {}
       *           }
       *         },
       *       }
       *   }
       * ```
       */
      object?: {
        /** @description Name or unique identifier of the folder/subfolder. This value might be `/` at the root of the hierarchy for some storage types, like `dropbox` and `ftp`. */
        folder_name?: {
          /**
           * @description The type `folder` indicates that this property is the name of a folder.
           *
           * @enum {string}
           */
          type?: "folder";
          /** @description This value indicates the display name of this folder and is only present for storage systems like `gdrive`, in which display names are not unique. */
          display_name?: string;
          /** @description List of subfolders and files in this folder. */
          value?: {
            /** @description Name of the file. */
            file_name?: {
              /** @enum {string} */
              type?: "file";
              /** @description File creation time in epoch time (milliseconds). */
              created_at?: number;
              /** @description File modification time (most recent) in epoch time (milliseconds). */
              updated_at?: number;
              /** @description File size in bytes. */
              size?: number;
              /** @description This value indicates the display name of the file and is only present for storage systems like `gdrive`, in which display names are not unique. */
              display_name?: string;
            };
          };
        };
        /** @description A special metadata object that indicates the relevant response Nexla metadata for probe responses. This is only present at the root level. */
        meta?: {
          /** @enum {string} */
          type?: "meta";
          value?: Record<string, never>;
        };
      };
    };
    database_probe_tree: {
      connection_type: "as400";
    } & Omit<components["schemas"]["probe_tree_common"], "connection_type"> & ({
      /**
       * @description This object reports the database-table-column structure in a nested JSON format for visualizing the database hierarchy tree.
       *
       * The unique name/identifier of any element in the storage system is set as the key of the relevant node. Each node entry contains the following:
       * 1. a `type` property that defines whether the element is a `database`, `table`, or `column`.
       * 2. a `value` property that defines the children of that node.
       *   - For a database, the `value` is an object, with each table included as a property of the object.
       *   - For a table, the `value` is an array of objects, with each object matching a column of the database.
       *   - Column objects do not have any `value` property because columns do not have any children.
       * 3. `column`-type nodes have `name`, `primaryKey` and `defaultValue` properties that define the column properties.
       *
       * __Example__ Sample value of `output` in the probe tree response.
       * ```
       * {
       *   "DEMO_DB": {
       *     "type": "database",
       *     "value": {
       *       "DEMO_TABLE": {
       *         "type": "table",
       *         "value": [
       *           {
       *             "name": "CREATIONDATE",
       *             "primaryKey": false,
       *             "type": "VARCHAR",
       *             "defaultValue": null
       *           },
       *           {
       *             "name": "PROJECTNAME",
       *             "primaryKey": false,
       *             "type": "VARCHAR",
       *             "defaultValue": null
       *           },
       *           {
       *             "name": "PROJECTYEAR",
       *             "primaryKey": false,
       *             "type": "VARCHAR",
       *             "defaultValue": null
       *           }
       *         ]
       *       }
       *   }
       * ```
       */
      object?: {
        /** @description Name of database. */
        db_name_1?: {
          /**
           * @description The type `database` indicates that this property is the name of a database.
           *
           * @enum {string}
           */
          type?: "database";
          /** @description List of tables in the database. */
          value?: {
            /** @description Name of the table. */
            table_name_1?: {
              /** @enum {string} */
              type?: "table";
              value?: ({
                  /** @enum {string} */
                  type?: "column";
                  /** @description Name of the column. */
                  name?: string;
                  /** @description Whether or not this column is a primary key for the table. */
                  primaryKey?: boolean;
                  /** @description Whether or not the column has a default value. */
                  defaultValue?: null | string | number;
                })[];
            };
          };
        };
      };
    });
    nosql_probe_tree: {
      connection_type: "dynamodb";
    } & Omit<components["schemas"]["probe_tree_common"], "connection_type"> & {
      /**
       * @description This object reports the database-collection structure in nested JSON format for visualizing the database hierarchy tree.
       *
       * The unique name/identifier of any element in the storage is set as the key of the relevant node. Each node entry contains the following:
       * 1. a `type` property that defines whether the element is a `database` or `collection`.
       * 2. a `value` property that defines the children of that node.
       *   - For a database, the `value` is an object, with each collection as a property of the object.
       *   - For a collection, this is an empty object (`{}`), as the platform does not list documents inside the collection as part of this response. Use the `probe/sample` endpoint to obtain sample documents from the collection.
       *
       * __Example__ Sample value of `output` in the probe tree response:
       * ```
       * {
       *   "DEMO_DB": {
       *     "type": "database",
       *     "value": {
       *       "demo collection_1": {
       *         "type": "collection",
       *         "value": {}
       *       },
       *       "demo collection_2": {
       *         "type": "collection",
       *         "value": {}
       *       }
       *
       *   }
       * ```
       */
      object?: {
        /** @description Name of the database. */
        db_name_1?: {
          /**
           * @description The type `database` indicates that this property is the name of a database,
           *
           * @enum {string}
           */
          type?: "database";
          /** @description List of collections in the database. */
          value?: {
            /** @description Name of the collection. */
            collection_name_1?: {
              /** @enum {string} */
              type?: "collection";
              /** @enum {object} */
              value?: unknown;
            };
          };
        };
      };
    };
    probe_tree_with_async: {
      connection_type: "probe_tree_with_async";
    } & (Omit<components["schemas"]["probe_tree_common"], "connection_type"> | components["schemas"]["AsyncResponse"]);
    /** @enum {string} */
    ConnectorTypeFile: "azure_blb" | "azure_data_lake" | "box" | "delta_lake_azure_blb" | "delta_lake_azure_data_lake" | "delta_lake_s3" | "dropbox" | "ftp" | "gcs" | "gdrive" | "min_io_s3" | "s3" | "s3_iceberg" | "sharepoint" | "webdav";
    /** @enum {string} */
    ConnectorTypeDatabase: "as400" | "aws_athena" | "azure_synapse" | "bigquery" | "cloudsql_mysql" | "cloudsql_postgres" | "cloudsql_sqlserver" | "databricks" | "db2" | "firebolt" | "gcp_alloydb" | "gcp_spanner" | "hana_jdbc" | "hive" | "mysql" | "netsuite_jdbc" | "oracle" | "oracle_autonomous" | "postgres" | "redshift" | "snowflake" | "snowflake_dcr" | "sqlserver" | "sybase" | "teradata";
    /** @enum {string} */
    ConnectorTypeNoSql: "dynamodb" | "firebase" | "mongo";
    /** @enum {string} */
    ConnectorTypeKafka: "confluent_kafka" | "google_pubsub" | "jms" | "kafka" | "tibco";
    /** @enum {string} */
    ConnectorTypeVectorDB: "pinecone";
    probe_sample: {
      /**
       * @description Response status code from the third-party storage system to which this credential connects. `Ok` indicates that the request resulted in a valid response from the storage system.
       *
       * @enum {string}
       */
      status?: "ok";
      /**
       * @description Message string indicating response validity from the underlying storage system. `Ok` indicates that the request resulted in a valid response from the storage system.
       * Errors are returned as relevant message strings indicating the failure reasons.
       *
       * @enum {string}
       */
      message?: "Ok";
      connection_type?: components["schemas"]["ConnectorTypeFile"] & components["schemas"]["ConnectorTypeDatabase"] & components["schemas"]["ConnectorTypeNoSql"] & components["schemas"]["ConnectorTypeKafka"] & components["schemas"]["ConnectorTypeVectorDB"] & "rest" & "soap";
      output?: OneOf<[{
        /** @description File content type. Usually, this is `application/json`, `text/plain`, or `application/binary`. */
        contentType?: string;
        /** @description Storage system status code for the sample request. Usually, this is 200 for a successful sample attempt and other status codes for unsuccessful sample attempts. */
        statusCode?: number;
        /** @description Sample lines from the file. */
        response?: string;
      }, {
        /** @description Response content type. Usually, this is `application/json`. */
        contentType?: string;
        /** @description Storage system status code for the sample request. Usually, this is 200 for a successful sample attempt and other status codes for unsuccessful sample attempts. */
        statusCode?: number;
        response?: {
          /** @description An array of column names in the sample response. */
          columns?: string[];
          /** @description An array of data rows in the sample response. */
          data?: ({
              [key: string]: number | string | Record<string, never>;
            })[];
        };
      }, {
        /**
         * @description Response content type. Usually, this is `application/json`.
         *
         * @enum {string}
         */
        contentType?: "application/json";
        /** @description Storage system status code for the sample request. Usually, this is 200 for a successful sample attempt and other status codes for unsuccessful sample attempts. */
        statusCode?: number;
        /** @description JSON string in which each key is a document name and the value of each key is the content of the corresponding document. */
        response?: string;
      }, {
        /** @description Connector response content type. Usually, this is `application/json`, `text/plain`, or `application/binary`. */
        contentType?: string;
        /** @description Storage system status code for the sample request. Usually, this is 200 for a successful sample attempt and other status codes for unsuccessful sample attempts. */
        statusCode?: number;
        /** @description API response from the 3rd party (connector) API. */
        response?: string;
      }]>;
    };
    probe_sample_with_async: components["schemas"]["AsyncResponse"] | components["schemas"]["probe_sample"];
    FlowChildNode: {
      id?: number;
      /** @description The flow id of the flow node this node is a direct descendant of. */
      parent_node_id?: number;
      /** @description The flow id of the flow node at the root of this flow chain. */
      origin_node_id?: number;
      /**
       * Format: nullable
       * @description The ID of the data source this flow node is linked to if this is a flow node for a data source.
       */
      data_source_id?: number;
      /**
       * Format: nullable
       * @description The ID of the Nexset this flow node is linked to if this is flow node for a Nexset.
       */
      data_set_id?: number;
      /**
       * Format: nullable
       * @description The ID of the data sink this flow node is linked to if this is a flow node for a data sink.
       */
      data_sink_id?: number;
      /** @description Each element is a flow node that is directly linked to this node. */
      children?: unknown[];
    };
    FlowOriginNode: {
      id?: number;
      /**
       * Format: nullable
       * @description Flow id of the parent flow node if this node is not the root node in the flow chain. This will usually be `null` as most flow definitions will originate in the node for `data_source`.
       */
      parent_node_id?: number;
      /** @description Flow id of the root node in the flow chain. */
      origin_node_id?: number;
      /**
       * Format: nullable
       * @description The ID of the data source this flow node is linked to if this is a flow node for a data source.
       */
      data_source_id?: number;
      /**
       * Format: nullable
       * @description The ID of the Nexset this flow node is linked to if this is flow node for a Nexset.
       */
      data_set_id?: number;
      /**
       * Format: nullable
       * @description The ID of the data sink this flow node is linked to if this is a flow node for a data sink.
       */
      data_sink_id?: number;
      /** Format: nullable */
      shared_origin_node_id?: number;
      status?: string;
      /** Format: nullable */
      project_id?: number;
      flow_type?: string;
      ingestion_mode?: string;
      name?: string;
      description?: string;
      /** @description Each element of this array is a flow node that is directly linked to this flow node. */
      children?: components["schemas"]["FlowChildNode"][];
    };
    FlowNodes: components["schemas"]["FlowOriginNode"][];
    FlowElements: {
      /** @description All code containers that are linked to flow nodes in this response. */
      code_containers?: {
          id?: number;
          owner_id?: number;
          org_id?: number;
          name?: string;
          description?: null;
          data_credentials_id?: null;
          public?: boolean;
          managed?: boolean;
          reusable?: boolean;
          resource_type?: string;
          output_type?: string;
          code_type?: string;
          code_encoding?: string;
          access_roles?: unknown[];
          tags?: unknown[];
          copied_from_id?: number;
          /** Format: date-time */
          created_at?: string;
          /** Format: date-time */
          updated_at?: string;
        }[];
      /** @description All data sources that are linked to flow nodes in this response. */
      data_sources?: ({
          id?: number;
          owner_id?: number;
          org_id?: number;
          flow_node_id?: number;
          origin_node_id?: number;
          name?: string;
          description?: null;
          status?: string;
          data_credentials_id?: number | null;
          data_sink_id?: number | null;
          auto_generated?: boolean;
          managed?: boolean;
          source_type?: string;
          connector_type?: string;
          connection_type?: string;
          template_config?: Record<string, never>;
          vendor?: null;
          access_roles?: unknown[];
          tags?: unknown[];
          copied_from_id?: number | null;
          /** Format: date-time */
          created_at?: string;
          /** Format: date-time */
          updated_at?: string;
        })[];
      /** @description All Nexsets that are linked to flow nodes in this response. */
      data_sets?: ({
          id?: number;
          owner_id?: number;
          org_id?: number;
          flow_node_id?: number;
          origin_node_id?: number;
          name?: string;
          description?: string;
          status?: string;
          data_source_id?: number | null;
          parent_data_set_id?: number | null;
          code_container_id?: number | null;
          data_sink_ids?: unknown[];
          public?: boolean;
          managed?: boolean;
          access_roles?: unknown[];
          tags?: unknown[];
          copied_from_id?: number | null;
          /** Format: date-time */
          created_at?: string;
          /** Format: date-time */
          updated_at?: string;
        })[];
      /** @description All data sinks that are linked to flow nodes in this response. */
      data_sinks?: ({
          id?: number;
          owner_id?: number;
          org_id?: number;
          flow_node_id?: number;
          origin_node_id?: number;
          name?: string;
          description?: null;
          status?: string;
          data_credentials_id?: number;
          data_set_id?: number;
          data_source_id?: number | null;
          managed?: boolean;
          sink_type?: string;
          connector_type?: string;
          connection_type?: string;
          template_config?: Record<string, never>;
          vendor?: null;
          access_roles?: unknown[];
          tags?: unknown[];
          copied_from_id?: null;
          /** Format: date-time */
          created_at?: string;
          /** Format: date-time */
          updated_at?: string;
        })[];
      /** @description All credentials that are referenced by flow nodes in this response. */
      data_credentials?: {
          id?: number;
          owner_id?: number;
          org_id?: number;
          name?: string;
          description?: null;
          credentials_type?: string;
          verified_status?: string;
          managed?: boolean;
          template_config?: Record<string, never>;
          vendor?: null;
          access_roles?: unknown[];
          tags?: unknown[];
          copied_from_id?: null;
          /** Format: date-time */
          created_at?: string;
          /** Format: date-time */
          updated_at?: string;
        }[];
      /** @description Metadata about the parent Nexset any relevant origin flow node is a descendant of. This is only relevant for flow nodes that originate in a shared Nexset instead of a data source. */
      shared_data_sets?: unknown[];
      orgs?: components["schemas"]["org"][];
      users?: components["schemas"]["owner"][];
      /** @description All projects that any of the flows in this flow response are linked to. */
      projects?: {
          id?: number;
          owner_id?: number;
          org_id?: number;
          name?: string;
          description?: string;
          access_roles?: unknown[];
        }[];
    };
    flow_one_with_async: OneOf<[{
      flows?: components["schemas"]["FlowOriginNode"][];
    } & components["schemas"]["FlowElements"], components["schemas"]["AsyncResponse"]]>;
    data_source: {
      name?: string;
      description?: string;
      /**
       * @description __Credential ID__: Nexla data credential that contains all authentication information for this source.
       *
       * Note that this is not applicable for `file_upload`, `nexla_rest` and `email` sources but is required for all other connectors.
       */
      data_credentials_id?: number;
      /** @description Field only used for ELT Vendor Endpoints */
      stream_config?: Record<string, never>;
      /** @description __Connector Type__: Connector codename. */
      source_type?: string;
      /** @description ID of code container to attach to this source. */
      code_container_id?: number;
      /**
       * @description Code Container details that will be created and attached to this source. Note: you can't pass both `code_container` and `code_container_id` together,
       * code_container_id will take priority.
       */
      code_container?: {
        code?: string | Record<string, never> | unknown[];
        name?: string;
        description?: string;
        /** @enum {string} */
        resource_type?: "source" | "source_custom";
        /** @enum {string} */
        code_type?: "jolt_standard" | "jolt_custom" | "python" | "python3" | "javascript" | "flink_sql" | "spark_sql";
        /** @enum {string} */
        code_encoding?: "none" | "base64";
        code_config?: Record<string, never>;
        custom_config?: Record<string, never>;
        /** @enum {string} */
        repo_type?: "embedded" | "github";
        repo_config?: Record<string, never>;
      };
    };
    WithoutCDCSupport: {
      source_config?: {
        /**
         * @description __Scheduling Frequency__: The interval at which Nexla should scan this source for new data. This must be in the form of a cron expression.
         *
         * @example 0 0 22 10 11 ? 2022
         */
        "start.cron": string;
        /**
         * @description __Database Fetch Mode__: Database connectors are designed to support self-serve capabilities for use cases ranging from simple table ingestion to ingestion based on complex custom queries.
         *
         * * `Default`: Equivalent to running a simple (but optimized) SELECT clause on any database table, along with some additional customizations for filtering rows.
         *
         * * `Query`: Execute data fetching based on a custom database query using the syntax and convention supported by the underlying database/warehouse.
         *
         * @enum {string}
         */
        db_query_mode: "Default" | "Query";
        /**
         * @description __Query__: Set the Query to be executed during each ingestion cycle.
         *
         * __Required__ if `db_query_mode` is `Query`
         */
        query?: string;
        /**
         * @description __Database__: Database whose table needs to be scanned for data.
         *
         * __Required__ if `db_query_mode` is `Default`
         */
        database?: string;
        /**
         * @description __Table__: Table that needs to be scanned for data.
         *
         * __Required__ if `db_query_mode` is `Default`
         */
        table?: string;
        /**
         * @description __Table Scan Mode__: The default configuration of Table Mode is set to read all data in a table in each ingestion cycle, which is equivalent to a running `SELECT` clause on the table. However, when the table contains much more historical data than you wish to scan, you can instruct the platform to begin loading from a specific __id__ (stored in a numeric column), __timestamp__ (stored in a date-time column) or __both id and timestamp__.
         *
         * You can use the relevant Table Scan Mode to address this use case of partial loading from a table.
         *
         * Note that this can also be achieved by writing a properly structured query in Query Mode.
         *
         * Only applicable if `db_query_mode` is `Default`
         * Default Value: `none`
         *
         * * `none`: Read the whole table
         *
         * * `incrementing`: Start reading from a specific ID
         *
         * * `timestamp`: Start reading from a specific timestamp
         *
         * * `incrementing,timestamp`: Start reading from a specific ID and timestamp
         *
         * @enum {string}
         */
        mode?: "none" | "incrementing" | "timestamp" | "incrementing,timestamp";
        /**
         * @description __ID Column__: The ID column that should be used for executing partial data loading from the selected table. This must be a numeric column.
         *
         * Only applicable if `db_query_mode` is `Default` and `mode` is `incrementing` or `incrementing,timestamp`
         */
        "incrementing.column.name"?: string;
        /**
         * @description __Starting ID__: The starting ID value of __ID Column__ from which the platform should start ingesting data.
         *
         * Only applicable if `db_query_mode` is `Default` and `mode` is `incrementing` or `incrementing,timestamp`
         */
        "incrementing.load.from"?: string;
        /**
         * @description __Timestamp Column__: The timestamp column that should be used for executing partial data loading from the selected table. This must be a date-time column.
         *
         * Only applicable if `db_query_mode` is `Default` and `mode` is `timestamp` or `incrementing,timestamp`
         */
        "timestamp.column.name"?: string;
        /**
         * @description __Starting Timestamp__: The timestamp value of the __Timestamp Column__ from which the platform should start ingesting data. This must be a UNIX epoch- (milliseconds) or ISO-formatted date value (e.g., 2016-01-01T12:13:14).
         *
         * Only applicable if `db_query_mode` is `Default` and `mode` is `timestamp` or `incrementing,timestamp`
         */
        "timestamp.load.from"?: number | string;
        /**
         * Format: boolean
         * @description __Perform Database Commit after Read?__: You can instruct the platform to execute a database commit if the query includes statements that should also be committed to the database after ingestion. This is typically not the case, so most of the time, the value should be left as false.
         *
         * Only applicable if `db_query_mode` is `Query`
         *
         * Default Value: `"false"`
         *
         * @enum {string}
         */
        "commit.on.read"?: "false" | "true";
      };
    };
    as400_data_source: {
      source_type: "as400";
    } & Omit<components["schemas"]["data_source"], "source_type"> & components["schemas"]["WithoutCDCSupport"];
    aws_athena_data_source: {
      source_type: "aws_athena";
    } & Omit<components["schemas"]["data_source"], "source_type"> & components["schemas"]["WithoutCDCSupport"];
    file_data_source: {
      source_config?: {
        /**
         * @description __Scheduling Frequency__: The interval at which Nexla should scan this source for new files. This must be in the form of a cron expression.
         *
         * @example 0 0 22 10 11 ? 2022
         */
        "start.cron": string;
        /** @description __Path to Scan__: The path of the folder to be scanned for new data. */
        path: string;
        /**
         * @description __Choose a pre-built File Processor__: Select a file processor that best matches the format of your files. The platform offers several built-in options to handle various file types and formats. You can also combine these with custom file parsing code for more advanced use cases.
         *
         * The platform's default configurations of automatically detecting Nexsets from file content are primarily driven by parsing appropriately based on file extensions.
         *
         *
         * However, you can override the default parsing and further customize how the files are processed by selecting appropriate File Content Format choices.
         *
         * Some common scenarios are -
         *
         * 1. Files without extensions to indicate what type of parser should be applied
         *
         * 2. Compressed Zip or Tar files.
         * Select Custom Text Format, and the platform will automatically un-compress and parse the un-compressed files based on those settings.
         * 3. Text files with fixed-width or custom column delimiters
         * 4. CSV files without a header row. The platform will automatically assign attribute names as __attribute1__, __attribute2__, etc.
         * 5. Structured files in which some lines have to be skipped before processing rows
         * 6. Files in which the name extension does not match the desired parser (e.g., JSON content in a .dat file)
         * 7. Files for which some customization has to be applied to designate how the default extension parser treats data.
         *
         * * `Auto Detect`: (Automatic) Automatically detect how to parse each file. Select this option for most use cases, even if the source contains files in more than one format. The platform will automatically detect the file format ( AVRO, CSV, EDI, Excel, JSON, ORC, Parquet, TSV, XML, etc.) based on the file extensions.
         * * `Custom Text Format`: (Custom Text Parser) Force all files to be parsed as custom text files.
         * * `XML`: (XML Parser) Force all files to be parsed as XML-formatted files.
         * * `JSON`: (JSON Parser) Force all files to be parsed as JSON-formatted files.
         * * `EDI`: (EDI Parser) Force all files to be parsed as EDI-formatted files.
         * * `Log File`: (Log File Parser) Force all files to be parsed as Log File-formatted files.
         * * `ORC`: (ORC Parser) Force all files to be parsed as ORC-formatted files.
         * * `AVRO`: (AVRO Parser) Force all files to be parsed as AVRO files.
         * * `Parquet`: (Parquet Parser) Force all files to be parsed as Parquet files.
         * * `Excel`: (Excel Parser) Force all files to be parsed as Excel files.
         * * `Fixed Width`: (Fixed Width File Parser) Force all files to be parsed as fixed-width files.
         * * `PDF`: (PDF Parser) Force all files to be parsed as PDF files.
         * * `Unstructured`: (Unstructured.io Parser) This file parsing options leverages Unstructured.io's AI to parse unstructured data. Choose this option if you want customizations to how the files are parsed and Automatic parsing is not sufficient.
         * * `SWIFT`: (SWIFT File Parser) This file parser is useful when all the files are SWIFT file. Choose this option if you want customizations to how the files are parsed and Automatic parsing is not sufficient.
         * * `Raw File Data`: (Override with Custom File Processor) Use this option if you want to bypass Nexla's native parsers and only want to use custom file processors for parsing file content.
         *
         * @enum {string}
         */
        advanced_settings?: "Auto Detect" | "Custom Text Format" | "XML" | "JSON" | "EDI" | "Log File" | "ORC" | "AVRO" | "Parquet" | "Excel" | "Fixed Width" | "PDF" | "Unstructured" | "SWIFT" | "Raw File Data";
        /**
         * @description __Force Files to detect to:__ Configure this setting to make the platform ignore file extensions and instead parse files as if they had a different extension.
         *
         *   For example, if the files have a `.dat` extension but contain JSON content, set this to `*:json`, and the platform will process the files as if they were JSON files.
         *
         *   __Required__ if `advanced_settings` is anything other than `Auto Detect`
         *
         * * `*:txt` if `advanced_settings` is `XML`
         * * `*:xml` if `advanced_settings` is `JSON`
         * * `*:json` if `advanced_settings` is `XML`
         * * `*:edi` if `advanced_settings` is `EDI`
         * * `*:log` if `advanced_settings` is `Log File`
         * * `*:orc` if `advanced_settings` is `ORC`
         * * `*:avro` if `advanced_settings` is `AVRO`
         * * `*:parquet` if `advanced_settings` is `Parquet`
         * * `*:xlsx` if `advanced_settings` is  `Excel`
         * * `*:fw` if `advanced_settings` is `Fixed Width`
         * * `*:pdf` if `advanced_settings` is `PDF`
         * * `*:unstructured` if `advanced_settings` is `Unstructured`
         * * `*:swift` if `advanced_settings` is `SWIFT`
         *
         * @enum {string}
         */
        "overriden.extensions"?: "*:txt" | "*:xml" | "*:json" | "*:edi" | "*:log" | "*:orc" | "*:avro" | "*:parquet" | "*:xlsx" | "*:fw" | "*:pdf" | "*:unstructured" | "*:swift";
        /**
         * @description __Text Delimiter__: Delimiters are used to automatically split each row of data into multiple attributes. Select one of these common delimiters, or enter the character that you wish to use as a delimiter.
         *
         * Only applicable if `advanced_settings` is `Custom Text Format`
         * Default Value: `,`
         *
         * Common Values:
         * * `,`: Comma
         * * `\t`: Tab
         * * `\\n`: Newline
         * * `;`: Semicolon
         * * `|`: Pipe
         * * `^`: Caret
         */
        "csv.delimiter"?: string;
        /**
         * @description __Text Qualifier Character__: Usually, text in one row is separated into multiple attributes based on the delimiter. A qualifier character is used to wrap together the text that should be treated as one attribute even if it includes occurrences of the delimiter.\\n\\n Leave this field blank if you wish to use the default qualifier `"`. For example, most CSV file generators use `"` as the qualifier; thus, `"one,two"` can be one attribute.
         *
         * Only applicable if `advanced_settings` is `Custom Text Format`
         * Default Value: `"`
         */
        "csv.quote.char"?: string;
        /**
         * @description __Escape Character__: When reading CSV files, delimiters (like commas) separate fields and text qualifiers (like quotes) wrap fields. But sometimes these special characters need to appear within the field values themselves. The escape character is used to indicate that the character following it should be treated as regular text, not as a delimiter or qualifier.
         *
         * By default, backslash (`\\`) is used as the escape character. If your data contains backslashes that should be treated as regular text (not as escape characters), you should leave this field empty.
         * If your CSV parsing is failing, try leaving this field empty, especially if your data uses doubled quotes (`\"`) to escape quotes or if you want backslashes to be treated as regular characters.
         *
         * Only applicable if `advanced_settings` is `Custom Text Format`
         * Default Value: `\\`
         */
        "csv.escape.char"?: string;
        /**
         * @description __Schema Attribute Detection Mode__: Configure this option to control how the platform should set Nexset schema attribute names for each column of data. Set this option to __generated__ if your file does not have a row that should be treated as the header row, and the platform will assign attribute names like `attribute1` and `attribute2`.
         *
         * Only applicable if `advanced_settings` is `Custom Text Format`
         * Default Value: `header`
         *
         * * `header`: Select this option if the file contains a header row. Detected Nexset attribute names will be derived from the column names in the header row.
         *
         * * `generated`: Select this option if the file does not contain a header row. Nexla will automatically assign attribute names to each column of data.
         */
        "csv.schema.detection"?: string;
        /**
         * @description __Skip Lines at the Head__: The platform can be configured to skip the first few lines of each file before it starts ingesting data into records. Set this option if a fixed number of rows in each file should be ignored.
         *
         * Only applicable if `advanced_settings` is `Custom Text Format`
         * Default Value: `0`
         */
        "csv.skip.first.lines"?: number;
        /**
         * @description __Schema Attribute Detection Mode__: Configure this option to control how the platform should set Nexset schema attribute names for each column of data. Set this option to __generated__ if your file does not contain a row that should be treated as the header row, and the platform will assign attribute names like `attribute1` and `attribute2`.
         *
         * Only applicable if `advanced_settings` is `Excel`
         * Default Value: `header`
         *
         * * `header`: Select this option if the file contains a header row. Detected Nexset attribute names will be derived from the column names in the header row.
         *
         * * `generated`: Select this option if the file does not contain a header. Nexla will automatically assign attribute names to each column of data.
         *
         * @enum {string}
         */
        "excel.schema.detection"?: "header" | "generated";
        /**
         * @description __(Optional) Data Records Cell Range__: Configure the relevant cell range if you want only specific cells in your sheets to be scanned.
         *
         * This is an optional field. Leave the field blank if you want all cells to be ingested. You can specify multiple ranges by using comma-separated values.
         *
         * For example, `sheet1!A1:B5,sheet2!C2:D5` will ingest cells `A1:B5` from `sheet 1` and cells `C2:D5` from `sheet2`.
         *
         * Only applicable if `advanced_settings` is set to `Excel`
         */
        sheets?: string;
        /**
         * @description __(Optional) Metadata Cell Range__: By setting the `Data Records Cell Range` above you have configured the part of file that should be ingested by Nexla as individual records.
         *
         * But sometimes, you might want some common data in the file outside those cells that should be included in each record. Set this field to the appropriate cells path format and Nexla will include those attributes in each ingested record.
         *
         * 1. General format is `<sheetname>_<attributecell>:<valuecell>|...|<attributecellN>:<valuecellN>`
         *
         * 2. Split attribute cell from value cell by using `:` delimiter (`<attributecell>:<valuecell>`)
         *
         * 3. Split different key-value pairs by using `|` delimiter (`<attributecell_1>:<valuecell_1>|<attributecell_2>:<valuecell_2>`)
         *
         * 4. Specify sheetname following with `_` to read from the specific sheet.
         *
         * 5. Do not specify sheetname if you want to read from first single sheet by default.
         *
         * Only applicable if `advanced_settings` is set to `Excel`
         */
        "excel.range.additional"?: string;
        /**
         * @description __Skip Merged cells?__: The platform can be configured to skip merged cells when it is ingesting data into records. Select this option if you want merged cells to be skipped.
         *
         * Only applicable if `advanced_settings` is set to `Excel`
         * Default Value: `false`
         */
        "excel.skip.merged.cells"?: boolean;
        /**
         * @description __JSON Ingestion Mode__: JSON text files generated by data processing systems are often saved in JSON Line format, in which each row in the file is a valid JSON object instead of the entire file being a valid JSON object.
         *
         * Only applicable if `advanced_settings` is set to `JSON`
         * * `row`: Each row is a separate JSON object.
         * * `entire.file`: The entire file is a valid JSON object.
         *
         * @enum {string}
         */
        "json.mode"?: "row" | "entire.file";
        /**
         * @description __JSON Path To Data (when Ingestion Mode = entire.file)__: When JSON Ingestion Mode is set to `entire.file`, you can configure the platform to only ingest part of the JSON object.
         *
         * Set this path in JSON Path format to configure the area of the file from this Source that should be processed.
         *
         * Only applicable if `advanced_settings` is set to `JSON` and `json.mode` is `entire.file`
         */
        "json.path"?: string;
        /**
         * @description __Path to Additional JSON data__: Setting the `JSON Path to Data` above configures the part of the data file that should be ingested by Nexla as individual records.
         *
         * However, sometimes, you might want some common data in the file that is located outside of the entered JSON Path to be included in each record. Set this field to the appropriate file content in JSON path format, and Nexla will include that attribute in each ingested record.
         *
         * Only applicable if `advanced_settings` is set to `JSON` and `json.mode` is `entire.file`
         */
        "json.path.additional"?: string;
        /**
         * @description __XML Ingestion Mode__: XML files generated by data processing systems are often saved such that each row of the file is a valid XML object instead of the entire file being a valid XML object.
         *
         * Only applicable if `advanced_settings` is set to `XML`
         *
         * * `row`: Each row is a separate XML object.
         * * `entire.file`: Entire file is a valid XML object.
         *
         * @enum {string}
         */
        "xml.mode"?: "row" | "entire.file";
        /**
         * @description __XPath to Data (when Ingestion Mode = entire.file)__: When XML Ingestion Mode is set to `entire.file` you can configure the platform to only ingest part of the XML object.
         *
         * Set this path in XPath format to configure the area of the file from this Source that should be processed.
         *
         * Only applicable if `advanced_settings` is set to `XML`  and `xml.mode` is set to `entire.file`
         */
        "xml.xpath"?: string;
        /**
         * @description __Path to Additional XML data__: Setting the `XPath to Data` above configures the part of the data file that should be ingested by Nexla as individual records.
         *
         * However, sometimes, you might want some common data in the file that is located outside of the entered XPath to be included in each record. Set this field to the appropriate file content in XPath format, and Nexla will include that attribute in each ingested record.
         *
         * Only applicable if `advanced_settings` is set to `XML`  and `xml.mode` is set to `entire.file`
         */
        "xml.xpath.additional"?: string;
        /**
         * @description __EDI XPath__: Set the path (in XPath format) to the area of the file that should be processed as EDI content. Note that this option is necessary when the entire file isn't a valid EDI file and only a portion of the file content is valid EDI content
         *
         * Only applicable if `advanced_settings` is set to `EDI`
         */
        "edi.xpath"?: string;
        /**
         * @description __Grok Pattern__: Each line of a log file is parsed into multiple attributes by applying a Grok Pattern.
         *
         * Grok works by combining text patterns into something that matches your logs. Select one of these predefined patterns, or write your own custom Grok Pattern that should be applied when parsing log files.
         * **Predefined Patterns**: Depending on your log file content, one of these predefined patterns might be best suited for your use case.  Alternately you can also type in your own custom Grok Pattern.
         * - `%{SYSLOGBASE}`
         * - `%{COMBINEDAPACHELOG}`
         * - `%{NAGIOSLOGLINE}`
         * - `%{POSTGRESQL}`
         * - `%{REDISLOG}`
         * - `%{JAVASTACKTRACEPART}`
         *
         * Only applicable if `advanced_settings` is set to `Log File`
         *
         * @enum {string}
         */
        "grok.pattern"?: "%{SYSLOGBASE}" | "%{COMBINEDAPACHELOG}" | "%{NAGIOSLOGLINE}" | "%{POSTGRESQL}" | "%{REDISLOG}" | "%{JAVASTACKTRACEPART}";
        /**
         * @description __Length of Each Field in File__: Enter the length of each field in the file. This should be entered as a comma-separated list of numbers, for ex: `10,12,8,15,20`.
         *
         * __Required__ and __applicable__ only if `advanced_settings` is set to `Fixed Width`.
         */
        "field.lengths"?: string;
        /**
         * @description __Schema Attribute Detection Mode__: Configure this option to control how the platform should set Nexset schema attribute names for each column of data.
         *
         * * `header`: Select this option if the file contains a header row. Detected Nexset attribute names will be derived from the column names in the header row.
         *
         * * `generated`: Select this option if the file does not contain a header row. Nexla will automatically assign attribute names to each column of data.
         *
         * __Applicable__ only if `advanced_settings` is set to `Fixed Width`.
         *
         * @enum {string}
         */
        "fixed.width.schema.detection.mode"?: "header" | "generated";
        /**
         * @description __Padding Character__: Choose or type the character that acts as the separator between fields. For ex: `_`.
         *
         * Only applicable if `advanced_settings` is `Fixed Width`
         * Default: single space ` `
         *
         * Common Values:
         * * ` `: Single Space
         * * `` : No Padding
         * * `,`: Comma
         * * `\\t`: Tab
         * * `\\n`: Newline
         * * `;`: Semicolon
         * * `|`: Pipe
         * * `^`: Caret
         */
        "padding.character"?: string;
        /**
         * @description __Auto detect line separators?__: Set this option on if you wish the platform to automatically detect line separators in the document.
         *
         * Only applicable if `advanced_settings` is `Fixed Width`
         * Default: true
         */
        "line.separator.detection.enabled"?: boolean;
        /**
         * @description __Line Separation Character__: Specify the character that should be recognized by the platform as an indicator of a new line.
         *
         * Only applicable if `advanced_settings` is `Fixed Width` and `line.separator.detection.enabled` is set to `true`.
         *
         * Default:  `\\n`
         *
         * Common Values:
         * * `\\t`: Tab
         * * `\\n`: Newline
         */
        "line.separator"?: string;
        /**
         * @description __Remove Quote Characters?__: Set this option to true if you wish the platform to force remove quotes from strings where it is safe to do so.
         *
         * Only applicable if `advanced_settings` is `Fixed Width`.
         * Default: false
         */
        "remove.quotes.forced"?: boolean;
        /**
         * @description __Quote Character__: Set the character to be treated as a quote character. This is relevant if the Remove Quotes Character setting is enabled.
         *
         * Leave this field blank if you wish to use the default qualifier `"`
         *
         * Only applicable if `advanced_settings` is `Fixed Width` and `remove.quotes.forced` is set to `true`.
         */
        "quote.char"?: string;
        /**
         * @description __Force Scalar Coercion of String Values?__: Set this option on if you wish to force coercion of string values to scalar types.
         *
         * Only applicable if `advanced_settings` is `Fixed Width`
         * Default: true
         */
        "scalar.coercion"?: boolean;
        /**
         * @description __Skip Lines at the Head__: The platform can be configured to skip the first few lines of each file before it starts ingesting data into records. Set this option if a fixed number of rows in each file should be ignored.
         *
         * Only applicable if `advanced_settings` is `Fixed Width`
         * Default Value: `0`
         */
        "fixed.width.skip.first.lines"?: number;
        /**
         * @description __Skip Lines at the Tail__: The platform can be configured to skip the last few lines of each file before it starts ingesting data into records. Set this option if a fixed number of rows in each file should be ignored.
         *
         * Only applicable if `advanced_settings` is `Fixed Width`
         * Default Value: `0`
         */
        "fixed.width.skip.last.lines"?: number;
        /**
         * @description __Parsing mode__: Choose the mode for extracting text from the PDF Files.
         *
         * The `text` strategy is used to extract the textual layer from the PDF file. It will emit one record per page. The `semi-auto` strategy uses hints to extract structured data from the PDF file.
         *
         * * `text`: This strategy is used to extract the textual layer from the PDF file. It will emit one record per page with two attributes: `type` with value `text`, and `text` with value equal to extracted content of entire page.
         *
         * * `semi-auto`: This strategy uses hints to extract structured data from the PDF file.
         *
         * * `auto-1`: (auto-textract) This strategy uses Textract for parsing PDF file.
         *
         * * `auto-2`: (auto-tesseract) This strategy uses Tesseract for parsing PDF file.
         *
         * * `image`: (image) This strategy exports each page as a Base64-encoded PNG image.
         *
         * __Applicable__ only if `advanced_settings` is set to `PDF`.
         *
         * @enum {string}
         */
        "pdf.parsing.strategy"?: "text" | "semi-auto" | "auto-1" | "auto-2" | "image";
        /**
         * @description __Page Metadata Inclusion Mode__: Choose the mode for including page metadata in the generated content. This is relevant if you are generating embeddings from the source and wish to include information like page number in the embedded content.
         *
         * * `default`: (Default: Exclude From Data) This strategy is used to extract the textual layer from the PDF file. It will emit one record per page with two attributes: `type` with value `text`, and `text` with value equal to extracted content of entire page.
         *
         * * `embedded`:(Embedded: Include With Embeddings) Choose this option if you wish to include page metadata in embeddings. This is only relevant if you have opted into generating embeddings.
         *
         * * `extended`: (Extended: Include Without Embeddings)  Choose this option if you wish to include page metadata in the generated content when embeddings are not generated.
         *
         * * `table.as.message`: (Message Per Table) Choose this option if you wish to emit one message per table in the document. This option is useful if your processing logic requires table-level granularity.
         *
         * * `document.as.message`: (File Content as Message) Choose this option if you wish to emit one message for entire file. This option is useful if your processing logic requires file-level granularity.
         *
         * __Applicable__ only if `advanced_settings` is set to `PDF`.
         *
         * @default default
         * @enum {string}
         */
        "pdf.rendering.strategy"?: "default" | "embedded" | "extended" | "table.as.message" | "document.as.message";
        /**
         * @description __Extract Text Blocks?__: When parsing a PDF file only table blocks are extracted. This option allows you to extract additional text blocks between table blocks as record.
         *
         * __Applicable__ only if `advanced_settings` is set to `PDF` and `pdf.parsing.strategy` is `semi-auto`.
         *
         * Default: true
         */
        "pdf.parsing.emitTextBlocks"?: boolean;
        /**
         * @description __(Optional) Document Password__: Enter the password for opening and processing the PDF files if they are password protected.
         *
         * __Applicable__ only if `advanced_settings` is set to `PDF`.
         */
        "pdf.document.password"?: string;
        /**
         * @description __Placeholder Text for empty values__: Set the text placeholder to be used if a cell in the parsed table is empty.
         *
         * __Applicable__ only if `advanced_settings` is set to `PDF`.
         *
         * Default: `(blank)`
         */
        "pdf.parsing.emptyValuePlaceholder"?: string;
        /**
         * @description __Configuration Settings for Extracting Tables__:  Set this property with all configuration settings required for extracting Nexla records from different slices of structured data in the file. This property must be a valid JSON object, with some or all of the keys listed below.
         *
         * 1. `columns`: This must be an array of column names in the table. This is the only **required** property in this object. Column names should be listed from left to right or top to bottom. There are two special values : `(blank)` for a column without a name in the table and `(column)` or `(column=Desired Name)` for empty columns.
         *
         * 2. `forceBoldHeaders`: A boolean that defaults to false. If true, this property only treats headers that are in bold as attribute names.
         *
         * 3. `forceFullWidth`: A boolean that defaults to true. If true, the parser uses entire page width as table width, else the parser tries to treat least possible width as table width.
         *
         * 4. `header`: Configures whether columns are defined horizontally (value `ROW`) or vertically (value `COLUMN`).
         *
         * 5. `tupleNumber`: An integer value if the header mode is set to COLUMN and the table does not take up entire page width.
         *
         * 6. `spacing`: A double data type used for tuning for complex documents. Defaults to 2.5
         *
         *
         * __Applicable and required__ if `advanced_settings` is set to `PDF` and `pdf.parsing.strategy` is `semi-auto`.
         *
         * Example: `[{\n\t\"columns\": [  ]\n}]`
         */
        "pdf.parsing.tables"?: string;
        /**
         * @description __Extract Text Blocks?__: Set this option to true if you wish to extract text blocks from the PDF file.
         *
         * __Applicable__ only if `advanced_settings` is set to `PDF` and `pdf.parsing.strategy` is `auto-1`.
         *
         * Default Value: `true`
         */
        "pdf.parsing.auto-1.outputText"?: boolean;
        /**
         * @description __Extract Table Blocks?__: Set this option to true if you wish to extract table blocks from the PDF file.
         *
         * __Applicable__ only if `advanced_settings` is set to `PDF` and `pdf.parsing.strategy` is `auto-1`.
         *
         * Default Value: `true`
         */
        "pdf.parsing.auto-1.outputTables"?: boolean;
        /**
         * @description __Image Scale__: Set the scale factor for the image.
         *
         * __Applicable__ only if `advanced_settings` is set to `PDF` and `pdf.parsing.strategy` is `image`.
         *
         * Default Value: `1.25`
         */
        "pdf.parsing.image.scale"?: string;
        /**
         * @description __Content Type for Compressed Files__: In case the files in your file system are compressed files, set this to the expected content type of the files after they have been uncompressed.
         *
         * * `application/pdf`: Set this if the files are compressed PDF files.
         *
         * __Applicable__ only if `advanced_settings` is set to `Unstructured`.
         *
         * @enum {string}
         */
        "unstructured.gz.uncompressed.content.type"?: "application/pdf";
        /**
         * @description __Content Encoding Method__: Set this to the content encoding method that should be used for decoding text input.
         *
         * __Applicable__ only if `advanced_settings` is set to `Unstructured`.
         */
        "unstructured.encoding"?: string;
        /**
         * @description __Include Page Breaks?__: Set this option to true if you wish to include page breaks in the extracted content.
         *
         * __Applicable__ only if `advanced_settings` is set to `Unstructured`.
         *
         * @default false
         */
        "unstructured.include.page.breaks"?: boolean;
        /**
         * @description __Infer Table Structure In PDFs?__: Set this to true if you wish to include 'text_as_html' metadata for table elements within PDFs.
         *
         * __Applicable__ only if `advanced_settings` is set to `Unstructured`.
         *
         * @default false
         */
        "unstructured.pdf.infer.table.structure"?: boolean;
        /**
         * @description __Chunking Strategy__: Set this to the strategy for chunking the returned elements. Leave it blank for default strategy.
         *
         * * ``: Default strategy.
         * * `by_title`: Chunk by title.
         *
         * __Applicable__ only if `advanced_settings` is set to `Unstructured`.
         *
         * @enum {string}
         */
        "unstructured.chunking.strategy"?: "" | "by_title";
        /**
         * @description __Allow Sections to Span Multiple Pages__: Set this to true for allowing sections to span multiple pages. This is only applicable if chunking strategy has been set.
         *
         * __Applicable__ only if `advanced_settings` is set to `Unstructured` and `unstructured.chunking.strategy` is set to `by_title`.
         *
         * @default true
         */
        "unstructured.multipage.sections"?: boolean;
        /**
         * @description __Minimum # of characters for combing elements__: Set this to minimum number of characters in a section until which elements should be combined.
         *
         * __Applicable__ only if `advanced_settings` is set to `Unstructured` and `unstructured.chunking.strategy` is set to `by_title`.
         *
         * @default 500
         */
        "unstructured.combine.under.n.chars"?: number;
        /**
         * @description __(Soft) Maximum # of characters in a section__: Set this to (soft) maximum number of characters that can be present in a section. This is a soft maximum. A new section will be created soon after / before this number is hit.
         *
         * __Applicable__ only if `advanced_settings` is set to `Unstructured` and `unstructured.chunking.strategy` is set to `by_title`.
         *
         * @default 1500
         */
        "unstructured.new.after.n.chars"?: number;
        /**
         * @description __(Hard) Maximum # of characters in a section__: Set this to (hard) maximum number of characters that can be present in a section.
         *
         * __Applicable__ only if `advanced_settings` is set to `Unstructured` and `unstructured.chunking.strategy` is set to `by_title`.
         *
         * @default 1500
         */
        "unstructured.max.characters"?: number;
        /**
         * @description __Is lenient?__: Indicates whether the parser is permissive or not. Defaults to true, meaning the parser will do a best effort to read as much from the message content as possible regardless of the content and block boundaries being valid or not.
         *
         * __Applicable__ only if `advanced_settings` is set to `SWIFT`.
         *
         * Default Value: `true`
         *
         * @default true
         */
        lenient?: boolean;
        /**
         * @description __Should Parse Text Block?__: Set this to true you if you wish the text block (block 4) to be parsed.
         *
         * __Applicable__ only if `advanced_settings` is set to `SWIFT`.
         *
         * Default Value: `true`
         *
         * @default true
         */
        "parse.text.block"?: boolean;
        /**
         * @description __Should Parse Trailer Block?__: Set this to true you if you wish the trailer block (block 5) to be parsed.
         *
         * __Applicable__ only if `advanced_settings` is set to `SWIFT`.
         *
         * Default Value: `true`
         *
         * @default true
         */
        "parse.trailer.block"?: boolean;
        /**
         * @description __Should Parse User Block?__: Set this to true you if you wish the user block to be parsed.
         *
         * __Applicable__ only if `advanced_settings` is set to `SWIFT`.
         *
         * Default Value: `true`
         *
         * @default true
         */
        "parse.user.block"?: boolean;
        /**
         * @description __Runtime Data Credentials For LLM__: Set the Nexla Credential Id for the OpenAI API that should be used for generating embeddings.
         *
         * __Applicable and required__ only if `post.processor` is set to `true`.
         */
        runtime_data_credentials_id?: number;
        /**
         * @description __Embedding Model__: Set the model that should be used for generating embeddings.
         *
         * __Applicable and required__ only if `post.processor` is set to `true`.
         *
         * Example: `text-embedding-ada-002`
         */
        model?: string;
        /**
         * @description __Attribute for embeddings__: Set the data property that should be used for generating embeddings. For example, if your input data has a property called `text` that you wish to use for embeddings, set this value to `text`.
         *
         * __Applicable and required__ only if `post.processor` is set to `true`.
         *
         * Example: `text`
         */
        property?: string;
        /**
         * @description __Chunking Limit__: Set the size segments that the parsed text should be broken down to.
         *
         * __Applicable__ only if `post.processor` is set to `true`.
         *
         * Default Value: `1000`
         *
         * @default 1000
         */
        chunk_threshold?: number;
        /**
         * @description __AI Function ID__: Set the Nexla AI function to be used for post-processing these files before the data is delivered to the Nexset.
         *
         * __Applicable__ only if `ai.function` is set to `true`.
         */
        "ai.function.id"?: number;
        /**
         * Format: epoch
         * @description __Only read files modified after:__ Set this property to indicate whether the platform should skip the ingestion of some files based on the file modification date.
         *
         * Note that the platform always keeps track of whether or not a file has been processed. Therefore, changes to a previously ingested (or ignored) file that cause a change in its modification date do result in the file being processed again.
         *
         * Default value: ''
         */
        "ignore.files.older.than.ms"?: number;
        /**
         * @description __Customize Paths to be Scanned/Ignored__: Once you have selected a root bucket/folder/path to be scanned for data, you can further indicate specific path patterns to be scanned or ignored within the selected pattern.
         *
         * Enable this setting and configure the relevant path patterns if you want the platform to scan (or ignore) all sub-folders or files that match a pattern.
         *
         * Default Value: `false`
         */
        path_exclusions?: boolean;
        /**
         * @description __Paths to be scanned Eg. **\/Done/__: Configure a path pattern if you want to only scan sub-folders or files that match a pattern. For example, enter `**\/ABC/*` if you would like to only scan files in the subfolder ABC.
         *
         * **Note**:
         * 1. Patterns must match the **Apache Ant Path Pattern**. See [Apache Ant Path Documentation](https://ant.apache.org/manual/dirtasks.html) for examples.
         * 2. Patterns must start from the root of the location accessible to the credentials.
         * 3. You will still need to select a base folder (root or a subfolder). Only pattern matches that are inside the selected base folder will be scanned.
         *
         *  Only applicable if  `path_exclusions` is `true`
         */
        "whitelist.pathmatchers"?: string;
        /**
         * @description __Paths NOT to be scanned. E.g., **\/archives/__: Configure a path pattern if you do __NOT__ want to scan sub-folders or files that match a pattern. For example, enter `**\/ABC/*` if you would like to ignore files that are in the subfolder ABC.
         * **Note**
         * 1. Patterns must match the **Apache Ant Path Pattern**. See [Apache Ant Path Documentation](https://ant.apache.org/manual/dirtasks.html) for examples.
         * 2. Patterns must start from the root of the location accessible to the credentials.
         * 3. You will still need to select a base folder (root or a subfolder). Only pattern matches that are inside the selected base folder will be ignored.
         *
         * Only applicable if  `path_exclusions` is `true`
         */
        "blacklist.pathmatchers"?: string;
        /**
         * @description __Timezone for Path Format__
         * Only applicable if  `path_exclusions` is `true`
         */
        timezone?: string;
        /**
         * @description __Force a Single Schema__: The platform's automatic Nexset detection mechanism ensures that similar files are always processed as the same Nexset, even if the file extensions are different.
         *
         * However, sometimes, it might be beneficial to bypass Nexset detection and enforce a single schema. Use this setting to force the platform to only detect one Nexset for this Source.
         *
         * For example, you might want to force a single schema in the following scenarios:
         * 1. Your business case requirement is time-sensitive to any processing latencies, and you know that the data will always be in the same structure. While the Schema Detector does not incur a large overhead per file, for high file volumes, bypassing this additional processing might result in noticeable improvement.
         * 2. You know that files should always be processed as the same Nexset, but there is a high likelihood of sparse data. As the Detector might not find significant overlap in the case of sparse data, enforcing a single schema will ensure that the detector will only grow the Nexset, regardless of the presence or absence of overlapping.
         *
         * Default Value: `false`
         */
        "schema.detection.once"?: boolean;
        /**
         * @description __Enable Grouping__: Set this option and associated settings if you have files in which rows of data need to be combined based on the value of a key.
         *
         * For example, this is useful if you have CSV files with a column __order_number__ in addition to other columns of information about that order, and instead of including each row as a unique record, you want a Nexset in which all orders with the same number are concatenated as one record at the time of ingestion. To produce a Nexset with the record structure including the attribute __order_number__ and another attribute __order_details__, with an array of objects containing the values of the other columns, you can set __order_number__ as the __Grouping Key Attribute__ and __order_details__ as the __Grouped Field Name__.
         *
         * Default Value: `false`
         */
        allowGrouping?: boolean;
        /**
         * @description __Grouping Key Attribute__: The name of the column/attribute based on which grouping needs to be performed.
         *
         * For example, if you have CSV files with a column __order_number__ in addition to other columns of information about that order and grouping needs to be performed based on the column __order_number__, set the value in this box to __order_number__. Data will now be grouped by the __order_number__.
         *
         * Required and only applicable if ` allowGrouping` is `true`.
         */
        "group.by.keys"?: string;
        /**
         * @description __Grouped Field Name__: Enter the attribute name for the grouped object in the resulting Nexset.
         *
         * For example, if you have CSV files with a column __order_number__ in addition to other columns of information about that order, and grouping needs to be performed based on the __order_number__, set this input to __order_details__. The resulting Nexset will contain the attribute __order_details__, which will include an array of objects containing the content of each row of grouped data.
         *
         * Required and only applicable if ` allowGrouping` is `true`.
         */
        "group.field.name"?: string;
        /**
         * @description __Publish value of null key in grouping__: You can configure how the platform should process rows of data in which the Grouping Key Attribute is missing.
         *
         * Turn on this setting, and the platform will assign such rows to a Grouping Key Attribute with the value `null`. Turn off this setting, and the platform will ignore such rows.
         *
         * Only applicable if ` allowGrouping` is `true`
         */
        "group.publish.null.key"?: string;
      };
    };
    azure_blb_data_source: {
      source_type: "azure_blb";
    } & Omit<components["schemas"]["data_source"], "source_type"> & components["schemas"]["file_data_source"];
    azure_data_lake_data_source: {
      source_type: "azure_data_lake";
    } & Omit<components["schemas"]["data_source"], "source_type"> & components["schemas"]["file_data_source"];
    azure_synapse_data_source: {
      source_type: "azure_synapse";
    } & Omit<components["schemas"]["data_source"], "source_type"> & components["schemas"]["WithoutCDCSupport"];
    bigquery_data_source: {
      source_type: "bigquery";
    } & Omit<components["schemas"]["data_source"], "source_type"> & components["schemas"]["WithoutCDCSupport"];
    box_data_source: {
      source_type: "box";
    } & Omit<components["schemas"]["data_source"], "source_type"> & components["schemas"]["file_data_source"];
    WithCDCSupport: {
      source_config?: {
        /**
         * @description __Scheduling Frequency__: The interval at which Nexla should scan this source for new data. This must be in the form of a cron expression.
         *
         * @example 0 0 22 10 11 ? 2022
         */
        "start.cron": string;
        /**
         * @description __Database Fetch Mode__: Database connectors are designed to support self-serve capabilities for use cases ranging from simple table ingestion to ingestion based on complex custom queries.
         *
         * * `Default`: Equivalent to running a simple (but optimized) SELECT clause on any database table, along with some additional customizations for filtering rows.
         *
         * * `Query`: Execute data fetching based on a custom database query using the syntax and convention supported by the underlying database/warehouse.
         *
         * @enum {string}
         */
        db_query_mode: "Default" | "Query";
        /**
         * @description __Query__: Set the Query to be executed during each ingestion cycle.
         *
         * __Required__ if `db_query_mode` is `Query`
         */
        query?: string;
        /**
         * @description __Database__: Database whose table needs to be scanned for data.
         *
         * __Required__ if `db_query_mode` is `Default`
         */
        database?: string;
        /**
         * @description __Table__: Table that needs to be scanned for data.
         *
         * __Required__ if `db_query_mode` is `Default`
         */
        table?: string;
        /**
         * @description __Table Scan Mode__: The default configuration of Table Mode is set to read all data in a table in each ingestion cycle, which is equivalent to a running `SELECT` clause on the table. However, when the table contains much more historical data than you wish to scan, you can instruct the platform to begin loading from a specific __id__ (stored in a numeric column), __timestamp__ (stored in a date-time column) or __both id and timestamp__.
         *
         * You can use the relevant Table Scan Mode to address this use case of partial loading from a table.
         *
         * Note that this can also be achieved by writing a properly structured query in Query Mode.
         *
         * Only applicable if `db_query_mode` is `Default` and `cdc.enabled` is `false`
         * Default Value: `none`
         *
         * * `none`: Read the whole table
         *
         * * `incrementing`: Start reading from a specific ID
         *
         * * `timestamp`: Start reading from a specific timestamp
         *
         * * `incrementing,timestamp`: Start reading from a specific ID and timestamp
         *
         * @enum {string}
         */
        mode?: "none" | "incrementing" | "timestamp" | "incrementing,timestamp";
        /**
         * @description __ID Column__: The ID column that should be used for executing partial data loading from the selected table. This must be a numeric column.
         *
         * Only applicable if `db_query_mode` is `Default` and `mode` is `incrementing` or `incrementing,timestamp`
         */
        "incrementing.column.name"?: string;
        /**
         * @description __Starting ID__: The starting ID value of __ID Column__ from which the platform should start ingesting data.
         *
         * Only applicable if `db_query_mode` is `Default` and `mode` is `incrementing` or `incrementing,timestamp`
         */
        "incrementing.load.from"?: string;
        /**
         * @description __Timestamp Column__: The timestamp column that should be used for executing partial data loading from the selected table. This must be a date-time column.
         *
         * Only applicable if `db_query_mode` is `Default` and `mode` is `timestamp` or `incrementing,timestamp`
         */
        "timestamp.column.name"?: string;
        /**
         * @description __Starting Timestamp__: The timestamp value of the __Timestamp Column__ from which the platform should start ingesting data. This must be a UNIX epoch- (milliseconds) or ISO-formatted date value (e.g., 2016-01-01T12:13:14).
         *
         * Only applicable if `db_query_mode` is `Default` and `mode` is `timestamp` or `incrementing,timestamp`
         */
        "timestamp.load.from"?: number | string;
        /**
         * Format: boolean
         * @description __Perform Database Commit after Read?__: You can instruct the platform to execute a database commit if the query includes statements that should also be committed to the database after ingestion. This is typically not the case, so most of the time, the value should be left as false.
         *
         * Only applicable if `db_query_mode` is `Query`
         *
         * Default Value: `"false"`
         *
         * @enum {string}
         */
        "commit.on.read"?: "false" | "true";
        /**
         * @description __Enable Change Data Capture (CDC)__: Select this option if you would like the platform to monitor database transaction logs to determine data ingestion.
         *
         * Note that your DBA will need to grant necessary Change Data Capture permissions to allow Nexla to access transaction logs. Contact Nexla support for relevant instructions.
         *
         * If limitations that prevent you from enabling CDC controls on your database are in place, you can still set up this source for incremental ingestion by disabling this option and instead selecting incremental table ingestion rules.
         *
         * Default value: `false`
         *
         * __Applicable__ if `db_query_mode` is `Default`
         */
        "cdc.enabled"?: boolean;
        /**
         * @description __CDC: Ingest Initial Snapshot__: Choose this option if you want to perform a one-time historical load of all data in the table during the first ingestion from the source. If this option is disabled, only events observed after the source is first activated will be processed.
         *
         * Default value: `false`
         *
         * __Applicable__ if `db_query_mode` is `Default` and `cdc.enabled` is `true`
         */
        "cdc.snapshot.enabled"?: boolean;
        /**
         * @description __CDC: Track Deletions__: Choose this option if you also need to track deletions.
         *
         * You might want this option enabled if you intend to link this source to a destination that needs to be kept in sync with the source by tracking and removing any rows that have been deleted.
         *
         * With this option enabled, the detected Nexset will include a Nexset record for each deletion event. This record will always contain a `nexla_op` attribute with the value `DELETE`. Additionally, it will include either the primary key of the deleted row or, if the table contains no primary key columns, the content of the entire row.
         *
         * Default value: `false`
         *
         * __Applicable__ if `db_query_mode` is `Default` and `cdc.enabled` is `true`
         */
        "cdc.capture.delete"?: boolean;
      };
    };
    cloudsql_mysql_data_source: {
      source_type: "cloudsql_mysql";
    } & Omit<components["schemas"]["data_source"], "source_type"> & components["schemas"]["WithCDCSupport"];
    cloudsql_postgres_data_source: {
      source_type: "cloudsql_postgres";
    } & Omit<components["schemas"]["data_source"], "source_type"> & components["schemas"]["WithCDCSupport"];
    cloudsql_sqlserver_data_source: {
      source_type: "cloudsql_sqlserver";
    } & Omit<components["schemas"]["data_source"], "source_type"> & components["schemas"]["WithCDCSupport"];
    stream_data_source: {
      source_config?: {
        /**
         * @description __Scheduling Frequency__: The interval at which Nexla should scan this source for new files. This must be in the form of a cron expression.
         *
         * @example 0 0 22 10 11 ? 2022
         */
        "start.cron": string;
        /**
         * @description __Data Format__: Select the data format parser for the data in the topic. This is usually JSON.
         *
         * @enum {string}
         */
        "parser.type": "json" | "csv" | "tsv" | "txt" | "xml";
      };
    };
    confluent_kafka_data_source: {
      source_type: "confluent_kafka";
    } & Omit<components["schemas"]["data_source"], "source_type"> & components["schemas"]["stream_data_source"] & ({
      source_config?: {
        /** @description __Topic__: Select the topic for your data. */
        topic: string;
        /**
         * @description __Offset Mode__: You can configure the default offset mode to be used for reading data from the topic.
         *
         * Usually set to `earliest`
         *
         * @enum {string}
         */
        "offset.mode"?: "earliest" | "from_date" | "latest" | "manual";
        /**
         * @description __Consume Data From Date__: You can choose to configure this source for reading data from a specific date. Enter the starting date for data ingestion.
         *
         * __Required__ if `offset.mode` is `from_date`
         */
        "start.from.date"?: string;
        /**
         * @description __Consume Data From Offset__: You can choose to configure this source for reading data from a specific offset. Enter the starting offset for data ingestion.
         *
         * __Required__ if `offset.mode` is `manual`
         */
        "start.from.offsets"?: string;
        /**
         * @description __Data Format__: Select the data format parser for the data in the topic. This is usually JSON.
         *
         * @enum {string}
         */
        "parser.type"?: "json" | "csv" | "tsv" | "txt" | "xml" | "avro";
        /**
         * @description __Key Deserializer__: Enter the type of key deserializer that should be used to read keys from the Kafka topic. This is usually in the form `org.apache.kafka.common.serialization.StringDeserializer`.
         *
         * Recommended default value:
         * - `org.apache.kafka.common.serialization.StringDeserializer` if `parser.type` is `csv`, `tsv`, `txt`, `xml`, or `json`
         * - `org.apache.kafka.common.serialization.ByteArrayDeserializer` if `parser.type` is `avro`
         */
        "key.deserializer"?: string;
        /**
         * @description __Value Deserializer__: Enter the type of value deserializer that should be used to read from the Kafka topic. This is usually in the form `org.apache.kafka.common.serialization.StringDeserializer`.
         *
         * Recommended default value:
         * - `org.apache.kafka.common.serialization.StringDeserializer` if `parser.type` is `csv`, `tsv`, `txt`, `xml`, or `json`
         * - `org.apache.kafka.common.serialization.ByteArrayDeserializer` if `parser.type` is `avro`
         */
        "value.deserializer"?: string;
        /**
         * @description __Serialization Variant__: Set the variant of serializer for processing data. This is required for AVRO parser. Typically this should be set to `confluent`.
         *
         * __Applicable__ if `parser.type` is `avro`
         */
        "serialization.variant"?: string;
      };
    });
    databricks_data_source: {
      source_type: "databricks";
    } & Omit<components["schemas"]["data_source"], "source_type"> & components["schemas"]["WithoutCDCSupport"];
    db2_data_source: {
      source_type: "db2";
    } & Omit<components["schemas"]["data_source"], "source_type"> & components["schemas"]["WithoutCDCSupport"];
    dropbox_data_source: {
      source_type: "dropbox";
    } & Omit<components["schemas"]["data_source"], "source_type"> & components["schemas"]["file_data_source"];
    nosql_data_source: {
      source_config?: {
        /**
         * @description __Ingestion Frequency__: The interval at which Nexla should scan this source for new data. This must be in the form of a cron expression.
         *
         * @example 0 0 22 10 11 ? 2022
         */
        "start.cron": string;
        /**
         * @description __Database__: The database whose collection needs to be scanned for data.
         *
         * __Required__ if the `data_credentials` access for this destination is not limited to one database.
         */
        database?: string;
        /** @description __Collection__: The collection that needs to be scanned for data. */
        collection: string;
        /**
         * @description __Filter Collections__: Instead of reading all the documents in a collection in each ingestion cycle, you can instruct the platform to ingest only some documents.
         *
         * In some scenarios, when the collection contains much more historical data than you wish to scan, you might want to instruct the platform to begin loading from a specific __timestamp__. You can also write your filter queries to set rules based on which documents from the collection should be ingested.
         *
         * - `default`: Read all documents in the collection.
         * - `timestamp`: Start reading from a specific timestamp.
         * - `query`: Filter using Query.
         *
         * @default default
         * @enum {string}
         */
        mode: "default" | "timestamp" | "query";
        /**
         * @description __Timestamp Attribute__: Set the document metadata attribute that should be used to execute partial data loading from the selected collection. This must be an attribute containing a date-time value, such as `created_at`.
         *
         * __Applicable and required__ if `mode` is `timestamp`.
         */
        "timestamp.key"?: string;
        /**
         * @description __Starting Timestamp__: Set the timestamp value of the __Timestamp Key__ from which the platform should start ingesting data. This must be a UNIX epoch (milliseconds) or ISO-formatted date-time value (e.g., 2016-01-01T12:13:14).
         *
         * __Applicable and required__ if `mode` is `timestamp`.
         */
        "timestamp.load.from"?: string;
        /**
         * @description __Ending Timestamp__: Set the timestamp value of the __Timestamp Key__ at which the platform should end ingesting data. This must be a UNIX epoch (milliseconds) or ISO-formatted date-time value (e.g., 2016-01-01T12:13:14).
         *
         * __Applicable__ if `mode` is `timestamp`.
         */
        "timestamp.load.to"?: string;
      };
    };
    dynamodb_data_source: {
      source_type: "dynamodb";
    } & Omit<components["schemas"]["data_source"], "source_type"> & components["schemas"]["nosql_data_source"] & {
      source_config?: {
        /**
         * @description __DynamoDB Filter Expression__: Enter a valid DynamoDB Query expression to filter collections.
         *
         * See https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/Query.html#Query.FilterExpression for information about the Filter Expression structure.
         *
         * Example: `#name = :name_value`.
         *
         * __Applicable and required__ if `mode` is `query`.
         */
        "dynamodb.filter.expression"?: string;
        /**
         * @description __Filter Expression: Attribute Values__: Set attribute values for attributes that are used in your filter expression.
         *
         * See https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/Query.html#Query.FilterExpression for information about the Filter Expression structure.
         *
         * For example, for the above expression, this value is `{":name_value":{"S":"My Name"}}`.
         *
         * __Applicable__ if `mode` is `query`.
         */
        "dynamodb.filter.attributes.values"?: string;
        /**
         * @description __Filter Expression: Attribute Names__: Set attribute names for attributes that are used in your filter expression.
         *
         * See https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/Query.html#Query.FilterExpression for information about the Filter Expression structure.
         *
         * For example, for the above expression, this value is `{"#name":"name_column"}`.
         *
         * __Applicable__ if `mode` is `query`.
         */
        "dynamodb.filter.attributes.names"?: string;
      };
    };
    file_upload_data_source: {
      source_type: "file_upload";
    } & Omit<components["schemas"]["data_source"], "source_type"> & components["schemas"]["file_data_source"];
    firebase_data_source: {
      source_type: "firebase";
    } & Omit<components["schemas"]["data_source"], "source_type"> & components["schemas"]["nosql_data_source"] & {
      source_config?: {
        /**
         * @description __Query Expression__: Set the Query to be executed during each ingestion cycle. The query content should be a valid JSON object in Nexla Firebase query DSL. Please contact Nexla support for tips on writing valid queries.
         *
         * Example: `{"filters": [ { "fieldName": "name", "operator": "EQUAL", "fieldType": "string", "stringValue": "test" }]}` results in documents containing a `name` property with the value `test`.
         *
         * __Applicable and required__ if `mode` is `query`.
         */
        "firebase.query"?: string;
      };
    };
    firebolt_data_source: {
      source_type: "firebolt";
    } & Omit<components["schemas"]["data_source"], "source_type"> & components["schemas"]["WithoutCDCSupport"];
    ftp_data_source: {
      source_type: "ftp";
    } & Omit<components["schemas"]["data_source"], "source_type"> & components["schemas"]["file_data_source"];
    gcp_alloydb_data_source: {
      source_type: "gcp_alloydb";
    } & Omit<components["schemas"]["data_source"], "source_type"> & components["schemas"]["WithCDCSupport"];
    gcp_spanner_data_source: {
      source_type: "gcp_spanner";
    } & Omit<components["schemas"]["data_source"], "source_type"> & components["schemas"]["WithoutCDCSupport"] & {
      source_config?: {
        /**
         * @description __Enable Spanner Data Boost?__: Set this option to True if you want to leverage Spanner Data Boost capability for this source. Note that the service account used in the credential must have `spanner.databases.useDataBoost` IAM permission for successfully running the query with Data Boost.
         *
         * Default: `false`
         */
        "enable.spanner.data.boost"?: boolean;
      };
    };
    gcs_data_source: {
      source_type: "gcs";
    } & Omit<components["schemas"]["data_source"], "source_type"> & components["schemas"]["file_data_source"];
    gdrive_data_source: {
      source_type: "gdrive";
    } & Omit<components["schemas"]["data_source"], "source_type"> & components["schemas"]["file_data_source"];
    google_pubsub_data_source: {
      source_type: "google_pubsub";
    } & Omit<components["schemas"]["data_source"], "source_type"> & components["schemas"]["stream_data_source"] & ({
      source_config?: {
        /** @description __Subscription__: Select the subscription for your data. */
        subscription: string;
        /**
         * @description __Offset Mode__: You can configure the default offset mode used to read data from the topic.
         *
         * Usually set to `earliest`
         *
         * @enum {string}
         */
        "offset.mode"?: "earliest" | "from_date" | "latest" | "manual";
        /**
         * @description __Consume Data From Date__: You can choose to configure this source for reading data from a specific date. Enter the starting date for data ingestion.
         *
         * __Required__ if `offset.mode` is `from_date`
         */
        "start.from.date"?: string;
        /**
         * @description __Consume Data From Offset__: You can choose to configure this source for reading data from a specific offset. Enter the starting offset for data ingestion.
         *
         * __Required__ if `offset.mode` is `manual`
         */
        "start.from.offsets"?: string;
        /**
         * @description __Key Deserializer__: Enter the type of key deserializer that should be used for reading keys from the topic. This is usually in the form `org.apache.kafka.common.serialization.StringDeserializer`.
         *
         * Default value: `org.apache.kafka.common.serialization.StringDeserializer`
         */
        "key.deserializer"?: string;
        /**
         * @description __Value Deserializer__: Enter the type of value deserializer that should be used for reading from the topic. This is usually in the form `org.apache.kafka.common.serialization.StringDeserializer`.
         *
         * Default value: `org.apache.kafka.common.serialization.StringDeserializer`
         */
        "value.deserializer"?: string;
      };
    });
    hana_jdbc_data_source: {
      source_type: "hana_jdbc";
    } & Omit<components["schemas"]["data_source"], "source_type"> & components["schemas"]["WithoutCDCSupport"];
    hive_data_source: {
      source_type: "hive";
    } & Omit<components["schemas"]["data_source"], "source_type"> & components["schemas"]["WithoutCDCSupport"];
    jms_data_source: {
      source_type: "jms";
    } & Omit<components["schemas"]["data_source"], "source_type"> & components["schemas"]["stream_data_source"] & ({
      source_config?: {
        /**
         * @description __Type of Source__: Select whether the source is a `topic` or `queue`.
         *
         * @enum {string}
         */
        "source.type": "topic" | "queue";
        /** @description __Topic or Queue Name__: Configure the topic or queue from which data needs to be ingested. */
        "source.name": string;
      };
    });
    kafka_data_source: {
      source_type: "kafka";
    } & Omit<components["schemas"]["data_source"], "source_type"> & components["schemas"]["stream_data_source"] & ({
      source_config?: {
        /** @description __Topic__: Select the topic for your data. */
        topic: string;
        /**
         * @description __Offset Mode__: You can configure the default offset mode to be used for reading data from the topic.
         *
         * Usually set to `earliest`
         *
         * @enum {string}
         */
        "offset.mode"?: "earliest" | "from_date" | "latest" | "manual";
        /**
         * @description __Consume Data From Date__: You can choose to configure this source for reading data from a specific date. Enter the starting date for data ingestion.
         *
         * __Required__ if `offset.mode` is `from_date`
         */
        "start.from.date"?: string;
        /**
         * @description __Consume Data From Offset__: You can choose to configure this source for reading data from a specific offset. Enter the starting offset for data ingestion.
         *
         * __Required__ if `offset.mode` is `manual`
         */
        "start.from.offsets"?: string;
        /**
         * @description __Key Deserializer__: Enter the type of key deserializer that should be used to read keys from the Kafka topic. This is usually in the form `org.apache.kafka.common.serialization.StringDeserializer`.
         *
         * Default value: `org.apache.kafka.common.serialization.StringDeserializer`
         */
        "key.deserializer"?: string;
        /**
         * @description __Value Deserializer__: Enter the type of value deserializer that should be used to read from the Kafka topic. This is usually in the form `org.apache.kafka.common.serialization.StringDeserializer`.
         *
         * Default value: `org.apache.kafka.common.serialization.StringDeserializer`
         */
        "value.deserializer"?: string;
      };
    });
    min_io_s3_data_source: {
      source_type: "min_io_s3";
    } & Omit<components["schemas"]["data_source"], "source_type"> & components["schemas"]["file_data_source"];
    mongo_data_source: {
      source_type: "mongo";
    } & Omit<components["schemas"]["data_source"], "source_type"> & components["schemas"]["nosql_data_source"] & {
      source_config?: {
        /**
         * @description __Query Expression__: Set the Mongo query expression to be executed during each ingestion cycle. See https://www.mongodb.com/docs/compass/current/query/filter/ for tips on constructing a valid query.
         *
         * Example: `{$query: {name: 'John'}, $orderby: {name: -1}}`.
         *
         * __Applicable and required__ if `mode` is `query`.
         */
        "mongo.query.expression"?: string;
      };
    };
    mysql_data_source: {
      source_type: "mysql";
    } & Omit<components["schemas"]["data_source"], "source_type"> & components["schemas"]["WithCDCSupport"];
    netsuite_jdbc_data_source: {
      source_type: "netsuite_jdbc";
    } & Omit<components["schemas"]["data_source"], "source_type"> & components["schemas"]["WithoutCDCSupport"];
    rest_data_source: {
      source_type: "rest";
    } & Omit<components["schemas"]["data_source"], "source_type"> & ({
      source_config?: {
        /**
         * @description With Nexla you can configure chains of API calls to fetch data from APIs before records land in the Nexset. Each step in the chain can be configured to fetch multiple pages of data based on the iteration type. Each step is an object in this array.
         *
         * Typically, you want to fetch multiple pages of data from a REST API. This is done by configuring one object in this array and setting an appropriate `iteration.type` in that object.
         *
         * But if you want to fetch data from multiple APIs in a chain, configure multiple objects in this array. Assign a unique `key` to each object, and then you can reference the results of each step in subsequent steps using the `<key>.<path>` syntax.
         */
        "rest.iterations": ({
            /** @description __Step Key__: Unique key for this iteration step. This can be any string that is unique within all rest iterations steps for this source. The key is used for referencing results from a step in subsequent steps. We typically use `step_<number>` as the key. */
            key: string;
            /**
             * @description __API URL__: The API URL to fetch data from. You can use Nexla macros in the URL:
             *  Date/Time macros: Use `now` with optional offsets (e.g. `now-1`)
             *  Response macros: Reference data from previous steps using `step_<key>.<path>` syntax
             *  User-defined variables: Use `{variable_name=default_value}` syntax to define variables that can be set at runtime
             *
             * Examples:
             *  `https://api.example.com/data?date=${now-1}`
             *  `https://api.example.com/users?token=${step_1.token}`
             *  `https://api.example.com/orders?status={status=pending}&limit={limit=100}`
             */
            "url.template": string;
            /**
             * @description __HTTP Method__: HTTP method for the request.
             *  GET: Retrieve data from the server
             *  POST: Submit data to be processed
             *  PUT: Update or replace existing data
             *
             * @enum {string}
             */
            method: "GET" | "POST" | "PUT";
            /**
             * @description __Date Format__: The format of the date to be used in the API URL. You can use Nexla macros in the date format:
             *  Date/Time macros: Use `now` with optional offsets (e.g. `now-1`)
             *  Response macros: Reference data from previous steps using `step_<key>.<path>` syntax
             *  User-defined variables: Use `{variable_name=default_value}` syntax to define variables that can be set at runtime
             *
             * Examples:
             *  `%Y-%m-%d`
             *  `%Y-%m-%d %H:%M:%S`
             *  `%Y-%m-%d %H:%M:%S %z`
             *
             * @enum {string}
             */
            "date.format"?: "yyyy-MM-dd" | "MM/dd" | "yy" | "yyyy" | "MM" | "MMM" | "MMMM" | "hh" | "hh:mm" | "HH" | "HH:mm" | "DD" | "eeee" | "ssss" | "yyyy-MM-dd'T'HH:mm:ss'Z'";
            /**
             * @description __Time Unit for Operations__: The unit of date or time for performing mathematical operations on Nexla date-time macro.
             *
             * @enum {string}
             */
            "date.time.unit"?: "yyyy" | "MM" | "dd" | "HH" | "mm" | "ss";
            /**
             * @description __Request Body__: Enter the payload for this request.
             *
             * **For REST APIs:**
             * 1. Enter a valid JSON object
             * 2. You can use Nexla macros in the payload
             *
             * **For GraphQL APIs:**
             * 1. If using GraphQL pagination (page or cursor), enter your GraphQL query directly
             * 2. For other GraphQL requests that you wish to send as a standard REST API POST request, wrap your query in a JSON object with `"query"` field
             *
             * **Example REST payload:**
             * `{ "user_id": 123 }`
             *
             * **Example GraphQL with pagination:**
             * `query {\n  characters(page: $page) {\n    results {\n      name\n      species\n    }\n  }\n}`
             *
             * **Example GraphQL without pagination:**
             * `{ "query": "query { users { id name } }" }`
             */
            "body.template"?: string;
            /**
             * @description __Response Format__: Select the format of the response from the API. This is used to parse the response from the API into a format that can be used by Nexla.
             *
             * @enum {string}
             */
            "response.format"?: "xml" | "json";
            /**
             * @description __Response Data Path__: Specify path to data in API response.
             * You can choose which part of the API response should be treated as relevant data by Nexla. For ex: when pulling a list of items from a REST API endpoint, the API will usually return an array of records along with some metadata. You can configure this field such that Nexla can treat each element of that array as a record.
             * For JSON API response, please specify the JSON Path to point to the object or array you want Nexla to consider as relevant data, and for XML API use XPATH.
             * For ex: JSONPath could be $.data[*] if the response has an array named data at the top level. Select one of the smart tokens generated when you test the API, or try out JSON Path examples at https://jsonpath.com
             */
            "response.data.path"?: string;
            /**
             * @description __Response Data Path Additional__: Specify path to metadata in response (Optional).
             * By choosing Path to Data in Response above you had defined which part of the API response should be treated by Nexla as a record. But sometimes there can be API response data outside that path to data that you also wish to include in each record. Set this property if you wish to include that common metadata in each record.
             * For JSON API response, please specify the JSON Path to point to the object or array you want Nexla to consider as relevant data, and for XML API use XPATH. Try out JSON Path examples at https://jsonpath.com
             */
            "response.data.path.additional"?: string;
            /** @description __Request Headers__: Add any optional request headers that must be sent as part of this request. You do not need to repeat headers already present in credentials. Please input as comma-separated values e.g `header1:value1,header2:value2`. */
            "request.headers"?: string;
            /** @description __Lookup ID__: You can use values of a column in a Nexla lookup as a macro for API URL. Select the lookup you wish to use for generating API macros. */
            "map.id"?: string;
            /**
             * @description __Type of Iteration__: Type of iteration to use for fetching data. Set instructions for how the connector should iterate requests over multiple pages in this step before moving on to the next step.
             *  static.url: No Iteration
             *  paging.incrementing: Page Number
             *  paging.incrementing.offset: Offset
             *  paging.next.token: Next Token In Response
             *  paging.next.url: Next URL in Response
             *  link.header: Next URL in Response Header
             *  response.id.number: ID (number) in Response
             *  response.id.string: ID (String) In Response
             *  graphql.page: GraphQL Page
             *  graphql.cursor: GraphQL Cursor
             *  data.map.key.queue: Data Map Iteration
             *  async.poll: Asynchronous Job Status API
             *  body.as.file: Process API Response as File
             *
             * @enum {string}
             */
            "iteration.type": "paging.incrementing" | "paging.incrementing.offset" | "paging.next.token" | "paging.next.url" | "link.header" | "response.id.number" | "response.id.string" | "graphql.page" | "graphql.cursor" | "data.map.key.queue" | "async.poll" | "body.as.file" | "static.url";
            /** @description __URL parameter for ID / Token / Page__: Enter the URL parameter name that is used to set the id / page number / token for this type of iteration. */
            "param.id"?: string;
            /** @description __Start From Page__: Set the starting value for the URL page number parameter. Nexla will automatically iterate through subsequent pages of data till there is no more data to be fetched. */
            "start.page.from"?: number;
            /** @description __(Optional) Stop After Page No__: You can configure the platform to stop fetching after receiving a specific page number. Leave blank to fetch all relevant data. */
            "end.page.to"?: number;
            /**
             * @description __URL Param for Items per page__: Enter the URL parameter name that is used to set the the number of items that are returned in each page.
             * API developers usually set the default number of items returned to a low number, but for data ingestion we recommend setting the property to maximum allowed by the API you are trying to access.
             */
            "param.page.size"?: string;
            /** @description __Items Per Page__: Set the value for number of items to be fetched in page of data. */
            "page.expected.rows"?: number;
            /** @description __Response Header containing Next Page URL__: Set the name of the response header that contains the next page URL. Often API developers send this data in the `Link` header. */
            link?: string;
            /** @description __URL Param For Offset__: Enter the URL parameter name that is used to set the offset for this type of iteration. */
            "param.offset"?: string;
            /** @description __Start From Offset__: Set the starting value of offset that should be used for the first request. */
            "start.offset.from"?: number;
            /** @description __(Optional) Stop After Offset__: You can configure the platform to stop fetching after receiving a specific offset. Leave blank to fetch all relevant data. */
            "end.offset.to"?: number;
            /**
             * @description __Parallel Requests__: You can configure multiple requests to be executed in parallel by changing this number.
             * __Recommendation__:  A high parallelism count can result in being flagged for rate-limiting by the API vendor, so usually you should leave this to the default setting of 1. Modify this setting only if the source is taking longer to iterate through all pages than is acceptable for your use case.
             */
            "request.parallelism.count"?: number;
            /** @description __Path to next token__: Choose which part of the API response should be treated as relevant token for the next request. This must be a valid JSON Path (for JSON responses) or XPath (for XML responses). */
            "response.next.token.data.path"?: string;
            /** @description __(Optional) Stop After Token__: You can configure the platform to stop fetching after receiving a specific token. Leave blank to fetch all relevant data. */
            "end.token.to"?: string;
            /** @description __Path to next URL__: Choose which part of the API response should be treated as relevant urls for the next request. This must be a valid JSON Path (for JSON responses) or XPath (for XML responses). */
            "response.next.url.data.path"?: string;
            /** @description __(Optional) Stop After URL__: You can configure the platform to stop fetching after receiving a specific URL. Leave blank to fetch all relevant data. */
            "end.url.to"?: string;
            /** @description __Start ID from__: Set the starting value of ID that should be used for the first request. */
            "start.id.from"?: string;
            /** @description __(Optional) Stop After ID__: You can configure the platform to stop fetching after receiving a specific ID. Leave blank to fetch all relevant data. */
            "end.id.to"?: number;
            /** @description __ID Name__: Specify Path to ID in API response. Choose which part of the API response should be treated as relevant IDs for the next request. This must be a valid JSON Path (for JSON responses) or XPath (for XML responses). */
            "response.id.field.name"?: string;
            /** @description __Next ID Inclusive?__: Set this to true if the highest ID in current response should be used as the starting ID for fetching next page of data. */
            "param.id.inclusive"?: boolean;
            /**
             * @description __Page Variable Name__: Enter the name of the variable used for pagination in your GraphQL query. This variable will be automatically incremented in subsequent requests until empty results are returned.
             * __Applicable__ if `iteration.type` is `graphql.page`.
             */
            "graphql.page.name"?: string;
            /**
             * @description __Starting Page Number__: Enter the initial page number to start fetching data from. This number will be used as the first value for your page variable and will be incremented in subsequent requests.
             * __Applicable__ if `iteration.type` is `graphql.page`.
             */
            "graphql.page.start"?: string;
            /**
             * @description __Cursor Variable Name__: Enter the name of the variable used for cursor-based pagination in your GraphQL query. This variable will be updated with the cursor value from each response to fetch the next page of results.
             *
             * Example: If your query uses `$cursor`, enter `"cursor"`
             * __Applicable__ if `iteration.type` is `graphql.cursor`.
             */
            "graphql.cursor.name"?: string;
            /**
             * @description __Initial Cursor Source__: Advanced: Only needed for specific APIs like Monday.com where the initial cursor query has a different structure than subsequent queries.
             *
             * Most GraphQL APIs don't need this - only use if your API requires:
             * 1. A different query structure to get the first cursor
             * 2. A different query structure for subsequent pages
             *
             * Format: `stepKey.path` (e.g., `step1.cursor`)
             *
             * Example: Monday.com needs this because:
             * - First query: `query { boards { items_page { cursor... } } }`
             * - Later queries: `query { next_items_page(cursor: $cursor) { ... } }`
             *
             * __Applicable__ if `iteration.type` is `graphql.cursor`.
             */
            "graphql.cursor.template"?: string;
            /**
             * @description __Path to Next Cursor__: Specify where to find the next cursor value in the GraphQL response. The cursor from this path will be used in the next request. Iteration stops when a blank cursor is returned.
             *
             * Example: For a response like `{ data: { products: { edges: [{ cursor: "abc" }] } } }`, use `$.data.products.edges[-1:].cursor`
             *
             * __Applicable__ if `iteration.type` is `graphql.cursor`.
             */
            "response.graphql.cursor.path"?: string;
            /** @description __Job Status Param__: Choose which part of the API response should be treated as relevant property for evaluating the status of the asynchronous job. This must be a valid JSON Path (for JSON responses) or XPath (for XML responses). */
            "async.iteration.path"?: string;
            /** @description __Job Completion Value__: Set the value of Job Status Param that would indicate completion of the asynchronous job. */
            "async.iteration.value"?: string;
            /**
             * @description __Data Format of Response File__: When an API endpoint returns a file in response (or response body is plain text that should be parsed as a file), the platform can be configured to parse the response content accordingly.
             *
             * @enum {string}
             */
            "file.response.format"?: "csv" | "json" | "txt" | "xml";
            /**
             * @description __Include Previous Step Results__: When enabled, this setting preserves results from all steps in a multi-step REST workflow, rather than only keeping the final step's results.
             *
             * For example, in a two-step workflow:
             * Step 1 returns: `{ "data": 1, "cursor": "abc123" }`
             * Step 2 returns: `{ "data": 2, "cursor": null }`
             *
             * With this enabled, the final output includes both:
             * `[ { "data": 1, "cursor": "abc123" }, { "data": 2, "cursor": null } ]`
             *
             * Without this (default), only the last step's results are kept:
             * `[ { "data": 2, "cursor": null } ]`
             *
             * This is particularly useful for:
             *  API calls that require initial requests to get pagination tokens
             *  Multi-step workflows where early responses contain important metadata
             *  Cases where discarding intermediate results would lose valuable information
             *
             * __Applicable__ if `iteration.type` is `paging.incrementing`, `paging.incrementing.offset`, `paging.next.token`, `paging.next.url`, `link.header`, `response.id.number`, `response.id.string`, `graphql.page`, `graphql.cursor`, `data.map.key.queue`, `async.poll`, `body.as.file`, `static.url`.
             * Default value: `false`.
             */
            "results.pass.through"?: boolean;
          })[];
        /**
         * @description __Fetch Data__: The interval at which Nexla should scan this source for new data. This must be in the form of a cron expression.
         * Example: `0 0 22 10 11 ? 2022`.
         */
        "start.cron"?: string;
      };
    });
    nexla_monitor_data_source: components["schemas"]["rest_data_source"];
    nexla_rest_data_source: {
      source_type: "nexla_rest";
    } & Omit<components["schemas"]["data_source"], "source_type"> & ({
      source_config?: {
        /**
         * @description __Webhook Authorization Type__: Webhooks are usually authorized via a Nexla API key.
         *
         * An additional layer of authorization can be enabled via Hash-Based Message Authentication Code(HMAC). Some third parties send a hash along with the payload. In such cases, Nexla can validate that the incoming call was generated by the authorized partner. Set the HMAC properties that will be used by Nexla for validation against the incoming hash.
         *
         * Default Value: `Nexla API Key`
         *
         * @enum {string}
         */
        "webhook.auth_type": "Nexla API Key" | "Payload Hash";
        /**
         * @description Set this to `true` if you want to enforce the detection of only one Nexset.
         *
         * Set this to `false` to instruct the platform to monitor each call to the webhook for changes in the Nexset schema.
         *
         * Default value: `true`
         */
        "schema.detection.once": boolean;
        /**
         * @description Set to `true` to support incoming webhook authentication via the payload hash.
         *
         * Default value: `false`
         */
        "hash.enabled": boolean;
        /**
         * @description __Hashing Algorithm__: The hash algorithm used to generate the hash during payload hashing.
         *
         * __Required__ if `hash.enabled` is `true`
         *
         * @enum {string}
         */
        hash_algorithm?: "HmacSHA1" | "HmacSHA256" | "HmacSHA384" | "HmacSHA512" | "HmacMD5";
        /**
         * @description Parameter/header name in the incoming request containing the hash.
         *
         * __Required__ if `hash.enabled` is `true`
         */
        hash_request_param?: string;
        /**
         * @description The hash secret key for payload hashing.
         *
         * __Required__ if `hash.enabled` is `true`
         */
        hash_secret_key?: string;
      };
    });
    oracle_data_source: {
      source_type: "oracle";
    } & Omit<components["schemas"]["data_source"], "source_type"> & components["schemas"]["WithCDCSupport"];
    oracle_autonomous_data_source: {
      source_type: "oracle_autonomous";
    } & Omit<components["schemas"]["data_source"], "source_type"> & components["schemas"]["WithoutCDCSupport"];
    vector_db_data_source: {
      source_config?: {
        /**
         * @description __Scheduling Frequency__: The interval at which Nexla should scan this source for new data. This must be in the form of a cron expression.
         *
         * @example 0 0 22 10 11 ? 2022
         */
        "start.cron": string;
      };
    };
    pinecone_data_source: {
      source_type: "pinecone";
    } & Omit<components["schemas"]["data_source"], "source_type"> & components["schemas"]["vector_db_data_source"] & ({
      source_config?: {
        /** @description __Index__: Specify the name of the index to be queried within the selected Pinecone database. */
        database: string;
        /**
         * @description __Namespace__: Set the namespace to query within the selected Pinecone database.
         * You can use the default namespace or specify a custom namespace.
         *
         * @default
         */
        collection?: string;
        /**
         * @description __Query Type__: Define the type of operation to perform, such as fetching vectors,
         * performing similarity search, or retrieving vectors by ID.
         * - `fetch_vectors` (Fetch Vectors): Retrieve vectors from the Pinecone database.
         * - `similarity_search` (Similarity Search): Retrieve similar vectors to a given vector.
         * - `fetch_ids` (Fetch IDs): Retrieve vectors by their unique identifiers.
         *
         * @default similarity_search
         * @enum {string}
         */
        query_type: "fetch_vectors" | "similarity_search" | "fetch_ids";
        /**
         * @description __Top K Similar Vectors__: Specify the number of top similar vectors to retrieve.
         * Applicable when `query_type` is `similarity_search`.
         *
         * @default 20
         */
        topK?: string;
        /**
         * @description __Search Filter__: Specify a filter to refine which vectors are retrieved from the database.
         * Applicable when `query_type` is `similarity_search`.
         *
         * @default
         */
        "pinecone.filter"?: string;
        /**
         * @description __Search By Criteria__: Specify the type of search to perform for similarity search.
         * - `dense_vector` (Dense Vector): Provide a dense vector for similarity search.
         * - `vector_id` (Vector Identifier): Provide the unique identifier of the vector to fetch.
         *
         * Applicable when `query_type` is `similarity_search`.
         *
         * @default dense_vector
         * @enum {string}
         */
        search_by?: "dense_vector" | "vector_id";
        /**
         * @description __Dense Vector__: Provide the dense vector for similarity search.
         *
         * Required when `query_type` is `similarity_search` and  `search_by` is `dense_vector`.
         */
        dense_vector?: string;
        /**
         * @description __Sparse Vector Indices__: List the indices of non-zero values in the sparse vector for similarity search.
         *
         * Applicable when `query_type` is `similarity_search` and  `search_by` is `dense_vector`.
         */
        sparse_vector_indices?: string;
        /**
         * @description __Sparse Vector Values__: Provide the values corresponding to the indices of the sparse vector for similarity search.
         *
         * Applicable when `query_type` is `similarity_search` and  `search_by` is `dense_vector`.
         */
        sparse_vector_values?: string;
        /**
         * @description __Vector Identifier__: Unique identifier of the vector to fetch.
         *
         * This field is required when using the `similarity_search` query type and `search_by` is `vector_id`.
         */
        vector_id?: string;
        /**
         * @description __Pinecone Prefix__: Specify a prefix to refine which vectors are retrieved from the database.
         *
         * Applicable when `query_type` is `similarity_search` or `fetch_vectors`.
         */
        "pinecone.prefix"?: string;
        /**
         * @description __Include Values?__: Set this field to `true` to include the values of the vectors in the output.
         * Applicable when `query_type` is `similarity_search`.
         *
         * @default true
         */
        "pinecone.includeValues"?: boolean;
        /**
         * @description __Include Metadata?__: Set this field to `true` to include the metadata of the vectors in the output.
         * Applicable when `query_type` is `similarity_search`.
         *
         * @default true
         */
        "pinecone.includeMetadata"?: boolean;
      };
    });
    postgres_data_source: {
      source_type: "postgres";
    } & Omit<components["schemas"]["data_source"], "source_type"> & components["schemas"]["WithCDCSupport"];
    redshift_data_source: {
      source_type: "redshift";
    } & Omit<components["schemas"]["data_source"], "source_type"> & components["schemas"]["WithoutCDCSupport"];
    s3_data_source: {
      source_type: "s3";
    } & Omit<components["schemas"]["data_source"], "source_type"> & components["schemas"]["file_data_source"];
    s3_iceberg_data_source: {
      source_type: "s3_iceberg";
    } & Omit<components["schemas"]["data_source"], "source_type"> & ({
      source_config?: {
        /**
         * @description __Check for data__: The interval at which Nexla should scan this source for new data. This must be in the form of a cron expression.
         *
         * @example 0 0 22 10 11 ? 2022
         */
        "start.cron": string;
        /**
         * @description __Warehouse Directory__: Path to the directory containing the Iceberg table.
         * Nexla uses the path-based Hadoop catalog to discover tables in S3. So if your Iceberg table `sales` is in `s3://my-nexla-bucket/product/sales`, then set this property to `my-nexla-bucket`.
         */
        "iceberg.warehouse.dir": string;
        /**
         * @description __Table Name__: Name of the table from which data will be read.
         * Nexla uses the path-based Hadoop catalog to discover tables in S3. So if your Iceberg table `sales` is in `s3://my-nexla-bucket/product/sales`, then set this property to `product.sales` to read from the table.
         */
        "iceberg.table.name": string;
        /**
         * @description __Table Scan Modes__: Select the mode to query the table using Apache Iceberg time travel features.
         * The default value can be used to skip timetravel features. The other modes can be used to query table as-of a branch, tag, timestamp, snapshot or read appended data between two snapshots.
         *
         * * `none` - (Do not use time travel features) Select this mode if you do not want to use any time travel features and want to read all data from the table.
         * * `branch` - (Branch) Select this mode if you want to query the table as of a branch.
         * * `tag` - (Tag) Select this mode if you want to query the table as of a tag.
         * * `timestamp` - (Timestamp) Select this mode if you want to query the table as of a timestamp.
         * * `snapshot` - (Snapshot) Select this mode if you want to query the table as of a snapshot.
         * * `incremental` - (Incremental) Select this mode if you want to read appended data between two snapshots.
         *
         * @enum {string}
         */
        "iceberg.timetravel.modes": "none" | "branch" | "tag" | "timestamp" | "snapshot" | "incremental";
        /**
         * @description __Branch to Query__: Branch to query using Apache Iceberg time travel features. Not compatible with time travel by timestamp.
         *
         * __Applicable and required__ if `iceberg.timetravel.modes` is set to `branch`.
         */
        "iceberg.timetravel.as.of.branch"?: string;
        /**
         * @description __Tag to Query__: Tag to query using Apache Iceberg time travel features. Not compatible with time travel by timestamp.
         *
         * __Applicable and required__ if `iceberg.timetravel.modes` is set to `tag`.
         */
        "iceberg.timetravel.as.of.tag"?: string;
        /**
         * @description __Snapshot ID to Query__: Snapshot ID to query using Apache Iceberg time travel features.
         *
         * __Applicable and required__ if `iceberg.timetravel.modes` is set to `snapshot`.
         */
        "iceberg.timetravel.as.of.snapshot"?: string;
        /**
         * @description __Timestamp to Query__: Timestamp to query using Apache Iceberg time travel features. Supported formats: `YYYY-MM-DD HH:MM:SS` or Unix timestamp in seconds.
         *
         * __Applicable and required__ if `iceberg.timetravel.modes` is set to `timestamp`.
         */
        "iceberg.timetravel.as.of.timestamp"?: string;
        /**
         * @description __Snapshot ID to start reading from__: Read appended data between two snapshots with the incremental read feature. This is the starting snapshot ID and is required for this feature. Incremental reads are not compatible with other time travel features nor with upserts and deletes.
         *
         * __Applicable and required__ if `iceberg.timetravel.modes` is set to `incremental`.
         */
        "iceberg.incremental.start-snapshot-id"?: string;
        /**
         * @description __Snapshot ID to end reading at__: Read appended data between two snapshots with the incremental read feature. This is the ending snapshot ID and is optional, if the starting snapshot ID is specified but the ending snapshot ID is not provided will read all subsequent data. Incremental reads are not compatible with other time travel features nor with upserts and deletes.
         *
         * __Applicable__ if `iceberg.timetravel.modes` is set to `incremental`.
         */
        "iceberg.incremental.end-snapshot-id"?: string;
      };
    });
    sharepoint_data_source: {
      source_type: "sharepoint";
    } & Omit<components["schemas"]["data_source"], "source_type"> & components["schemas"]["file_data_source"];
    snowflake_data_source: {
      source_type: "snowflake";
    } & Omit<components["schemas"]["data_source"], "source_type"> & components["schemas"]["WithoutCDCSupport"];
    soap_data_source: {
      source_type: "soap";
    } & Omit<components["schemas"]["data_source"], "source_type"> & {
      source_config?: {
        /**
         * @description __Scheduling Frequency__: The interval at which Nexla should scan this source for new data. This must in the form of a cron expression.
         *
         * @example 0 0 22 10 11 ? 2022
         */
        "start.cron": string;
        /** @description __WSDL URL__: Enter the WSDL URL of the Soap service to which you wish to connect. */
        "soap.wsdl.url": string;
        /** @description __SOAP Service Name__: Enter the name of the SOAP Service that you wish to access. */
        "soap.service": string;
        /**
         * @description __SOAP Binding Name__: Enter the name of the SOAP binding element.
         *
         * The SOAP binding element defines the message format and protocol details for each port. The binding element has two attributes: the name attribute and the type attribute.
         */
        "soap.binding": string;
        /** @description __SOAP Operation Name__: Select the operation for the binding that you wish to access. */
        "soap.operation": string;
        /**
         * @description __SOAP Binding Port Type__: Enter the port type of the SOAP binding element.
         *
         * The SOAP binding element defines the message format and protocol details for each port. The binding element has two attributes: the name attribute and the type attribute.
         */
        "soap.port.type": string;
        /** @description __SOAP Service Port__: Select the Service Port that you wish to access. */
        "soap.service.port": string;
        /**
         * @description __Operation Parameters and Values__: Enter a dictionary of operation parameters and relevant operation parameter values for this source.
         *
         * example:
         * ```
         *   {
         *       "TrackRequest/ClientDetail/AccountNumber": "12345",
         *       "TrackRequest/TransactionDetail/Localization/LanguageCode": "EN"
         *   }
         * ```
         */
        "soap.params": string;
      };
    };
    sqlserver_data_source: {
      source_type: "sqlserver";
    } & Omit<components["schemas"]["data_source"], "source_type"> & components["schemas"]["WithCDCSupport"];
    sybase_data_source: {
      source_type: "sybase";
    } & Omit<components["schemas"]["data_source"], "source_type"> & components["schemas"]["WithoutCDCSupport"];
    teradata_data_source: {
      source_type: "teradata";
    } & Omit<components["schemas"]["data_source"], "source_type"> & components["schemas"]["WithoutCDCSupport"];
    tibco_data_source: {
      source_type: "tibco";
    } & Omit<components["schemas"]["data_source"], "source_type"> & components["schemas"]["stream_data_source"] & ({
      source_config?: {
        /**
         * @description Select whether the source is a `topic` or `queue`.
         *
         * @enum {string}
         */
        "source.type": "topic" | "queue";
        /** @description __Topic or Queue Name__: Configure the topic or queue from which data needs to be ingested. */
        "source.name": string;
      };
    });
    webdav_data_source: {
      source_type: "webdav";
    } & Omit<components["schemas"]["data_source"], "source_type"> & components["schemas"]["file_data_source"];
    data_set_schema: {
      properties?: {
        [key: string]: string;
      };
      /** Format: url */
      $schema?: string;
      "$schema-id"?: number;
    };
    UserSimplified: {
      id?: number;
      full_name?: string;
      email?: string;
      /** Format: date-time */
      email_verified_at?: string;
    };
    OrgSimplified: {
      id?: number;
      name?: string;
      email_domain?: string;
      email?: string;
      client_identifier?: string;
      org_webhook_host?: string;
    };
    DataSource: {
      /** Format: int32 */
      id?: number;
      /** Format: int32 */
      owner_id?: number;
      /** Format: int32 */
      org_id?: number;
      name?: string;
      /** Format: nullable */
      description?: string;
      status?: string;
      source_type?: string;
      connector?: {
        /** Format: int32 */
        id?: number;
        type?: string;
        connection_type?: string;
        name?: string;
        description?: string;
        nexset_api_compatible?: boolean;
      };
      /** Format: nullable */
      vendor_id?: string;
    };
    DataSetBrief: {
      id?: number;
      owner_id?: number;
      org_id?: number;
      name?: string;
      description?: string;
      /** Format: date-time */
      created_at?: string;
      /** Format: date-time */
      updated_at?: string;
    };
    DataSinkSimplified: {
      /** Format: int32 */
      id?: number;
      /** Format: int32 */
      owner_id?: number;
      /** Format: int32 */
      org_id?: number;
      name?: string;
      status?: string;
      sink_type?: string;
    };
    DataSet: {
      /** Format: int32 */
      id?: number;
      owner?: components["schemas"]["UserSimplified"];
      org?: components["schemas"]["OrgSimplified"];
      name?: string;
      description?: string;
      status?: string;
      /** @description Id of the data source this Nexset was detected from. This is only relevant for detected Nexsets. */
      data_source_id?: number | null;
      /** @description Details about the data source this Nexset was detected from. This is only relevant for detected Nexsets. */
      data_source?: components["schemas"]["DataSource"];
      /** @description Details about the Nexset this Nexset is derived from. This element is empty in case of detected Nexsets and has 1 item in case of derived Nexsets. */
      parent_data_sets?: components["schemas"]["DataSetBrief"][];
      /** @description Details about every data sink this Nexset is directly connected to. */
      data_sinks?: components["schemas"]["DataSinkSimplified"][];
      access_roles?: components["schemas"]["AccessRoles"];
      /**
       * @description The ID of the Transform entity that has been used to create the output of this Nexset from the parent Nexset.
       *
       * This element is null for detected Nexsets.
       */
      transform_id?: number | null;
      /** @description JSON schema of this Nexset's output. */
      output_schema?: Record<string, never>;
      /**
       * Format: nullable
       * @description Reference ID of the Nexset that this Nexset was created as a copy of. This is only valid if the Nexset was created by issuing a request to the `copy` endpoint of another Nexset.
       */
      copied_from_id?: number;
      /** Format: date-time */
      created_at?: string;
      /** Format: date-time */
      updated_at?: string;
      tags?: string[];
      /** @description The flow type of the origin node. */
      flow_type?: string;
    };
    DataSetMutable: OneOf<[{
      /**
       * @description Set this to `false` to indicate that the payload contains the `transform` code that should be used for creating the output schema.
       *
       * @enum {boolean}
       */
      has_custom_transform?: false;
      /** @description Transform code that should be applied on the parent Nexset. */
      transform?: Record<string, never>;
    }, {
      /**
       * @description Set this to `true` to indicate that the payload contains the `transform_id` of a transform that should be applied for creating the output schema.
       *
       * @enum {boolean}
       */
      has_custom_transform?: true;
      /** @description Id of a reusable record transform that should be applied on the parent Nexset. */
      transform_id?: number;
    }]> & ({
      name?: string;
      description?: string;
      /** @description Nexset ID of the parent Nexset on which all the rules should be applied for creating this Nexset. */
      parent_data_set_id?: number;
      /**
       * @description You can document details about important Nexset attributes by annotating them with short descriptions.
       *
       * Set descriptions for all such attributes by adding them to this object. Attributes should be added in standard JSON schema path format. You can refer to Nexset's output schema structure for guidance.
       */
      output_schema_annotations?: {
        properties?: {
          [key: string]: {
            /** @description Set a short description for this attribute. */
            description?: string;
          };
        };
      };
      /**
       * @description Set this to true and attach the relevant `output_validation_schema` if you want all records to be validated against some JSON schema validation rules.
       *
       * Records that fail validation will be routed to the Nexset error queue instead of the Nexset output.
       */
      output_schema_validation_enabled?: boolean;
      /**
       * @description You can set JSON Schema validation rules that should be applied on every record of this Nexset.
       *
       * See https://json-schema.org/learn/getting-started-step-by-step.html for guidance on writing JSON schema validation rules.
       */
      output_validation_schema?: {
        [key: string]: Record<string, never> | string;
      };
      /** @description You can choose to attach one or more data sinks to this Nexset. Each data sink will receive the output of this Nexset when the Nexset generates output records. */
      data_sinks?: (number | Record<string, never>)[];
      /** @description `Reserved for Nexla UI`: This field is used by Nexla UI for display instructions when displaying this Nexset on the UI. This entry has no impact on how the Nexla data plane processes data for this Nexset. */
      custom_config?: Record<string, never>;
      tags?: string[];
    });
    DataSetCreate: components["schemas"]["DataSetMutable"];
    data_sink: {
      name?: string;
      description?: string;
      /** @description __Credential ID__: Nexla data credential that contains all authentication information for this destination. */
      data_credentials_id?: number;
      /** @description __Nexset ID__: Set the Nexset ID whose output records will be written out to this destination. */
      data_set_id?: number;
      /** @description __Connector Type__: Connector codename. */
      sink_type?: string;
    };
    database_data_sink: {
      /**
       * @description __Create Table In Destination__ If the desired table doesn't exist in your database, you can instruct Nexla to create a table when this destination is first activated.
       *
       * Default Value: `false`
       */
      create_destination?: boolean;
      sink_config?: {
        /** @description __Database__: If the Destination credentials allow access to multiple databases, specify the database to which the destination table belongs. This is only needed if the `data_credentials` entry for this destination is not limited to one database. */
        database?: string;
        /** @description __Table__: Set the table to which you wish to push Nexset records. */
        table: string;
        /**
         * @description __Table Update Mode__: Select whether records should be inserted or upserted into the database.
         *
         * @enum {string}
         */
        "insert.mode": "INSERT" | "UPSERT";
        /**
         * @description __Primary Key Columns__: Set all columns that should be set as primary keys of the table. For multiple columns, enter a comma-separated list of column names.
         *
         * __Required__ if `insert.mode` is set to `UPSERT`
         */
        "primary.key"?: string;
        /** @description __Mapping__: Set rules for how Nexset record attributes should be written into Database Columns. */
        mapping: {
          /**
           * @description Most databases require manual mapping of attributes into columns. With manual mapping, you can set a single attribute to be written into multiple columns. Additionally, you can specify the desired data format for each column.
           *
           *
           * * `auto`: Automatically map attributes to database columns. Column data types will be inferred from record values, and the nesting of attributes will be preserved. __Only available for select warehouses and databases.__
           *
           * * `manual`: Explicitly define attribute mapping and database columns.
           *
           * @enum {string}
           */
          mode: "manual";
          /**
           * @description __Attribute to Database Column Mapping__: Define how attributes should be mapped to database columns.
           *
           * __Required__ if `mapping.mode` is `manual`
           *
           * __Object Definition Rules__:
           *
           * 1. Each Nexset record attribute that needs to be written to one or more columns should be listed as a property of this `mapping` object. In the example, the properties are `nexset_attr_1` and `nexset_attr_2`.
           *
           * 2. Each database column to which the attribute needs to be written is a property of the attribute object above. In the example, `nexset_attr_1` is set to write to columns `db_col_1` and `db_col_2`.
           *
           * 3. Each database column property has a value that defines the desired data format allowed by the database. Here, data written to `db_col_1` will be written as `TEXT`.
           *
           * __Example__
           *   ```
           *   {
           *       "nexset_attr_1":
           *       {
           *           "db_col_1": "TEXT",
           *           "db_col_2": "TEXT"
           *       },
           *       "nexset_attr_2":
           *
           *       {
           *           "db_col_3": "FLOAT64"
           *       }
           *   }
           * ```
           */
          mapping?: {
            [key: string]: {
              [key: string]: string;
            };
          };
          /**
           * @description __Tracker Mode__: Each record that flows through Nexla has an associated unique tracker ID. Set this to `RECORD` to configure the tracker ID to be written out to a database column along with the Nexset record.
           *
           * * `NONE`: The tracker ID won't be written to the database.
           * * `RECORD`: The short form tracker ID containing all required lineage information will be written out in the relevant column.
           *
           * @enum {string}
           */
          tracker_mode: "NONE" | "RECORD";
          /**
           * @description __Column Name for Nexla Tracker__: Name of the column used for the Nexla record tracker information.
           *
           * __Applicable and Required__ if `tracker.mode` is set to `RECORD`
           */
          tracker_name?: string;
        };
        /**
         * @description __Allow column updates with nulls__: Set as false to allow partial upsert of a record with only non-null values.
         *
         * Only valid if `insert.mode` is `UPSERT`
         *
         * Default Value: `true`
         */
        "upsert.nulls"?: boolean;
      };
    };
    as400_data_sink: {
      sink_type: "as400";
    } & Omit<components["schemas"]["data_sink"], "sink_type"> & components["schemas"]["database_data_sink"] & ({
      sink_config?: {
        mapping?: {
          mapping?: {
            [key: string]: {
              [key: string]: "TINYINT" | "SMALLINT" | "MEDIUMINT" | "INT" | "BIGINT" | "DECIMAL" | "FLOAT" | "DOUBLE" | "BIT" | "BOOLEAN" | "BOOL" | "CHAR" | "VARCHAR(4096)" | "BINARY" | "VARBINARY(65535)" | "TINYBLOB" | "BLOB" | "MEDIUMBLOB" | "LONGBLOB" | "TINYTEXT" | "TEXT" | "MEDIUMTEXT" | "LONGTEXT" | "ENUM" | "SET" | "DATE" | "DATETIME" | "TIMESTAMP" | "YEAR";
            };
          };
        };
      };
    });
    file_data_sink: {
      sink_config?: {
        /** @description __Path to Write__: Set the path to which you want to write all files. */
        path: string;
        /**
         * @description __Subfolder Path Format__: You can configure the platform to automatically create subfolders and partition files into those subfolders.
         *
         * Use Nexla system macros like `{YYYY}`, `{MM}`, etc. to create date-time subfolders. You can also split folders by values of an attribute in the Nexset by using the macro `{record.<attribute-name>}`.
         *
         * Default Value: `{YYYY}/{MM}/{dd}`
         */
        "output.dir.name.pattern"?: string;
        /**
         * @description __Custom File Name Prefix__: Generated file names are in the format <prefix>-<nexset-identifier>-<randomizer>. Set this property to define the prefix of each file.
         *
         * You can use Nexla system macros like `{YYYY}`, `{MM}`, etc. to create date-time patterns.
         */
        "file.name.prefix"?: string;
        /**
         * @description __Maximum File Size (in MB)__: The maximum size (MB) of each generated file. Data will automatically be partitioned into multiple files.
         *
         * Default Value: `4096`
         */
        "max.file.size.mb"?: number;
        /**
         * @description __File Format__: Set the output format of the generated files.
         *
         * * `csv`: Files where column values are separated by commas.
         * * `tsv`: Files where column values are separated by tabs.
         * * `json`: Files where each row is a valid JSON object. Note that this is a JSON-line file with a `.json` extension.
         * * `xlsx`: Excel files.
         * * `edi`: EDI files.
         * * `avro`: AVRO files.
         * * `parquet`: Parquet files.
         * * `orc`: ORC files.
         * * `fw`: Fixed width files where each column has a fixed width.
         *
         * @enum {string}
         */
        data_format: "csv" | "tsv" | "json" | "xml" | "xlsx" | "edi" | "avro" | "parquet" | "orc" | "fw";
        /**
         * @description __Parent XML Tag__: Data from each record is wrapped around a parent XML tag when writing to XML files. Set the wrapper tag that should be used. The default wrapper tag is `root`.
         *
         * Only valid if `data_format` is `orc`
         *
         * Default Value: `root`
         */
        "xml.root"?: string;
        /**
         * @description __ORC Compression Type__: Select the type of compression algorithm that should be used to compress file contents into ORC files.
         *
         * Only valid if `data_format` is `orc`
         *
         * Default Value: `zlib`
         *
         * @enum {string}
         */
        "orc.compress"?: "none" | "zlib" | "snappy" | "lzo" | "lz4";
        /**
         * @description __Write Attribute Names As Header?__: Set this option if you want the attribute names to be added as a header row on each file.
         *
         * Only applicable if `data_format` is `fw`.
         *
         * Default Value: `true`
         */
        "write.header"?: boolean;
        /**
         * @description __Length of Each Field in File__: Enter the length of each field in the file. This should be entered as a comma-separated list of numbers, for ex: `10,12,8,15,20`.
         *
         * Only applicable if `data_format` is `fw`.
         */
        "field.lengths"?: string;
        /**
         * @description __Padding Character__: Choose or type the character that should be used to separate fields. For ex: `_`.
         *
         * Only applicable if `data_format` is `fw`.
         * Default: single space ` `
         *
         * Common Values:
         * * ` `: Single Space
         * * `` : No Padding
         * * `,`: Comma
         * * `\\t`: Tab
         * * `\\n`: Newline
         * * `;`: Semicolon
         * * `|`: Pipe
         * * `^`: Caret
         */
        "padding.character"?: string;
        /**
         * @description __Line Separation Character__: Specify the character that should be recognized by the platform as an indicator of a new line.
         *
         * Only applicable if `data_format` is `fw`.
         *
         * Default:  `\\n`
         *
         * Common Values:
         * * `\\t`: Tab
         * * `\\n`: Newline
         */
        "line.separator"?: string;
        /** @description __Mapping__: Set rules for how Nexset record attributes should be written into the generated files. */
        mapping?: {
          /**
           * @description Based on the desired `data_format`, Nexla automatically converts Nexset records into appropriate contents in output files.
           *
           * However, for some `data_formats` such as `csv` that support the concept of additional rules like the column order, you can choose to manually assign Nexset attributes to output row mapping.
           *
           *
           * * `auto` : Automatically map Nexset attributes to output files. Recommended for data_formats `json`, `xml`, `edi`, `avro`, `parquet`, and `orc`.
           *
           * * `manual`: Explicitly define attribute mapping and columns in the output file. Recommended for data_formats `csv`, `tsv`, `xlsx`, and `GOOGLE_SPREADSHEET`.
           *
           * @enum {string}
           */
          mode: "auto" | "manual";
          /**
           * @description __Attribute to File Column Mapping__: Define how attributes should be mapped to database columns.
           *
           * __Required__ if `mapping.mode` is `manual`
           *
           * __Object Definition Rules__:
           *
           * Each Nexset record attribute that needs to be written to one or more columns should be listed as a property of this `mapping` object. In the example, the properties are `nexset_attr_1` and `nexset_attr_2`.
           *
           * __Example__
           *   ```
           *   {
           *       "nexset_attr_1": [
           *           "file_col_1",
           *           "file_col_2"
           *         ],
           *       "nexset_attr_2": [
           *           "file_col_3"
           *         ]
           *   }
           * ```
           */
          mapping?: {
            [key: string]: string[];
          };
          /**
           * Format: strings
           * @description __Field Order__: The order of the column names in the output file.
           *
           * __Required__ if `mapping.mode` is `manual`
           */
          fields_order?: unknown[];
          /**
           * @description __Optional Header Content__: You can choose to add a predefined header in each generated output file. The format of this string should match the format of a row of data in that `data_format`.
           *
           * For example, if the `data_format` is `xml`, the header would be an XML object like `<hdate>{now}</hdate>`, but if the desired value is a JSON string, it would be `"{\"header\":\"{now}\"}`.
           *
           * Note that this field supports Nexla date-time macros like `{now}`.
           */
          header_template?: string;
          /**
           * @description __Tracker Mode__: Each record that flows through Nexla has an associated unique tracker ID. Set this to `RECORD` to configure the tracker ID to be written out to a column along with the Nexset record.
           *
           * * `NONE`: The tracker won't be written to the database.
           * * `RECORD`: The short-form tracker containing all required lineage information will be written out in the relevant column.
           *
           * @enum {string}
           */
          tracker_mode: "NONE" | "RECORD";
          /**
           * @description __Column Name for Nexla Tracker__: The column name for the Nexla record tracker information.
           *
           * __Applicable and Required__ if `tracker.mode` is set to `RECORD`.
           */
          tracker_name?: string;
        };
      };
    };
    azure_blb_data_sink: {
      sink_type: "azure_blb";
    } & Omit<components["schemas"]["data_sink"], "sink_type"> & components["schemas"]["file_data_sink"];
    azure_data_lake_data_sink: {
      sink_type: "azure_data_lake";
    } & Omit<components["schemas"]["data_sink"], "sink_type"> & components["schemas"]["file_data_sink"];
    azure_synapse_data_sink: {
      sink_type: "azure_synapse";
    } & Omit<components["schemas"]["data_sink"], "sink_type"> & components["schemas"]["database_data_sink"] & ({
      sink_config?: {
        mapping?: {
          mapping?: {
            [key: string]: {
              [key: string]: "BIGINT" | "INT" | "SMALLINT" | "TINYINT" | "BIT" | "NUMERIC" | "MONEY" | "SMALLMONEY" | "REAL" | "DATETIME" | "SMALLDATETIME" | "CHAR(3000)" | "VARCHAR(100)" | "VARCHAR(3000)" | "VARCHAR(max)" | "TEXT" | "NCHAR" | "NVARCHAR" | "NTEXT" | "BINARY" | "VARBINARY" | "TABLE" | "UNIQUEIDENTIFIER" | "DECIMAL(18, 4)" | "FLOAT(12)";
            };
          };
        };
      };
    });
    bigquery_data_sink: {
      sink_type: "bigquery";
    } & Omit<components["schemas"]["data_sink"], "sink_type"> & components["schemas"]["database_data_sink"] & ({
      sink_config?: {
        /** @description __Partitioning Column__: You can choose to have the data partitioned by a specific column when it is written to the destination table. Set the partitioning column if you wish to leverage that capability. */
        "partitioning.column"?: string;
        /** @description __Clustering Columns__: You can choose to leverage column clustering when data is written to the destination tables. Set this value to a comma-separated list of columns that should be used for clustering. */
        "clustering.columns"?: string;
        mapping?: {
          /** @enum {string} */
          mode?: "auto" | "manual";
          mapping?: {
            [key: string]: {
              [key: string]: "BOOLEAN" | "DATE" | "DATETIME" | "TIME" | "TIMESTAMP" | "FLOAT64" | "INT64" | "STRING" | "NUMERIC";
            };
          };
        };
      };
    });
    box_data_sink: {
      sink_type: "box";
    } & Omit<components["schemas"]["data_sink"], "sink_type"> & components["schemas"]["file_data_sink"];
    cloudsql_mysql_data_sink: {
      sink_type: "cloudsql_mysql";
    } & Omit<components["schemas"]["data_sink"], "sink_type"> & components["schemas"]["database_data_sink"] & ({
      sink_config?: {
        mapping?: {
          mapping?: {
            [key: string]: {
              [key: string]: "TINYINT" | "SMALLINT" | "MEDIUMINT" | "INT" | "BIGINT" | "DECIMAL" | "FLOAT" | "DOUBLE" | "BIT" | "BOOLEAN" | "BOOL" | "CHAR" | "VARCHAR(4096)" | "BINARY" | "VARBINARY(65535)" | "TINYBLOB" | "BLOB" | "MEDIUMBLOB" | "LONGBLOB" | "TINYTEXT" | "TEXT" | "MEDIUMTEXT" | "LONGTEXT" | "ENUM" | "SET" | "DATE" | "DATETIME" | "TIMESTAMP" | "YEAR";
            };
          };
        };
      };
    });
    cloudsql_postgres_data_sink: {
      sink_type: "cloudsql_postgres";
    } & Omit<components["schemas"]["data_sink"], "sink_type"> & components["schemas"]["database_data_sink"] & ({
      sink_config?: {
        mapping?: {
          mapping?: {
            [key: string]: {
              [key: string]: "BIGINT" | "INT8" | "BIGSERIAL" | "SERIAL8" | "BIT" | "BIT_VARYING" | "VARBIT" | "BOOLEAN" | "BOOL" | "BOX" | "BYTEA" | "CHAR" | "VARCHAR" | "CHARACTER VARYING" | "CIDR" | "CIRCLE" | "DATE" | "DOUBLE PRECISION" | "INET" | "INTEGER" | "INT" | "INT4" | "INTERVAL" | "JSON" | "JSONB" | "LINE" | "LSEG" | "MACADDR" | "MONEY" | "NUMERIC" | "DECIMAL" | "PATH" | "PG_LSN" | "POINT" | "POLYGON" | "REAL" | "FLOAT4" | "SMALLINT" | "INT2" | "SMALLSERIAL" | "SERIAL2" | "SERIAL" | "SERIAL4" | "TEXT" | "TIME" | "TIMETZ" | "TIMESTAMP" | "TIMESTAMPTZ" | "TSQUERY" | "TSVECTOR" | "TXID_SNAPSHOT" | "UUID" | "XML";
            };
          };
        };
      };
    });
    cloudsql_sqlserver_data_sink: {
      sink_type: "cloudsql_sqlserver";
    } & Omit<components["schemas"]["data_sink"], "sink_type"> & components["schemas"]["database_data_sink"] & ({
      sink_config?: {
        mapping?: {
          mapping?: {
            [key: string]: {
              [key: string]: "BIGINT" | "INT" | "SMALLINT" | "TINYINT" | "BIT" | "NUMERIC" | "MONEY" | "SMALLMONEY" | "REAL" | "DATETIME" | "SMALLDATETIME" | "CHAR(3000)" | "VARCHAR(100)" | "VARCHAR(3000)" | "VARCHAR(max)" | "TEXT" | "NCHAR" | "NVARCHAR" | "NTEXT" | "BINARY" | "VARBINARY" | "TABLE" | "UNIQUEIDENTIFIER" | "DECIMAL(18, 4)" | "FLOAT(12)";
            };
          };
        };
      };
    });
    stream_data_sink: {
      sink_config?: Record<string, never>;
    };
    confluent_kafka_data_sink: {
      sink_type: "confluent_kafka";
    } & Omit<components["schemas"]["data_sink"], "sink_type"> & components["schemas"]["stream_data_sink"] & {
      sink_config?: {
        /** @description __Topic__: Select the topic for your data. */
        topic: string;
        /**
         * @description __Include Nexla Metadata in Message?__: Enable this check to include Nexla metadata as part of the message.
         * Default value: `false`
         */
        "include.metadata"?: boolean;
        /** @description __Attribute used as Message Key__: Set the Nexset record attribute that will be used as a key for the Kafka message. */
        "message.key"?: string;
      };
    };
    data_map_data_sink: {
      sink_type: "data_map";
    } & Omit<components["schemas"]["data_sink"], "sink_type"> & {
      sink_config?: {
        /** @description __Mapping__: Rules for how Nexset record attributes should be written into Nexla Dynamic Lookup columns. */
        mapping: {
          /**
           * @description __Mapping Mode__: Setting this to `auto` instructs the platform to automatically create column names to match attribute names.
           *
           * @enum {string}
           */
          mode: "auto";
        };
      };
      data_map: {
        /** @description __Lookup Name__: This destination will create and be linked to a Nexla Lookup. You can choose a different name for the lookup, although we usually recommend using the same name. */
        name: string;
        /** @description __Primary Key__: Set the Nexset attribute that should be used as a primary key in the lookup. */
        map_primary_key: string;
        /**
         * @description __Return Default Values__: If this value is set to true, any query for lookup rows will return the default values of a column if the Nexset record does not contain that attribute.
         *
         * Default value: `true`
         */
        emit_data_default?: boolean;
        /**
         * @description __Column Default Values__: You can set default values for any column if a value for that column is not present in a Nexset row.
         *
         * Example:
         *   ```
         *     {
         *       "attr1" : "NA",
         *       "attr2": ""
         *     }
         *
         *   ```
         */
        data_defaults?: {
          [key: string]: string;
        };
      };
    };
    databricks_data_sink: {
      sink_type: "databricks";
    } & Omit<components["schemas"]["data_sink"], "sink_type"> & components["schemas"]["database_data_sink"] & ({
      sink_config?: {
        mapping?: {
          /** @enum {string} */
          mode?: "auto" | "manual";
          mapping?: {
            [key: string]: {
              [key: string]: "SMALLINT" | "INT2" | "INTEGER" | "INT" | "INT4" | "BIGINT" | "INT8" | "DECIMAL(18,4)" | "NUMERIC(18,4)" | "REAL" | "FLOAT4" | "DOUBLE PRECISION" | "FLOAT8" | "BOOLEAN" | "BOOL" | "CHAR" | "CHARACTER" | "VARCHAR(65535)" | "CHARACTER VARYING" | "DATE" | "TIMESTAMP" | "TIMESTAMPTZ";
            };
          };
        };
      };
    });
    delta_lake_azure_blb_data_sink: {
      sink_type: "delta_lake_azure_blb";
    } & Omit<components["schemas"]["data_sink"], "sink_type"> & ({
      sink_config?: {
        /** @description __Path to Write__: Set the path to which you want to write all files. */
        path: string;
        /**
         * @description __Subfolder Path Format__: You can configure the platform to automatically create subfolders and partition files into those subfolders.
         *
         * Use Nexla system macros like `{YYYY}`, `{MM}`, etc. to create date-time subfolders. You can also split folders based on the values of an attribute in the Nexset by using the macro `{record.<attribute-name>}`.
         *
         * Default Value: `{YYYY}/{MM}/{dd}`
         */
        "output.dir.name.pattern"?: string;
        /**
         * @description __File Format__: Set the output format of the generated files.
         *
         * @enum {string}
         */
        data_format: "delta";
        /**
         * @description __Insertion Mode__: Select this mode if you wish to always add new records to the table.
         *
         * * `Insert`: __Append / Insert new records__ - Select this mode if you wish to always add new records to the table.
         *
         * * `Update`: __Update Records in Table__ - Select this mode if you wish to update existing records anytime the table already contains records with matching keys.
         *
         * Default value: `Insert`
         *
         * @enum {string}
         */
        "delta.table.insert.mode"?: "Insert" | "Update";
        /**
         * @description __Record Identifier Keys/Fields__: Enter the fields/keys that will be used for matching during updating. This entry should be in the form of a comma-separated string.
         *
         * __Applicable and required__ if `delta.table.insert.mode` is `Update`
         */
        "delta.table.keys"?: string;
      };
    });
    delta_lake_azure_data_lake_data_sink: {
      sink_type: "delta_lake_azure_data_lake";
    } & Omit<components["schemas"]["data_sink"], "sink_type"> & ({
      sink_config?: {
        /** @description __Path to Write__: Set the path to which you want to write all files. */
        path: string;
        /**
         * @description __Subfolder Path Format__: You can configure the platform to automatically create subfolders and partition files into those subfolders.
         *
         * Use Nexla system macros like `{YYYY}`, `{MM}`, etc. to create date-time sub-folders. You can also split folders based on the values of an attribute in the Nexset by using the macro `{record.<attribute-name>}`.
         *
         * Default Value: `{YYYY}/{MM}/{dd}`
         */
        "output.dir.name.pattern"?: string;
        /**
         * @description __File Format__: Set the output format of the generated files.
         *
         * @enum {string}
         */
        data_format: "delta";
        /**
         * @description __Insertion Mode__: Select this mode if you wish to always add new records to the table.
         *
         * * `Insert`: __Append / Insert new records__ - Select this mode if you wish to always add new records to the table.
         *
         * * `Update`: __Update Records in Table__ - Select this mode if you wish to update existing records anytime the table already contains records with matching keys.
         *
         * Default value: `Insert`
         *
         * @enum {string}
         */
        "delta.table.insert.mode"?: "Insert" | "Update";
        /**
         * @description __Record Identifier Keys/Fields__: Enter the fields/keys that will be used for matching during updating. This entry should be in the form of a comma-separated string.
         *
         * __Applicable and required__ if `delta.table.insert.mode` is `Update`
         */
        "delta.table.keys"?: string;
      };
    });
    delta_lake_s3_data_sink: {
      sink_type: "delta_lake_s3";
    } & Omit<components["schemas"]["data_sink"], "sink_type"> & ({
      sink_config?: {
        /** @description __Path to Write__: Set the path to which you want to write all files. */
        path: string;
        /**
         * @description __Subfolder Path Format__: You can configure the platform to automatically create subfolders and partition files into those subfolders.
         *
         * Use Nexla system macros like `{YYYY}`, `{MM}`, etc. to create date-time sub-folders. You can also split folders based on the values of an attribute in the Nexset by using the macro `{record.<attribute-name>}`.
         *
         * Default Value: `{YYYY}/{MM}/{dd}`
         */
        "output.dir.name.pattern"?: string;
        /**
         * @description __File Format__: Set the output format of the generated files.
         *
         * @enum {string}
         */
        data_format: "delta";
        /**
         * @description __Insertion Mode__: Select this mode if you wish to always add new records to the table.
         *
         * * `Insert`: __Append / Insert new records__ - Select this mode if you wish to always add new records to the table.
         *
         * * `Update`: __Update Records in Table__ - Select this mode if you wish to update existing records anytime the table already contains records with matching keys.
         *
         * Default value: `Insert`
         *
         * @enum {string}
         */
        "delta.table.insert.mode"?: "Insert" | "Update";
        /**
         * @description __Record Identifier Keys/Fields__: Enter the fields/keys that will be used for matching during updating. This entry should be in the form of a comma-separated string.
         *
         * __Applicable and required__ if `delta.table.insert.mode` is `Update`
         */
        "delta.table.keys"?: string;
      };
    });
    dropbox_data_sink: {
      sink_type: "dropbox";
    } & Omit<components["schemas"]["data_sink"], "sink_type"> & components["schemas"]["file_data_sink"];
    nosql_data_sink: {
      sink_config?: {
        /**
         * @description __Database__: If the destination credentials allow access to multiple databases, specify the database to which the destination collection belongs.
         *
         * __Required__ if the `data_credentials` access for this destination is not limited to one database.
         */
        database: string;
        /** @description __Collection__: Set the collection in which you wish to create documents. */
        collection: string;
      };
    };
    dynamodb_data_sink: {
      sink_type: "dynamodb";
    } & Omit<components["schemas"]["data_sink"], "sink_type"> & components["schemas"]["nosql_data_sink"];
    email_data_sink: {
      sink_type: "email";
    } & Omit<components["schemas"]["data_sink"], "sink_type"> & components["schemas"]["file_data_sink"];
    firebase_data_sink: {
      sink_type: "firebase";
    } & Omit<components["schemas"]["data_sink"], "sink_type"> & components["schemas"]["nosql_data_sink"];
    firebolt_data_sink: {
      sink_type: "firebolt";
    } & Omit<components["schemas"]["data_sink"], "sink_type"> & components["schemas"]["database_data_sink"] & ({
      sink_config?: {
        /**
         * @description __Firebolt Table Type__: Set the type of Firebolt table to which this destination is to be mapped.
         *
         *
         * @enum {string}
         */
        "firebolt.table.type"?: "FACT" | "DIMENSION";
        mapping?: {
          mapping?: {
            [key: string]: {
              [key: string]: "INT" | "INTEGER" | "BIGINT" | "LONG" | "FLOAT" | "DOUBLE" | "DOUBLE PRECISION" | "BOOLEAN" | "VARCHAR" | "TEXT" | "STRING" | "DATE" | "DATETIME" | "TIMESTAMP" | "ARRAY";
            };
          };
        };
      };
    });
    ftp_data_sink: {
      sink_type: "ftp";
    } & Omit<components["schemas"]["data_sink"], "sink_type"> & components["schemas"]["file_data_sink"];
    gcp_alloydb_data_sink: {
      sink_type: "gcp_alloydb";
    } & Omit<components["schemas"]["data_sink"], "sink_type"> & components["schemas"]["database_data_sink"] & ({
      sink_config?: {
        mapping?: {
          mapping?: {
            [key: string]: {
              [key: string]: "BIGINT" | "INT8" | "BIGSERIAL" | "SERIAL8" | "BIT" | "BIT_VARYING" | "VARBIT" | "BOOLEAN" | "BOOL" | "BOX" | "BYTEA" | "CHAR" | "VARCHAR" | "CHARACTER VARYING" | "CIDR" | "CIRCLE" | "DATE" | "DOUBLE PRECISION" | "INET" | "INTEGER" | "INT" | "INT4" | "INTERVAL" | "JSON" | "JSONB" | "LINE" | "LSEG" | "MACADDR" | "MONEY" | "NUMERIC" | "DECIMAL" | "PATH" | "PG_LSN" | "POINT" | "POLYGON" | "REAL" | "FLOAT4" | "SMALLINT" | "INT2" | "SMALLSERIAL" | "SERIAL2" | "SERIAL" | "SERIAL4" | "TEXT" | "TIME" | "TIMETZ" | "TIMESTAMP" | "TIMESTAMPTZ" | "TSQUERY" | "TSVECTOR" | "TXID_SNAPSHOT" | "UUID" | "XML";
            };
          };
        };
      };
    });
    gcp_spanner_data_sink: {
      sink_type: "gcp_spanner";
    } & Omit<components["schemas"]["data_sink"], "sink_type"> & components["schemas"]["database_data_sink"] & ({
      sink_config?: {
        mapping?: {
          mapping?: {
            [key: string]: {
              [key: string]: "ARRAY" | "BOOL" | "BYTES" | "DATE" | "JSON" | "INT64" | "NUMERIC" | "FLOAT64" | "STRING" | "TIMESTAMP";
            };
          };
        };
      };
    });
    gcs_data_sink: {
      sink_type: "gcs";
    } & Omit<components["schemas"]["data_sink"], "sink_type"> & components["schemas"]["file_data_sink"];
    gdrive_data_sink: {
      sink_type: "gdrive";
    } & Omit<components["schemas"]["data_sink"], "sink_type"> & ({
      sink_config?: {
        /**
         * @description __Path to Write__: Set the path to which you want to write all files.
         *
         * For Google Drive, this is the unique ID of the file/folder into which you want to write the data.
         *
         * Example: `1MZhNV996K77b-kLYC4yIdG7PJiUUGBwV`
         */
        path: string;
        /**
         * @description __Path (display format)__: This should be the human-readable Google Drive path. This is not required but is useful for keeping track of the actual folder path.
         *
         * Example: `demo/demodata`
         */
        "ui.display_path"?: string;
        /**
         * @description You can choose to always write the Nexset records to a specific Google spreadsheet instead of creating new files in a Google Drive folder.
         *
         * Add this property and set its value to `application/vnd.google-apps.spreadsheet` if you want to write your data to a specific spreadsheet instead of creating new files in the target folder.
         *
         * @enum {string}
         */
        "ui.selected_file_mime_type"?: "application/vnd.google-apps.spreadsheet";
        /**
         * @description __Subfolder Path Format__: You can configure the platform to automatically create sub-folders and partition files into those sub-folders.
         *
         * Use Nexla system macros like `{YYYY}`, `{MM}`, etc. to create datetime sub-folders. You can also split folders based on the values of an attribute in the Nexset by using the macro `{record.<attribute-name>}`.
         *
         * Default Value: `{YYYY}/{MM}/{dd}`
         *
         * __Applicable__: Only if `ui.selected_file_mime_type` is absent
         */
        "output.dir.name.pattern"?: string;
        /**
         * @description __Custom File Name Prefix__: Generated file names are in the format <prefix>-<nexset-identifier>-<randomizer>. Set this property to define the prefix of each file.
         *
         * You can use Nexla system macros like `{YYYY}`, `{MM}`, etc. to create datetime patterns.
         *
         * __Applicable__: Only if `ui.selected_file_mime_type` is absent
         */
        "file.name.prefix"?: string;
        /**
         * @description __Maximum File Size (in MB)__: The maximum size (MB) of each generated file. Data will be automatically partitioned into multiple files.
         *
         * Default Value: `4096`
         *
         * __Applicable__: Only if `ui.selected_file_mime_type` is absent
         */
        "max.file.size.mb"?: number;
        /**
         * @description __File Format__: Set the output format of the generated files.
         *
         * @enum {string}
         */
        data_format: "csv" | "tsv" | "json" | "xml" | "xlsx" | "edi" | "avro" | "parquet" | "orc" | "GOOGLE_SPREADSHEET";
        /**
         * @description __Row Insertion Mode__:  If you are writing the Nexset to a specific sheet, choose whether Nexla should completely overwrite an existing sheet while writing out data during the latest execution or always append new records as new rows.
         *
         * __Applicable and required__: only if `ui.selected_file_mime_type` is `application/vnd.google-apps.spreadsheet`.
         *
         * @enum {string}
         */
        "insert.mode"?: "OVERWRITE" | "INSERT_ROWS";
        /**
         * @description __Configure Sheet Name And Starting Cell__: If you are writing the Nexset to a specific sheet, you can configure the name of the sheet and/or starting cell for the data output.
         *
         * This is an optional step that allows you to define the exact sheet name and/or starting cell for the generated spreadsheet.
         *
         * __Applicable__: only if `ui.selected_file_mime_type` is `application/vnd.google-apps.spreadsheet`.
         */
        range?: string;
        /**
         * @description __Cell Range To Clear Before Writing Data__: If you are writing the Nexset to a specific sheet, you can configure the platform to clear a specific cell range before writing a new batch of records.
         *
         * __Applicable__: only if `ui.selected_file_mime_type` is `application/vnd.google-apps.spreadsheet`.
         */
        "clear.range"?: string;
      };
    }) & components["schemas"]["file_data_sink"];
    google_pubsub_data_sink: {
      sink_type: "google_pubsub";
    } & Omit<components["schemas"]["data_sink"], "sink_type"> & components["schemas"]["stream_data_sink"] & {
      sink_config?: {
        /** @description __Topic__: Select the topic for your data. */
        topic: string;
        /** @description __Subscription__: Set the subscription name if you are choosing to create a new topic. */
        subscription?: string;
        /**
         * @description __Include Nexla Metadata in Message?__: Enable this check to include Nexla metadata as part of the message.
         *
         * Default value: `false`
         */
        "include.metadata"?: boolean;
        /** @description __Attribute used as Message Key__: Set the Nexset record attribute that will be used as a key for the Kafka message. */
        "message.key"?: string;
      };
    };
    jms_data_sink: {
      sink_type: "jms";
    } & Omit<components["schemas"]["data_sink"], "sink_type"> & components["schemas"]["stream_data_sink"] & ({
      sink_config?: {
        /**
         * @description __Type of Destination__: Select whether this destination is a topic or a queue.
         *
         * @enum {string}
         */
        "target.type": "topic" | "queue";
        /** @description __Topic / Queue Name  __: Configure the name of the topic/queue where data should be written. */
        "target.name": string;
        /**
         * @description __Data Format__: Select the data format parser to be used for data written to this topic or queue. This is usually `json`.
         *
         * @enum {string}
         */
        "writer.type": "csv" | "tsv" | "txt" | "xml" | "json";
      };
    });
    kafka_data_sink: {
      sink_type: "kafka";
    } & Omit<components["schemas"]["data_sink"], "sink_type"> & components["schemas"]["stream_data_sink"] & {
      sink_config?: {
        /** @description __Topic__: Select the topic for your data. */
        topic: string;
        /**
         * @description __Include Nexla Metadata in Message?__: Enable this check to include Nexla metadata as part of the message.
         * Default value: `false`
         */
        "include.metadata"?: boolean;
        /** @description __Attribute used as Message Key__: Set the Nexset record attribute that will be used as a key for the Kafka message. */
        "message.key"?: string;
      };
    };
    min_io_s3_data_sink: {
      sink_type: "min_io_s3";
    } & Omit<components["schemas"]["data_sink"], "sink_type"> & components["schemas"]["file_data_sink"];
    mongo_data_sink: {
      sink_type: "mongo";
    } & Omit<components["schemas"]["data_sink"], "sink_type"> & components["schemas"]["nosql_data_sink"];
    mysql_data_sink: {
      sink_type: "mysql";
    } & Omit<components["schemas"]["data_sink"], "sink_type"> & components["schemas"]["database_data_sink"] & ({
      sink_config?: {
        mapping?: {
          mapping?: {
            [key: string]: {
              [key: string]: "TINYINT" | "SMALLINT" | "MEDIUMINT" | "INT" | "BIGINT" | "DECIMAL" | "FLOAT" | "DOUBLE" | "BIT" | "BOOLEAN" | "BOOL" | "CHAR" | "VARCHAR(4096)" | "BINARY" | "VARBINARY(65535)" | "TINYBLOB" | "BLOB" | "MEDIUMBLOB" | "LONGBLOB" | "TINYTEXT" | "TEXT" | "MEDIUMTEXT" | "LONGTEXT" | "ENUM" | "SET" | "DATE" | "DATETIME" | "TIMESTAMP" | "YEAR";
            };
          };
        };
      };
    });
    netsuite_jdbc_data_sink: {
      sink_type: "netsuite_jdbc";
    } & Omit<components["schemas"]["data_sink"], "sink_type"> & components["schemas"]["database_data_sink"] & ({
      sink_config?: {
        mapping?: {
          mapping?: {
            [key: string]: {
              [key: string]: "BIGINT" | "INT8" | "BIGSERIAL" | "SERIAL8" | "BIT" | "BIT_VARYING" | "VARBIT" | "BOOLEAN" | "BOOL" | "BOX" | "BYTEA" | "CHAR" | "VARCHAR" | "CHARACTER VARYING" | "CIDR" | "CIRCLE" | "DATE" | "DOUBLE PRECISION" | "INET" | "INTEGER" | "INT" | "INT4" | "INTERVAL" | "JSON" | "JSONB" | "LINE" | "LSEG" | "MACADDR" | "MONEY" | "NUMERIC" | "DECIMAL" | "PATH" | "PG_LSN" | "POINT" | "POLYGON" | "REAL" | "FLOAT4" | "SMALLINT" | "INT2" | "SMALLSERIAL" | "SERIAL2" | "SERIAL" | "SERIAL4" | "TEXT" | "TIME" | "TIMETZ" | "TIMESTAMP" | "TIMESTAMPTZ" | "TSQUERY" | "TSVECTOR" | "TXID_SNAPSHOT" | "UUID" | "XML";
            };
          };
        };
      };
    });
    oracle_data_sink: {
      sink_type: "oracle";
    } & Omit<components["schemas"]["data_sink"], "sink_type"> & components["schemas"]["database_data_sink"] & ({
      sink_config?: {
        mapping?: {
          mapping?: {
            [key: string]: {
              [key: string]: "VARCHAR2(3000)" | "NUMBER(10,0)" | "NUMBER(1,0)" | "BINARY_FLOAT" | "BINARY_DOUBLE" | "RAW(2000)" | "LONG RAW" | "CHAR(2000)" | "NCHAR(2000)" | "BLOB" | "DATE" | "INTERVAL YEAR TO MONTH" | "INTERVAL DAY TO SECOND";
            };
          };
        };
      };
    });
    oracle_autonomous_data_sink: {
      sink_type: "oracle_autonomous";
    } & Omit<components["schemas"]["data_sink"], "sink_type"> & components["schemas"]["database_data_sink"] & ({
      sink_config?: {
        mapping?: {
          mapping?: {
            [key: string]: {
              [key: string]: "VARCHAR2(3000)" | "NUMBER(10,0)" | "NUMBER(1,0)" | "BINARY_FLOAT" | "BINARY_DOUBLE" | "RAW(2000)" | "LONG RAW" | "CHAR(2000)" | "NCHAR(2000)" | "BLOB" | "DATE" | "TIMESTAMP" | "INTERVAL YEAR TO MONTH" | "INTERVAL DAY TO SECOND";
            };
          };
        };
      };
    });
    vector_db_data_sink: {
      /**
       * @description __Create Table In Destination__ If the desired table doesn't exist in your database, you can instruct Nexla to create a table when this destination is first activated.
       *
       * Default Value: `false`
       */
      create_destination?: boolean;
      sink_config?: {
        /** @description __Database__: If the Destination credentials allow access to multiple databases, specify the database to which the destination table belongs. This is only needed if the `data_credentials` entry for this destination is not limited to one database. */
        database?: string;
        /** @description __Table__: Set the table to which you wish to push Nexset records. */
        table: string;
        /**
         * @description __Table Update Mode__: Select whether records should be inserted or upserted into the database.
         *
         * @enum {string}
         */
        "insert.mode": "INSERT" | "UPSERT";
        /**
         * @description __Primary Key Columns__: Set all columns that should be set as primary keys of the table. For multiple columns, enter a comma-separated list of column names.
         *
         * __Required__ if `insert.mode` is set to `UPSERT`
         */
        "primary.key"?: string;
        /** @description __Mapping__: Set rules for how Nexset record attributes should be written into Database Columns. */
        mapping: {
          /**
           * @description Most databases require manual mapping of attributes into columns. With manual mapping, you can set a single attribute to be written into multiple columns. Additionally, you can specify the desired data format for each column.
           *
           *
           * * `auto`: Automatically map attributes to database columns. Column data types will be inferred from record values, and the nesting of attributes will be preserved. __Only available for select warehouses and databases.__
           *
           * * `manual`: Explicitly define attribute mapping and database columns.
           *
           * @enum {string}
           */
          mode: "manual";
          /**
           * @description __Attribute to Database Column Mapping__: Define how attributes should be mapped to database columns.
           *
           * __Required__ if `mapping.mode` is `manual`
           *
           * __Object Definition Rules__:
           *
           * 1. Each Nexset record attribute that needs to be written to one or more columns should be listed as a property of this `mapping` object. In the example, the properties are `nexset_attr_1` and `nexset_attr_2`.
           *
           * 2. Each database column to which the attribute needs to be written is a property of the attribute object above. In the example, `nexset_attr_1` is set to write to columns `db_col_1` and `db_col_2`.
           *
           * 3. Each database column property has a value that defines the desired data format allowed by the database. Here, data written to `db_col_1` will be written as `TEXT`.
           *
           * __Example__
           *   ```
           *   {
           *       "nexset_attr_1":
           *       {
           *           "db_col_1": "TEXT",
           *           "db_col_2": "TEXT"
           *       },
           *       "nexset_attr_2":
           *
           *       {
           *           "db_col_3": "FLOAT64"
           *       }
           *   }
           * ```
           */
          mapping?: {
            [key: string]: {
              [key: string]: string;
            };
          };
          /**
           * @description __Tracker Mode__: Each record that flows through Nexla has an associated unique tracker ID. Set this to `RECORD` to configure the tracker ID to be written out to a database column along with the Nexset record.
           *
           * * `NONE`: The tracker ID won't be written to the database.
           * * `RECORD`: The short form tracker ID containing all required lineage information will be written out in the relevant column.
           *
           * @enum {string}
           */
          tracker_mode: "NONE" | "RECORD";
          /**
           * @description __Column Name for Nexla Tracker__: Name of the column used for the Nexla record tracker information.
           *
           * __Applicable and Required__ if `tracker.mode` is set to `RECORD`
           */
          tracker_name?: string;
        };
        /**
         * @description __Allow column updates with nulls__: Set as false to allow partial upsert of a record with only non-null values.
         *
         * Only valid if `insert.mode` is `UPSERT`
         *
         * Default Value: `true`
         */
        "upsert.nulls"?: boolean;
      };
    };
    pinecone_data_sink: {
      sink_type: "pinecone";
    } & Omit<components["schemas"]["data_sink"], "sink_type"> & {
      sink_config?: {
        /** @description __Index__: Enter the name of the index where the vectors will be stored. */
        database: string;
        /**
         * @description __Namespace__: Set the namespace to store the vectors within the selected Pinecone database.
         * You can use the default namespace or specify a custom namespace.
         *
         * @default
         */
        collection: string;
        /** @description __Vector Mapping__: Enter the mapping of the vector fields to the columns in the collection. */
        vector_mapping?: string[];
        /**
         * @description __Upsert Parallelism__: Enter the number of parallel upserts to be performed.
         *
         * @default 1
         */
        "pinecone.upsert.parallelism"?: number;
      };
    } & components["schemas"]["vector_db_data_sink"];
    postgres_data_sink: {
      sink_type: "postgres";
    } & Omit<components["schemas"]["data_sink"], "sink_type"> & components["schemas"]["database_data_sink"] & ({
      sink_config?: {
        mapping?: {
          mapping?: {
            [key: string]: {
              [key: string]: "BIGINT" | "INT8" | "BIGSERIAL" | "SERIAL8" | "BIT" | "BIT_VARYING" | "VARBIT" | "BOOLEAN" | "BOOL" | "BOX" | "BYTEA" | "CHAR" | "VARCHAR" | "CHARACTER VARYING" | "CIDR" | "CIRCLE" | "DATE" | "DOUBLE PRECISION" | "INET" | "INTEGER" | "INT" | "INT4" | "INTERVAL" | "JSON" | "JSONB" | "LINE" | "LSEG" | "MACADDR" | "MONEY" | "NUMERIC" | "DECIMAL" | "PATH" | "PG_LSN" | "POINT" | "POLYGON" | "REAL" | "FLOAT4" | "SMALLINT" | "INT2" | "SMALLSERIAL" | "SERIAL2" | "SERIAL" | "SERIAL4" | "TEXT" | "TIME" | "TIMETZ" | "TIMESTAMP" | "TIMESTAMPTZ" | "TSQUERY" | "TSVECTOR" | "TXID_SNAPSHOT" | "UUID" | "XML";
            };
          };
        };
      };
    });
    redshift_data_sink: {
      sink_type: "redshift";
    } & Omit<components["schemas"]["data_sink"], "sink_type"> & components["schemas"]["database_data_sink"] & ({
      sink_config?: {
        /** @description __Partitioning Column__: You can choose to have the data partitioned by a specific column when it is written to the destination table. Set the partitioning column if you wish to leverage that capability. */
        "partitioning.column"?: string;
        /** @description __Clustering Columns__: You can choose to leverage column clustering when data is written to the destination tables. Set this value to a comma-separated list of columns that should be used for clustering. */
        "clustering.columns"?: string;
        mapping?: {
          mapping?: {
            [key: string]: {
              [key: string]: "SMALLINT" | "INT2" | "INTEGER" | "INT" | "INT4" | "BIGINT" | "INT8" | "DECIMAL(18,4)" | "NUMERIC(18,4)" | "REAL" | "FLOAT4" | "DOUBLE PRECISION" | "FLOAT8" | "BOOLEAN" | "BOOL" | "CHAR" | "CHARACTER" | "VARCHAR(65535)" | "CHARACTER VARYING" | "DATE" | "TIMESTAMP" | "TIMESTAMPTZ";
            };
          };
        };
      };
    });
    rest_data_sink: {
      sink_type: "rest";
    } & Omit<components["schemas"]["data_sink"], "sink_type"> & ({
      sink_config?: {
        /**
         * @description __URL__: Set the URL you wish to send data to.
         * You can use Nexla system macros like `{YYYY}`, `{MM}`, etc., and the output will be automatically converted into the corresponding time values. You can also set dynamic URLs based on the values of an attribute in the record by using the macro `{record.<attribute-name>}`.
         */
        "url.template": string;
        /**
         * @description __Method__: HTTP method used for this rest endpoint. This will usually be `POST`, `PUT`, `GET`, `PATCH`, or `DELETE`.
         *
         * @enum {string}
         */
        method: "POST" | "PUT" | "GET" | "PATCH" | "DELETE";
        /**
         * @description __Content Format__: Content format used for this rest endpoint. Usually, this will be `application/json`.
         *
         * @enum {string}
         */
        "content.type": "application/json" | "application/xml";
        /**
         * @description __Nexset Record to Payload Template__: In the case of 1 API call per Nexset record, you can customize how a Nexset record is added to the API payload. The record itself is referenced as a `{message.json}` macro.
         * Default and recommended value: `{message.json}`
         * Note:
         * 1. Usually, we recommend formatting the API payload with a Nexset transform.
         * 2. This property should not be used to format the payload when multiple Nexset records have to be batched together into 1 API call. In this case, please use the `batch.mode` and `body.transform.function` properties.
         */
        "body.template": string;
        /**
         * @description __Would you like to batch your records together?__: Select this option if you would like to combine multiple records in each API request. You can set the batching algorithm by configuring the related properties.
         * Default Value: `false`
         * __Supported__ only if `content.type` is `application/json`.
         */
        "batch.mode"?: boolean;
        /**
         * @description __Maximum Poll Records__: Set the maximum number of records that can be batched together when combining multiple records into an API call.
         * __Applicable and required__ if `batch.mode` is `true`.
         */
        "max.poll.records"?: number;
        /**
         * @description __Batching Algorithm__: You can define how the platform should combine multiple records in a single API call with a Scala function. Use `messages` to reference records within your Scala function.
         * Sample Scala Functions:
         * 1. Payload: JSON array of records:
         * `"body.transform.function": "messages"`
         * 2. Payload: JSON object containing array of records as a property (e.g., items):
         * `"body.transform.function": "Map(\"items\" -> messages)"`
         * 3. Payload: JSON object with each record modified before batching:
         * `"body.transform.function": "Map(\"items\"-> messages.map(m => {\nm.put(\"attributes\" , Map(\"type\"-> \"Account\"))\n m\n})\n)"`
         * will result in
         * `{
         *   "items:[
         *   { ...record1, "attributes": {"type": "Account"}},
         *   { ...record2, "attributes": {"type": "Account"}}
         *   ]
         * }`
         */
        "body.transform.function"?: string;
        /**
         * @description __Capture API Response__: Set this to `true` if you would like to capture the API response for each API call. Responses, along with requests, will be pushed to an autogenerated Nexla webhook.
         * Default value: `false`.
         */
        "create.datasource"?: boolean;
      };
    });
    s3_data_sink: {
      sink_type: "s3";
    } & Omit<components["schemas"]["data_sink"], "sink_type"> & components["schemas"]["file_data_sink"];
    s3_iceberg_data_sink: {
      sink_type: "s3_iceberg";
    } & Omit<components["schemas"]["data_sink"], "sink_type"> & ({
      sink_config?: {
        /**
         * @description __Warehouse Directory__: Path to the directory where you want the Iceberg table to be created/updated.
         * Nexla uses the path-based Hadoop catalog to write to tables in S3. So if you wish to write to Iceberg table `sales` in `s3://my-nexla-bucket/product/sales`, then set this property to `my-nexla-bucket/product`.
         */
        "iceberg.warehouse.dir": string;
        /**
         * @description __Table name__: Name of the table where data will be appended.
         * Nexla uses the path-based Hadoop catalog to write to tables in S3. So if you wish to write to Iceberg table `sales` in `s3://my-nexla-bucket/product/sales`, then set this property to `sales` to write to the table.
         */
        "iceberg.table.name": string;
        /**
         * @description __Update Mode__: Select the mode to insert data into the table. The default mode is `insert` which appends data to the table. The `upsert` mode will update records if they already exist in the table.
         *
         * @default upsert
         * @enum {string}
         */
        "iceberg.insert.mode"?: "insert" | "upsert";
        /** @description __ID Fields for Upserts__: Comma separated list of column names that will be used to identify records for upserts. If this field is not set, Nexla will append data to the table. */
        "iceberg.id-fields"?: string;
        /**
         * @description __Enable Change Data Capture (CDC)__: Select this option if you would like the platform to monitor database transaction logs for ingesting data.
         * Note that your DBA will need to grant necessary Change Data Capture permissions for Nexla to access transaction logs. Contact Nexla support for relevant instructions.
         * If there are limitations preventing you from enabling CDC controls on your database, you can still setup this source for incremental ingestion by disabling this option and instead selecting incremental table ingestion rules.
         *
         * @default true
         */
        "cdc.enabled"?: boolean;
        /** @description __Table name prefix__: Prefix for table name. */
        table_name_prefix?: string;
        /** @description __Table name suffix__: Suffix for table name. */
        table_name_suffix?: string;
        /** @description __Partition keys__: Comma separated list of column names to use for partitioning when creating a new table. If the table already exists we will not modify the table spec and this option will be ignored. */
        "iceberg.partition-keys"?: string;
      };
    });
    sharepoint_data_sink: {
      sink_type: "sharepoint";
    } & Omit<components["schemas"]["data_sink"], "sink_type"> & components["schemas"]["file_data_sink"];
    snowflake_data_sink: {
      sink_type: "snowflake";
    } & Omit<components["schemas"]["data_sink"], "sink_type"> & components["schemas"]["database_data_sink"] & ({
      sink_config?: {
        /** @description __Partitioning Column__: You can choose to have the data partitioned by a specific column when it is written to the destination table. Set the partitioning column if you wish to leverage that capability. */
        "partitioning.column"?: string;
        /** @description __Clustering Columns__: You can choose to leverage column clustering when data is written to the destination tables. Set this value to a comma-separated list of columns that should be used for clustering. */
        "clustering.columns"?: string;
        mapping?: {
          mapping?: {
            [key: string]: {
              [key: string]: "NUMBER" | "DECIMAL" | "NUMERIC" | "INT" | "INTEGER" | "BIGINT" | "SMALLINT" | "FLOAT" | "FLOAT4" | "FLOAT8" | "DOUBLE" | "DOUBLE PRECISION" | "REAL" | "VARCHAR" | "CHAR" | "CHARACTER" | "STRING" | "TEXT" | "BINARY" | "VARBINARY" | "BOOLEAN" | "DATE" | "DATETIME" | "TIME" | "TIMESTAMP" | "TIMESTAMP_LTZ" | "TIMESTAMP_NTZ" | "TIMESTAMP_TZ" | "VARIANT" | "OBJECT" | "ARRAY";
            };
          };
        };
      };
    });
    snowflake_dcr_data_sink: {
      sink_type: "snowflake_dcr";
    } & Omit<components["schemas"]["data_sink"], "sink_type"> & components["schemas"]["database_data_sink"] & ({
      sink_config?: {
        /** @description __Partitioning Column__: You can choose to have the data partitioned by a specific column when it is written to the destination table. Set the partitioning column if you wish to leverage that capability. */
        "partitioning.column"?: string;
        /** @description __Clustering Columns__: You can choose to leverage column clustering when data is written to the destination tables. Set this value to a comma-separated list of columns that should be used for clustering. */
        "clustering.columns"?: string;
        /** @description __Account Name for Consumer__: Set the account name for the consumer. This can be retrieved using select current-account() */
        "cleanroom.consumer.accountname": string;
        /** @description __Join Key Columns__: Select the columns on which the cleanroom queries have to be joined. */
        "cleanroom.join.keys"?: string;
        /** @description __Dimension Columns__: Select the columns to be treated as cleanroom dimension columns. */
        "cleanroom.dimensions"?: string;
        mapping?: {
          mapping?: {
            [key: string]: {
              [key: string]: "NUMBER" | "DECIMAL" | "NUMERIC" | "INT" | "INTEGER" | "BIGINT" | "SMALLINT" | "FLOAT" | "FLOAT4" | "FLOAT8" | "DOUBLE" | "DOUBLE PRECISION" | "REAL" | "VARCHAR" | "CHAR" | "CHARACTER" | "STRING" | "TEXT" | "BINARY" | "VARBINARY" | "BOOLEAN" | "DATE" | "DATETIME" | "TIME" | "TIMESTAMP" | "TIMESTAMP_LTZ" | "TIMESTAMP_NTZ" | "TIMESTAMP_TZ" | "VARIANT" | "OBJECT" | "ARRAY";
            };
          };
        };
      };
    });
    sqlserver_data_sink: {
      sink_type: "sqlserver";
    } & Omit<components["schemas"]["data_sink"], "sink_type"> & components["schemas"]["database_data_sink"] & ({
      sink_config?: {
        mapping?: {
          mapping?: {
            [key: string]: {
              [key: string]: "BIGINT" | "INT" | "SMALLINT" | "TINYINT" | "BIT" | "NUMERIC" | "MONEY" | "SMALLMONEY" | "REAL" | "DATETIME" | "SMALLDATETIME" | "CHAR(3000)" | "VARCHAR(100)" | "VARCHAR(3000)" | "VARCHAR(max)" | "TEXT" | "NCHAR" | "NVARCHAR" | "NTEXT" | "BINARY" | "VARBINARY" | "TABLE" | "UNIQUEIDENTIFIER" | "DECIMAL(18, 4)" | "FLOAT(12)";
            };
          };
        };
      };
    });
    teradata_data_sink: {
      sink_type: "teradata";
    } & Omit<components["schemas"]["data_sink"], "sink_type"> & components["schemas"]["database_data_sink"] & ({
      sink_config?: {
        mapping?: {
          mapping?: {
            [key: string]: {
              [key: string]: "BYTEINT" | "SMALLINT" | "INTEGER" | "BIGINT" | "FLOAT" | "DOUBLE PRECISION" | "VARCHAR" | "VARBYTE(64000)" | "DATE" | "TIME" | "TIMESTAMP";
            };
          };
        };
      };
    });
    tibco_data_sink: {
      sink_type: "tibco";
    } & Omit<components["schemas"]["data_sink"], "sink_type"> & components["schemas"]["stream_data_sink"] & ({
      sink_config?: {
        /**
         * @description Select whether this destination is a topic or a queue.
         *
         * @enum {string}
         */
        "target.type": "topic" | "queue";
        /** @description __Topic / Queue Name  __: Configure the name of the topic/queue where data should be written. */
        "target.name": string;
        /**
         * @description __Data Format__: Select the data format parser for the data to be written to this topic or queue. This is usually `json`.
         *
         * @enum {string}
         */
        "writer.type": "csv" | "tsv" | "txt" | "xml" | "json";
      };
    });
    DataMap: {
      /** Format: int32 */
      id?: number;
      name?: string;
      description?: string;
      public?: boolean;
      managed?: boolean;
      /** @example string */
      data_type?: string;
      /** Format: nullable */
      data_format?: string;
      /** Format: nullable */
      data_sink_id?: string;
      emit_data_default?: boolean;
      use_versioning?: boolean;
      /** @example id */
      map_primary_key?: string;
      data_defaults?: Record<string, never>;
      /**
       * Format: date-time
       * @example 2021-07-26T21:29:58.000Z
       */
      updated_at?: string;
      /**
       * Format: date-time
       * @example 2021-07-26T21:29:58.000Z
       */
      created_at?: string;
      owner?: {
        /** Format: int32 */
        id?: number;
        full_name?: string;
        /** Format: email */
        email?: string;
      };
      org?: components["schemas"]["OrgSimplified"];
      access_roles?: components["schemas"]["AccessRoles"];
      /** Format: nullable */
      data_set_id?: number;
      /**
       * Format: int32
       * @example 200
       */
      map_entry_count?: number;
      map_entry_schema?: Record<string, never>;
      tags?: string[];
    };
    DataMapBase: {
      name?: string;
      description?: string;
      /**
       * @description Key name which should be used as the primary key for looking up rows in this data map.
       *
       * @example id
       */
      map_primary_key?: string;
      /** @description The default values to use for any key if the key is not present in the corresponding row. */
      data_defaults?: {
        [key: string]: string | number;
      };
      /** @description This property defines whether a lookup query should return values with applicable default values for missing properties in the row. */
      emit_data_default?: boolean;
      tags?: string[];
    };
    DataMapCreate: components["schemas"]["DataMapBase"] & Record<string, never> & ({
      /**
       * @description Enter an array of data map entries if you wish to seed this data map with some rows of data while creating the data map.
       *
       * You can also update data map rows by calling the endpoint for updating entries.
       */
      data_map?: ({
          [key: string]: string | number;
        })[];
    });
    DataMapMutable: components["schemas"]["DataMapBase"];
    /** @enum {string} */
    ResourceType: "transform";
    DataCredentialBrief: {
      id?: number;
      name?: string;
      description?: string;
      /** Format: date-time */
      updated_at?: string;
      /** Format: date-time */
      created_at?: string;
    };
    /** @enum {string} */
    CodeType: "jolt_standard" | "jolt_custom";
    /** @enum {string} */
    OutputType: "record";
    Transform: {
      /**
       * Format: int32
       * @example 1
       */
      id?: number;
      /** @example test */
      name?: string;
      resource_type?: components["schemas"]["ResourceType"];
      reusable?: boolean;
      owner?: components["schemas"]["UserSimplified"];
      org?: components["schemas"]["OrgSimplified"];
      access_roles?: components["schemas"]["AccessRoles"];
      data_credentials?: components["schemas"]["DataCredentialBrief"];
      runtime_data_credentials?: components["schemas"]["DataCredentialBrief"];
      /** @example test */
      description?: string;
      code_type?: components["schemas"]["CodeType"];
      output_type?: components["schemas"]["OutputType"];
      code_config?: Record<string, never>;
      /** Format: nullable */
      custom_config?: Record<string, never>;
      /** @example none */
      code_encoding?: string;
      code?: Record<string, never>[];
      managed?: boolean;
      data_sets?: number[];
      /** Format: nullable */
      copied_from_id?: number;
      /** Format: date-time */
      updated_at?: string;
      /** Format: date-time */
      created_at?: string;
      tags?: string[];
    };
    TransformMutable: {
      name: string;
      description?: string;
      /**
       * @description Type of code container. This must be set to `record` to signify that this code container is to be used to convert an input record of a Nexset into an output record for that Nexset.
       *
       * @enum {string}
       */
      output_type: "record";
      /** @description Whether or not this transform can be referenced by multiple Nexsets. This should always be `true` for reusable record transforms. */
      reusable: boolean;
      /**
       * @description Type of code in the `code` block. Use `jolt_custom` if the code in the code block is a `python`, `python3` or `javascript` transform code block wrapped inside a Jolt operation block.
       * @enum {string}
       */
      code_type: "jolt_custom" | "jolt_standard";
      /**
       * @description Whether or not the code in the `code` block is encoded. Set this to `none` for reusable record transforms.
       *
       * @enum {string}
       */
      code_encoding: "none";
      /**
       * @description Code to be executed for transforming records.
       * If you wish to execute a Python or Javascript code snippet during transformation, you'll need to `base64`-encode that code snippet and wrap it inside the following Jolt operation object.
       *
       * For example, if you want to execute this Python code as a reusable record transform
       * ```python
       * def transform(input, metadata, args):
       *   # Sample python transform to pass all attributes through
       * return input
       * ```
       * the corresponding `code` object would be
       * ```json
       * [
       *   {
       *     "operation": "nexla.custom",
       *     "spec": {
       *       "language": "python",
       *       "encoding": "base64",
       *       "script": "ZGVmIHRyYW5zZm9ybShpbnB1dCwgbWV0YWRhdGEsIGFyZ3MpOgogICMgU2FtcGxlIHB5dGhvbiB0cmFuc2Zvcm0gdG8gcGFzcyBhbGwgYXR0cmlidXRlcyB0aHJvdWdoCiAgcmV0dXJuIGlucHV0"
       *     }
       *   }
       * ]
       * ```
       */
      code: OneOf<[({
          /**
           * @description Jolt operation for this code block. For `python`, `python3` and `javascript`, it must be `nexla.custom`.
           *
           * @enum {string}
           */
          operation?: "nexla.custom";
          /** @description Jolt specification for this block. See the Python example above for sample specs. */
          spec?: {
            /**
             * @description Code language of the encoded script.
             *
             * @enum {string}
             */
            language?: "python" | "python3" | "javascript";
            /**
             * @description Python or Javascript code snippets must always be Base64-encoded.
             *
             * @enum {string}
             */
            encoding?: "base64";
            /** @description Base64-encoded Python or Javascript code snippet that must be executed for transforming records. */
            script?: string;
          };
        })[], {
          [key: string]: Record<string, never>;
        }[]]>;
      /**
       * @description Configuration block useful for converting code into Nexla UI's Nexset Designer Rule blocks.
       *
       * This should not be sent in the payload unless the transform is being created using the Nexla UI's Nexset Designer screen.
       */
      custom_config?: Record<string, never>;
      tags?: string[];
    };
    /**
     * @description The type of resource that this code container is to be used for.
     * - `transform`: For user defined code that is used in a Nexset transform.
     * - `ai_function`: For user defined code that is used in an AI function. See `ai_function_type` for the scenarios where this is used.
     * - `source`: For user defined code in a source.
     * - `sink`: For user defined code in a sink.
     * - `error`: For user defined code that acts as an error handler.
     * - `validator`: For user defined code that acts as a validator.
     *
     * @enum {string}
     */
    code_containers_ResourceType: "transform" | "ai_function" | "source" | "sink" | "error" | "validator";
    /**
     * @description The type of output that this code container produces.
     *
     * - `record`: Produces a full Nexset record. Used only when the code container is used to modify a Nexset, i.e output_type: `transform`
     * - `attribute`: Produces value for an attribute inside a Nexset record. Used only when the code container is used to modify a value inside a Nexset, i.e output_type: `transform`
     * - `custom`: Produces custom output. Used as a catch-all output format when a code container is used in any context other than for Nexset modification.
     *
     * @enum {string}
     */
    code_containers_OutputType: "record" | "attribute" | "custom";
    /** @enum {string} */
    code_containers_CodeType: "jolt_standard" | "jolt_custom" | "python" | "python3" | "javascript";
    CodeContainerMutable: {
      /** @example test */
      name: string;
      /** @example test */
      description?: string;
      /**
       * Format: nullable
       * @description Credential ID for accessing the code repository (e.g., Github). This is for code containers in which the code is saved in a remote repository.
       *
       * Note that this is not required for script connectors in which the script is hosted in a Nexla Github repository.
       */
      data_credentials_id?: number;
      resource_type?: components["schemas"]["code_containers_ResourceType"];
      /**
       * @description The type of AI function that this code container is used for.
       * - `chunker`:  Used to chunk parsed file content into smaller chunks in a Document Ingestion flow.
       * - `context_enricher`: Used to enrich the context of a query in a RAG flow.
       * - `query_rewriter`: Used to rewrite a query in a RAG flow.
       * - `reranker`: Used to rerank a list of results in a RAG flow.
       *
       * @enum {string}
       */
      ai_function_type?: "chunker" | "context_enricher" | "query_rewriter" | "reranker";
      output_type: components["schemas"]["code_containers_OutputType"];
      code_type: components["schemas"]["code_containers_CodeType"];
      /**
       * @description Whether or not the code in the `code` block is encoded. Set this to `none` for reusable record transforms.
       *
       * @enum {string}
       */
      code_encoding: "none" | "base64";
      /**
       * @description Code to be executed in this code container.
       *
       * Please refer to the endpoints for `transforms`, `attribute_transforms` and `validators` for respective `code` block requirements.
       */
      code: OneOf<[string, {
          /** @example nexla.custom */
          operation?: string;
          spec?: {
            /** @example python */
            language?: string;
            /** @example base64 */
            encoding?: string;
            script?: string;
          };
        }[]]>;
      /** @description Whether or not this transform can be referenced by multiple resources. This should always be `true` for reusable record and attribute transforms. */
      reusable: boolean;
      tags?: string[];
      custom_config?: Record<string, never>;
    };
    CodeContainer: {
      /**
       * Format: int32
       * @example 1
       */
      id?: number;
      /** @example test */
      name?: string;
      resource_type?: components["schemas"]["code_containers_ResourceType"];
      /**
       * @description The type of AI function that this code container is used for.
       * - `chunker`:  Used to chunk parsed file content into smaller chunks in a Document Ingestion flow.
       * - `context_enricher`: Used to enrich the context of a query in a RAG flow.
       * - `query_rewriter`: Used to rewrite a query in a RAG flow.
       * - `reranker`: Used to rerank a list of results in a RAG flow.
       *
       * @enum {string}
       */
      ai_function_type?: "chunker" | "context_enricher" | "query_rewriter" | "reranker";
      reusable?: boolean;
      public?: boolean;
      owner?: components["schemas"]["UserSimplified"];
      org?: components["schemas"]["OrgSimplified"];
      access_roles?: components["schemas"]["AccessRoles"];
      data_credentials?: components["schemas"]["DataCredentialBrief"];
      runtime_data_credentials?: components["schemas"]["DataCredentialBrief"];
      /** @example test */
      description?: string;
      code_type?: components["schemas"]["code_containers_CodeType"];
      output_type?: components["schemas"]["code_containers_OutputType"];
      code_config?: Record<string, never>;
      /** Format: nullable */
      custom_config?: Record<string, never>;
      /** @example none */
      code_encoding?: string;
      code?: {
          /** @example nexla.custom */
          operation?: string;
          spec?: {
            /** @example python */
            language?: string;
            /** @example base64 */
            encoding?: string;
            /** @example ZGVmIHRyYW5zZm9ybShpbnB1dCwgbWV0YWRhdGEsIGFyZ3MpOgogICMgU2FtcGxlIHB5dGhvbiB0cmFuc2Zvcm0gdG8gcGFzcyBhbGwgYXR0cmlidXRlcyB0aHJvdWdoCiAgcmV0dXJuIGlucHV0 */
            script?: string;
          };
        }[];
      managed?: boolean;
      data_sets?: number[];
      /** Format: nullable */
      copied_from_id?: number;
      /**
       * Format: date-time
       * @example 2023-01-24T03:26:43.000Z
       */
      updated_at?: string;
      /**
       * Format: date-time
       * @example 2023-01-24T03:26:43.000Z
       */
      created_at?: string;
      tags?: string[];
    };
    /** @enum {string} */
    attribute_transforms_CodeType: "python" | "javascript";
    /** @enum {string} */
    attribute_transforms_OutputType: "attribute";
    AttributeTransform: {
      /**
       * Format: int32
       * @example 1
       */
      id?: number;
      /** @example test */
      name?: string;
      resource_type?: components["schemas"]["ResourceType"];
      reusable?: boolean;
      owner?: components["schemas"]["UserSimplified"];
      org?: components["schemas"]["OrgSimplified"];
      access_roles?: components["schemas"]["AccessRoles"];
      data_credentials?: components["schemas"]["DataCredentialBrief"];
      runtime_data_credentials?: components["schemas"]["DataCredentialBrief"];
      /** @example test */
      description?: string;
      code_type?: components["schemas"]["attribute_transforms_CodeType"];
      output_type?: components["schemas"]["attribute_transforms_OutputType"];
      code_config?: Record<string, never>;
      /** Format: nullable */
      custom_config?: Record<string, never>;
      /** @example none */
      code_encoding?: string;
      code?: string;
      managed?: boolean;
      data_sets?: number[];
      /** Format: nullable */
      copied_from_id?: number;
      /** Format: date-time */
      updated_at?: string;
      /** Format: date-time */
      created_at?: string;
      tags?: string[];
    };
    AttributeTransformMutable: {
      name: string;
      description?: string;
      /**
       * @description Type of code container. This must be set to `attribute` to signify that this code container is to be used for generating the value of an output attribute.
       *
       * @enum {string}
       */
      output_type: "attribute";
      /** @description Whether or not this transform can be referenced by multiple Nexsets. This should always be `true` for reusable transforms. */
      reusable: boolean;
      /**
       * @description Type of code in the code block.
       * @enum {string}
       */
      code_type: "python" | "python3" | "javascript";
      /**
       * @description Whether or not the code in the `code` block is encoded. Set this to `base64` for reusable attribute transforms.
       *
       * @enum {string}
       */
      code_encoding: "base64";
      /**
       * @description Code to be executed for transforming records.
       * If you wish to execute a Python or Javascript code snippet during transformation, you'll need to `base64`-encode that code snippet.
       *
       * For example, if you want to execute this Python code as a reusable record transform
       * ```python
       * def transformAttribute(input, metadata, args):
       *   return input.get(args[0])
       * ```
       * the corresponding `code` value would be
       * ```
       * ZGVmIHRyYW5zZm9ybUF0dHJpYnV0ZShpbnB1dCwgbWV0YWRhdGEsIGFyZ3MpOgogIHJldHVybiBpbnB1dC5nZXQoYXJnc1swXSk=
       * ```
       */
      code: string;
      /**
       * @description Configuration block useful for converting code into Nexla UI's Nexset Designer Rule blocks.
       *
       * This should not be sent in the payload unless the transform is being created using the Nexla UI's Nexset Designer screen.
       */
      custom_config?: Record<string, never>;
      tags?: string[];
    };
    ProjectDataFlow: {
      /** @description Unique identifier of this flow. */
      id?: number;
      /** @description Unique identifier of the project this flow belongs to. */
      project_id?: number;
      /**
       * Format: nullable
       * @description The ID of the data source which is the root node of this flow chain.
       *
       * Unless the flow chain has been created from a shared Nexset, flow definitions start from the source as the root node. This property reflects the source that is the root node of this flow.
       */
      data_source_id?: number;
      /**
       * Format: nullable
       * @description The ID of the Nexset which is the root node of this flow chain.
       *
       * This property is not null only if the flow was created from a shared Nexset. In that case, this value reflects the ID of the derived dataset created from the shared Nexset.
       */
      data_set_id?: number;
      /** @example 2023-01-31T01:39:54.000Z */
      updated_at?: string;
      /** @example 2023-01-31T01:39:54.000Z */
      created_at?: string;
    };
    Project: {
      /**
       * Format: int32
       * @description Unique identifier of this project.
       */
      id?: number;
      owner?: {
        /** Format: int32 */
        id?: number;
        /** @example John Johnson */
        full_name?: string;
        /** @example example@nexla.com */
        email?: string;
      };
      org?: {
        /** Format: int32 */
        id?: number;
        /** @example Nexla */
        name?: string;
        /** @example nexla.com */
        email_domain?: string;
        /** Format: nullable */
        client_identifier?: string;
      };
      /** @example test project */
      name?: string;
      /** @example it's a test project */
      description?: string;
      /**
       * @description List of all flows that are part of this project.
       *
       * > Note: This is a deprecated format of representing flows. We recommend using the `flows` entry in this object.
       */
      data_flows?: components["schemas"]["ProjectDataFlow"][];
      /**
       * @description List of all flows that are part of this project.
       *
       * > Note: This is a new recommended format of representing flows. We recommend using this format which uses unique flow ids instead of the `data_flows` object.
       */
      flows?: components["schemas"]["ProjectDataFlow"][];
      access_roles?: components["schemas"]["AccessRoles"];
      tags?: string[];
      /** Format: nullable */
      copied_from_id?: string;
      /**
       * Format: date-time
       * @example 2023-01-31T01:39:54.000Z
       */
      updated_at?: string;
      /**
       * Format: date-time
       * @example 2023-01-31T01:39:54.000Z
       */
      created_at?: string;
    };
    ProjectFlowIdentifier: {
      /**
       * @description The ID of the data source which is the root node of this flow chain.
       *
       * Unless the flow chain has been created from a shared Nexset, flow definitions start from the source as the root node. This property reflects the source that is the root node of this flow.
       */
      data_source_id?: number;
    } | {
      /**
       * @description The ID of the Nexset which is the root node of this flow chain.
       *
       * This property is not null only if the flow was created from a shared Nexset. In that case, this value reflects the ID of the derived dataset created from the shared Nexset.
       */
      data_set_id?: number;
    };
    ProjectFlowList: {
      data_flows?: components["schemas"]["ProjectFlowIdentifier"][];
    };
    ProjectMutable: {
      /** @example test project */
      name?: string;
      /** @example it's a test project */
      description?: string;
    } & components["schemas"]["ProjectFlowList"];
    ProjectCreate: components["schemas"]["ProjectMutable"];
    ProjectFlowListFlowNodes: {
      flows?: number[];
    };
    CustodiansPayload: {
        id?: number;
        email?: string;
      }[];
    OrgsUpdate: {
      name?: string;
      owner_id?: number;
      billing_owner_id?: number;
      email_domain?: string;
      /**
       * @description Recommended but not required. This is a unique identifier for the organization in the environment. This identifier is especially useful for organizations that are using SSO.
       *
       * Recommendation: Use the organization's domain name. Apply variants if a company needs more than one organization account in the environment.
       */
      client_identifier?: string;
      /**
       * @description Set to `false` if an organization requires no user to be allowed username-password-based access. Applicable for organizations who use GSuite email or have SSO enabled.
       *
       * Default value: `true`
       */
      enable_nexla_password_login?: boolean;
      custodians?: components["schemas"]["CustodiansPayload"];
    };
    /**
     * @description Indicates whether the user's membership in this organization is active or not.
     *
     * If the membership is DEACTIVATED the user can no longer access the account but the resources owned by them will still be accessible by the organization administrators.
     *
     * @enum {string}
     */
    OrgMembershipStatus: "ACTIVE" | "DEACTIVATED";
    /**
     * @description Indicates the user's account status across all organizations they are members of.
     *
     * @enum {string}
     */
    UserStatus: "ACTIVE" | "DEACTIVATED" | "SOURCE_COUNT_CAPPED" | "SOURCE_DATA_CAPPED" | "TRIAL_EXPIRED";
    OrgMember: {
      /** @description Nexla User ID of this user. */
      id?: number;
      full_name?: string;
      email?: string;
      /** @description Indicates whether this user is an administrator for the organization or not. */
      "is_admin?"?: boolean;
      access_role?: components["schemas"]["AccessRoles"];
      org_membership_status?: components["schemas"]["OrgMembershipStatus"];
      user_status?: components["schemas"]["UserStatus"];
    };
    OrgMemberMutable: OneOf<[{
      /** @description Nexla User ID of the user to be added or updated. */
      id: number;
      access_role?: components["schemas"]["AccessRoles"];
    }, {
      /** @description Email ID of the user to be added or updated. If a user with this Email ID already exists on the platform then the API will update that account with this membership rule. */
      email: string;
      access_role?: components["schemas"]["AccessRoles"];
    }]>;
    OrgMemberList: {
      members?: components["schemas"]["OrgMemberMutable"][];
    };
    OrgMemberDelete: {
      members?: OneOf<[{
          /** @description Nexla User ID of the user who should be removed. */
          id: number;
        }, {
          /** @description Email ID of the user who should be removed. */
          email: string;
        }]>[];
    };
    TeamMemberResponseSchema: {
      /** @description Unique ID of the user. */
      id?: number;
      /**
       * Format: email
       * @description Email ID of the user.
       */
      email?: string;
      /** @description Reflects whether the user is an administrator of this team or not. */
      admin?: boolean;
    };
    Team: {
      id?: number;
      name?: string;
      description?: string;
      owner?: components["schemas"]["UserSimplified"];
      org?: components["schemas"]["OrgSimplified"];
      member?: boolean;
      members?: components["schemas"]["TeamMemberResponseSchema"][];
      access_roles?: components["schemas"]["AccessRoles"];
      /** Format: date-time */
      updated_at?: string;
      /** Format: date-time */
      created_at?: string;
      tags?: string[];
    };
    TeamMemberRequestSchema: OneOf<[{
      /** @description Unique ID of the user. */
      id?: number;
      /** @description Reflects whether the user is an administrator of this team or not. */
      admin?: boolean;
    }, {
      /**
       * Format: email
       * @description Email ID of the user.
       */
      email?: string;
      /** @description Reflects whether the user is an administrator of this team or not. */
      admin?: boolean;
    }]>;
    TeamMutable: {
      name?: string;
      description?: string;
      members?: components["schemas"]["TeamMemberRequestSchema"][];
    };
    TeamCreate: components["schemas"]["TeamMutable"] & Record<string, never>;
    TeamMemberList: {
      members?: components["schemas"]["TeamMemberResponseSchema"][];
    };
    /**
     * @description Indicates whether a user is on a paid, free, or trial account. Used to determine limits on records processed by the account.
     *
     * @enum {string}
     */
    UserTier: "FREE" | "TRIAL" | "PAID" | "FREE_FOREVER";
    OrgMembership: {
      /** Format: int32 */
      id?: number;
      name?: string;
      "is_admin?"?: boolean;
      org_membership_status?: components["schemas"]["OrgMembershipStatus"];
    };
    User: {
      id?: number;
      /** Format: email */
      email?: string;
      full_name?: string;
      super_user?: boolean;
      impersonated?: boolean;
      default_org?: {
        id?: number;
        name?: string;
      };
      user_tier?: components["schemas"]["UserTier"];
      status?: components["schemas"]["UserStatus"];
      account_locked?: boolean;
      org_memberships?: components["schemas"]["OrgMembership"][];
      /** Format: date-time */
      email_verified_at?: string;
      /** Format: date-time */
      tos_signed_at?: string;
      /** Format: date-time */
      updated_at?: string;
      /** Format: date-time */
      created_at?: string;
    };
    UserAdmin: OneOf<["*", boolean, {
        admin?: boolean;
        org_id?: number;
      }[]]>;
    UsersCreateRequired: {
      full_name: string;
      email: string;
      default_org_id?: number;
      status?: components["schemas"]["UserStatus"];
      user_tier_id?: number;
      user_tier?: string;
      password?: string;
      /** Format: date-time */
      tos_signed_at?: string;
      admin?: components["schemas"]["UserAdmin"];
    };
    AccountSummary: {
      data_sources?: {
        counts?: {
          /** Format: int32 */
          total?: number;
          /** Format: int32 */
          owner?: number;
          /** Format: int32 */
          collaborator?: number;
          /** Format: int32 */
          active?: number;
          /** Format: int32 */
          paused?: number;
          /** Format: int32 */
          draft?: number;
        };
      };
      data_sets?: {
        counts?: {
          /** Format: int32 */
          total?: number;
          /** Format: int32 */
          owner?: number;
          /** Format: int32 */
          collaborator?: number;
          /** Format: int32 */
          active?: number;
          /** Format: int32 */
          paused?: number;
          /** Format: int32 */
          draft?: number;
        };
      };
      data_sinks?: {
        counts?: {
          /** Format: int32 */
          total?: number;
          /** Format: int32 */
          owner?: number;
          /** Format: int32 */
          collaborator?: number;
          /** Format: int32 */
          active?: number;
          /** Format: int32 */
          paused?: number;
          /** Format: int32 */
          draft?: number;
        };
      };
      data_maps?: {
        counts?: {
          /** Format: int32 */
          total?: number;
          /** Format: int32 */
          owner?: number;
          /** Format: int32 */
          collaborator?: number;
        };
      };
    };
    UserExpanded: components["schemas"]["User"] & {
      account_summary?: components["schemas"]["AccountSummary"];
    };
    UsersUpdate: {
      name?: string;
      email?: string;
      status?: components["schemas"]["UserStatus"];
      user_tier_id?: number;
      user_tier?: string;
      password?: string;
      password_confirmation?: string;
      password_current?: string;
      /** Format: date-time */
      tos_signed_at?: string;
      admin?: components["schemas"]["UserAdmin"];
    };
    UserTransferable: {
      /** Format: nullable */
      catalog_configs?: number[];
      /** Format: nullable */
      code_containers?: number[];
      /** Format: nullable */
      code_filters?: number[];
      /** Format: nullable */
      custom_data_flows?: number[];
      /** Format: nullable */
      dashboard_transforms?: number[];
      /** Format: nullable */
      data_credentials?: number[];
      /** Format: nullable */
      data_maps?: number[];
      /** Format: nullable */
      data_schemas?: number[];
      /** Format: nullable */
      data_sets?: number[];
      /** Format: nullable */
      data_sets_api_keys?: number[];
      /** Format: nullable */
      data_sinks?: number[];
      /** Format: nullable */
      data_sinks_api_keys?: number[];
      /** Format: nullable */
      data_sources?: number[];
      /** Format: nullable */
      data_sources_api_keys?: number[];
      /** Format: nullable */
      doc_containers?: number[];
      /** Format: nullable */
      org_idp_mappings?: number[];
      /** Format: nullable */
      projects?: number[];
      /** Format: nullable */
      teams?: number[];
      /** Format: nullable */
      users_api_keys?: number[];
    };
    UserTransferred: components["schemas"]["UserTransferable"] & {
      transfer_user_resources?: {
        previous_owner_id?: number;
        new_owner_id?: number;
        org_id?: number;
      };
    };
    UserSettings: {
      id?: string;
      owner?: {
        id?: number;
        full_name?: string;
        email?: string;
        email_verified_at?: string;
      };
      org?: components["schemas"]["OrgSimplified"];
      user_settings_type?: string;
      settings?: Record<string, never>;
    };
    Notification: {
      id?: number;
      owner?: components["schemas"]["UserSimplified"];
      org?: components["schemas"]["OrgSimplified"];
      access_roles?: components["schemas"]["AccessRoles"];
      level?: string;
      resource_id?: number;
      resource_type?: string;
      message_id?: number;
      message?: string;
      /** Format: date-time */
      read_at?: string;
      /** Format: date-time */
      updated_at?: string;
      /** Format: date-time */
      created_at?: string;
    };
    async_or_null: components["schemas"]["AsyncResponse"] | null;
    /** @enum {string} */
    NotificationTypeCategory: "PLATFORM" | "SYSTEM" | "DATA";
    /** @enum {string} */
    NotificationEventType: "SHARE" | "CREATE" | "DELETE" | "UPDATE" | "ACTIVATE" | "PAUSE" | "METRICS" | "RESETPASS" | "ERROR_AGGREGATED" | "ERROR" | "MONITOR" | "WRITE" | "EMPTY_DATA" | "READ_START" | "READ_DONE" | "WRITE_START" | "WRITE_DONE";
    /** @enum {string} */
    NotificationResourceType: "ORG" | "USER" | "DATA_FLOW" | "CUSTOM_DATA_FLOW" | "SOURCE" | "DATASET" | "SINK";
    NotificationType: {
      id?: number;
      name?: string;
      description?: string;
      category?: components["schemas"]["NotificationTypeCategory"];
      default?: boolean;
      status?: boolean;
      event_type?: components["schemas"]["NotificationEventType"];
      resource_type?: components["schemas"]["NotificationResourceType"];
    };
    /** @enum {string} */
    NotificationChannel: "APP" | "EMAIL" | "SMS" | "SLACK" | "WEBHOOKS";
    NotificationChannelSetting: {
      id?: number;
      owner_id?: number;
      org_id?: number;
      channel?: components["schemas"]["NotificationChannel"];
      config?: {
        [key: string]: string;
      };
    };
    NotificationChannelSettingUpdate: {
      channel?: components["schemas"]["NotificationChannel"];
      config?: {
        [key: string]: string;
      };
    };
    NotificationChannelSettingCreateRequired: components["schemas"]["NotificationChannelSettingUpdate"] & Record<string, never>;
    /**
     * @description Whether or not the user should be notified about this event for this resource on the selected channel.
     *
     * @enum {string}
     */
    NotificationSettingStatus: "PAUSED" | "ACTIVE";
    NotificationSetting: {
      id?: number;
      org_id?: number;
      owner_id?: number;
      channel?: components["schemas"]["NotificationChannel"];
      notification_resource_type?: components["schemas"]["NotificationResourceType"];
      resource_id?: number;
      config?: Record<string, never>;
      priority?: number;
      status?: components["schemas"]["NotificationSettingStatus"];
      notification_type_id?: number;
      name?: string;
      description?: string;
      code?: number;
      category?: string;
      event_type?: components["schemas"]["NotificationEventType"];
      resource_type?: components["schemas"]["NotificationResourceType"];
    };
    NotificationSettingUpdate: {
      channel?: components["schemas"]["NotificationChannel"];
      status?: components["schemas"]["NotificationSettingStatus"];
      /** @description Configuration properties for customizing the criteria for firing the event. */
      config?: {
        [key: string]: string;
      };
      notification_resource_type?: components["schemas"]["NotificationResourceType"];
      resource_id?: number;
      checked?: boolean;
      notification_channel_setting_id?: number;
      notification_type_id?: number;
    };
    NotificationSettingCreateRequired: components["schemas"]["NotificationSettingUpdate"] & Record<string, never>;
    /** @enum {string} */
    NotificationSettingResourceStatus: "INIT" | "PAUSED" | "ACTIVE" | "RATE_LIMITED";
    NotificationSettingTypeView: {
      /** Format: int32 */
      setting_id?: number;
      /** Format: int32 */
      org_id?: number;
      /** Format: int32 */
      owner_id?: number;
      channel?: components["schemas"]["NotificationChannel"];
      resource_type?: components["schemas"]["NotificationResourceType"];
      /** Format: int32 */
      resource_id?: number;
      /** Format: nullable */
      setting_config?: string;
      /** Format: int32 */
      priority?: number;
      status?: components["schemas"]["NotificationSettingStatus"];
      /** Format: int32 */
      notification_type_id?: number;
      setting_created_at?: string;
      setting_updated_at?: string;
      notification_type_name?: string;
      notification_type_description?: string;
      /** Format: int32 */
      notification_type_code?: number;
      notification_type_category?: string;
      notification_type_event_type?: components["schemas"]["NotificationEventType"];
      /** Format: int32 */
      resource_owner_id?: number;
      /** Format: int32 */
      resource_org_id?: number;
      resource_name?: string;
      resource_description?: string;
      resource_status?: components["schemas"]["NotificationSettingResourceStatus"];
    };
    DashboardMetricSet: {
      /**
       * Format: int32
       * @description The total number of records that were processed for this resource during the past 24 hours.
       */
      records?: number;
      /**
       * Format: int32
       * @description The total volume (in bytes) of records that were processed for this resource during the past 24 hours.
       */
      size?: number;
      /**
       * Format: int32
       * @description The total number of data processing errors that occurred on this resource during the past 24 hours.
       */
      errors?: number;
      /**
       * @description Indicates whether the platform identified this resource's performance during the last 24 hours as something that might require attention or not.
       *
       * @enum {string}
       */
      status?: "OK" | "WARNING" | "ERROR";
    };
    ResourceMetricDaily: {
      /**
       * Format: date
       * @description The date (in UTC) that the metrics in this entry are applicable for.
       */
      time?: string;
      /**
       * Format: int32
       * @description The total number of records that were processed on the date indicated by the `time` property.
       */
      records?: number;
      /**
       * Format: int32
       * @description The total volume (in bytes) of records that were processed on the date indicated by the `time` property.
       */
      size?: number;
      /**
       * Format: int32
       * @description The total number of data processing errors that occurred on the date indicated by the `time` property.
       */
      errors?: number;
    };
    ResourceMetricByRun: {
      /** @description The run ID / ingestion cycle the the metrics in this entry are applicable for. */
      runId?: number;
      /**
       * @description The destination write batch id the the metrics in this entry are applicable for.
       *
       * > *Note*: This entry is present and applicable only if the request was made for a destination *and* the request was for grouping by `lastWritten` instead of `runId`
       */
      lastWritten?: number;
      /** @description The Nexset ID these records were applicable for. For a data source, this indicates the nexset that received the records these metrics correspond to. For a data sink, this indicates the nexset that had the records these metrics correspond to. */
      dataSetId?: number;
      /**
       * Format: int32
       * @description The total number of records that were processed during the ingestion cycle indicated by `runId`
       */
      records?: number;
      /**
       * Format: int32
       * @description The total volume (in bytes) of records that processed during the ingestion cycle indicated by `runId`
       */
      size?: number;
      /**
       * Format: int32
       * @description The total number of data processing errors that occurred during the ingestion cycle indicated by `runId`
       */
      errors?: number;
    };
    FlowResourceMetric: {
      id?: number;
      metric?: {
        records?: number;
        size?: number;
        errors?: number;
      };
    };
    FlowLogEntry: {
      /**
       * Format: unix epoch in milliseconds
       * @description Timestamp at which this log entry was generated.
       *
       * @example 1695442864636
       */
      timestamp?: number;
      /** @description The ID of the resource that generated this log entry. */
      resource_id?: number;
      /**
       * @description The type of flow resource that generated this log entry.
       *
       * @enum {string}
       */
      resource_type?: "SOURCE" | "DATASET" | "SINK";
      /**
       * @description Detailed information about the data processing events on the flow resource.
       *
       * @example Processed records=100, errors=0, size=94162"
       */
      log?: string;
      /**
       * @description Indicates the type of event reflected by log entry.
       *
       * * `SUMMARY`: Log entry describing high level summary of data processing event.
       * * `LOG`: Log entry describing details of data processing status.
       *
       * @enum {string}
       */
      log_type?: "LOG" | "SUMMARY";
      /**
       * @description Indicates the severity of the event reflected by this log entry.
       *
       * @enum {string}
       */
      severity?: "INFO" | "WARNING" | "ERROR";
    };
    LogEntry: {
      /**
       * Format: int32
       * @description Unique ID of this change event.
       */
      id?: number;
      /**
       * @description The type of resource that the change was performed on.
       *
       * @example DataSource
       */
      item_type?: string;
      /**
       * Format: int32
       * @description Unique ID of resource that the change was performed on.
       */
      item_id?: number;
      /**
       * @description The type of change event that was executed.
       *
       * @example association_added
       */
      event?: string;
      change_summary?: string[];
      /**
       * @description This object contains before and after information on each property that was modified as a result of this change event.
       *
       * Each key in this object is the name of the property that was modified. The value of each property is a 2-element array. The first element shows the value of the property before the change event was executed and the second element shows the value of this property after the change event was executed.
       *
       * For example, the values below should be interpreted as resource `status` was changed from `ACTIVE` to `PAUSED` and resource `name` was changed from `before` to `after`.
       *
       * ```
       *  {
       *    "status": ["ACTIVE", "PAUSED"],
       *    "name": ["before", "after"]
       *
       *  }
       *
       * ```
       */
      object_changes?: {
        [key: string]: (string | number | boolean | Record<string, never> | unknown[] | null)[];
      };
      /**
       * Format: nullable
       * @description Sometimes change events result in updates to relationships between resources. This object reflects information about the resource relationship that was modified.
       */
      association_resource?: {
        /** @description The resource type of the resource whose relationship with this resource was modified. */
        type?: string;
        /**
         * Format: int32
         * @description The ID of the resource whose relationship with this resource was modified.
         */
        id?: number;
      };
      /**
       * Format: ipv4
       * @description IP Address of the device where this change event request originated.
       *
       * @example 1.2.3.4
       */
      request_ip?: string;
      /** @description User Agent of the browser where this change event request originated. */
      request_user_agent?: string;
      /**
       * Format: url
       * @description Nexla UI or API URL that was accessed by the user to trigger this change event.
       */
      request_url?: string;
      /** @description Details about the user who triggered this change event. Note that if changes were triggered by a Nexla support team member acting on behalf of a user then this field reflects information about that user while `impersonator_id` reflects information about the Nexla support team member. */
      user?: {
        /** Format: int32 */
        id?: number;
        /**
         * Format: email
         * @example user@nexla.com
         */
        email?: string;
      };
      /**
       * Format: nullable
       * @description If the changes were made by a Nexla support team member acting on behalf of a user then this field reflects information about the Nexla support team member.
       */
      impersonator_id?: string;
      /**
       * Format: int32
       * @description The ID of the organization that this resource belongs to.
       */
      org_id?: number;
      /**
       * Format: int32
       * @description The ID of the user that this resource belongs to.
       */
      owner_id?: number;
      /** @description Email ID of the user that this resource belongs to. */
      owner_email?: string;
      /**
       * Format: date-time
       * @example 2022-11-08T22:51:47.720Z
       */
      created_at?: string;
    };
    audit_log_response: components["schemas"]["LogEntry"][] | components["schemas"]["AsyncResponse"];
    /** @enum {string} */
    QuarantineResourceType: "ORG" | "USER" | "FLOW" | "PIPELINE" | "DATA_FLOW" | "CUSTOM_DATA_FLOW" | "SOURCE" | "DATASET" | "SINK";
    DataCredential: {
      id?: number;
      name?: string;
      description?: string;
      owner?: components["schemas"]["UserSimplified"];
      org?: components["schemas"]["OrgSimplified"];
      access_roles?: string[];
      credentials_version?: string;
      managed?: boolean;
      credentials_type?: string;
      connector?: {
        id?: number;
        type?: string;
        connection_type?: string;
        name?: string;
        description?: string;
        nexset_api_compatible?: boolean;
      };
      api_keys?: unknown[];
      credentials_non_secure_data?: {
        [key: string]: string | Record<string, never> | number;
      };
      verified_status?: string;
      /** Format: date-time */
      verified_at?: string;
      /** Format: nullable */
      copied_from_id?: number;
      /** Format: date-time */
      updated_at?: string;
      /** Format: date-time */
      created_at?: string;
      tags?: unknown[];
    };
    QuarantineSetting: {
      /** Format: int32 */
      id?: number;
      owner?: components["schemas"]["UserSimplified"];
      org?: components["schemas"]["OrgSimplified"];
      resource_type?: components["schemas"]["QuarantineResourceType"];
      /** Format: int32 */
      resource_id?: number;
      /**
       * @example {
       *   "start.cron": "0 50 18 1 1/1 ? *",
       *   "path": "/nexla_error_data/export"
       * }
       */
      config?: {
        "start.cron"?: string;
        path?: string;
      };
      /** Format: int32 */
      data_credentials_id?: number;
      /** @example gdrive */
      credentials_type?: string;
      data_credentials?: components["schemas"]["DataCredential"];
    };
    QuarantineSettingMutable: {
      /** @description Nexla data credential to a file storage system where all error data should be exported. Configure the base folder within the location accessible by this credential by setting an appropriate value for `configure["path"]`. */
      data_credentials_id?: number;
      /**
       * @example {
       *   "start.cron": "0 50 18 1 1/1 ? *",
       *   "path": "/nexla_error_data/export"
       * }
       */
      config?: {
        /**
         * @description The interval at which Nexla should scan all quarantined records in the user's account and export them to the specified file storage.
         *
         * This should be a valid cron expression.
         */
        "start.cron": string;
        /** @description The base folder where all quarantined records will be exported. Nexla will automatically create subfolder tree in this base folder when exporting error data files. These subfolders will be of the pattern `<base-path>/<nexla-env-code>/<resource-type>/<resource-id>/<yyyy>/<MM>/<dd>/<unique-file-name>.json` */
        path: string;
      };
    };
    QuarantineSettingCreate: components["schemas"]["QuarantineSettingMutable"] & Record<string, never>;
    ApprovalRequest: {
      id?: number;
      org_id?: number;
      request_type?: string;
      topic_id?: number;
      status?: string;
      requestor_id?: number;
      /** Format: date-time */
      created_at?: string;
      /** Format: date-time */
      updated_at?: string;
      assignee_id?: number;
      rejection_reason?: string;
    };
    ResponseOrgAccessor: {
      /** @enum {string} */
      type?: "ORG";
      /** @example nexla.com */
      email_domain?: string;
      /** Format: nullable */
      client_identifier?: string;
    };
    ResponseTeamAccessor: {
      /** @enum {string} */
      type?: "TEAM";
      name?: string;
    };
    ResponseUserAccessor: {
      /** @enum {string} */
      type?: "USER";
      /** @example example@nexla.com */
      email?: string;
    };
    AccessorsResponseSchema: (components["schemas"]["ResponseOrgAccessor"] | components["schemas"]["ResponseTeamAccessor"] | components["schemas"]["ResponseUserAccessor"]) & {
      access_roles?: components["schemas"]["AccessRoles"];
      /**
       * Format: date-time
       * @example 2021-04-06T21:02:17.000Z
       */
      created_at?: string;
      /**
       * Format: date-time
       * @example 2021-04-06T21:02:17.000Z
       */
      updated_at?: string;
    };
    RequestUserAccessor: {
      /**
       * @description Choose this option if the access permissions should be granted to a user.
       *
       * >  Note: Users can belong to multiple organizations. The platform allows granting access permission across organization boundaries only for Nexset `sharer` access role.
       *
       * @enum {string}
       */
      type?: "USER";
      /** @description Unique ID of the user that should be granted this permission. */
      id?: number;
      /**
       * @description `Optional`: Only user-id or email is required to identify the user who should be granted this access permission.
       *
       * @example example@nexla.com
       */
      email?: string;
      /** @description Users can belong to multiple organizations. Specify the org_id to explicitly set the organization context for this access permission. If this is not specified the platform will try to automatically assign the permission to the user's default organization (when granting sharer access on a Nexset) or to the current organization (for all other access roles). */
      org_id?: number;
    };
    RequestTeamAccessor: {
      /**
       * @description Choose this option if the access permissions should be granted to a team.
       *
       * @enum {string}
       */
      type?: "TEAM";
      /** @description Unique ID of the team that should be granted this permission. */
      id?: number;
    };
    RequestOrgAccessor: {
      /**
       * @description Choose this option if the access permissions should be granted to an entire organization.
       *
       * @enum {string}
       */
      type?: "ORG";
      /** @description Unique ID of the organization that should be granted this permission. */
      id?: number;
    };
    AccessorsMutable: (components["schemas"]["RequestUserAccessor"] | components["schemas"]["RequestTeamAccessor"] | components["schemas"]["RequestOrgAccessor"]) & {
      access_roles?: components["schemas"]["AccessRoles"];
    };
    AccessorsRequestSchema: {
      accessors?: components["schemas"]["AccessorsMutable"][];
    };
    MarketplaceDomain: {
      id?: number;
      org_id?: null | number;
      owner_id?: null | number;
      name?: string;
      description?: string;
      /** @description ID of the parent domain. Domains may build a hierarchy. */
      parent_id?: number;
      /** Format: date-time */
      created_at?: string;
      /** Format: date-time */
      updated_at?: string;
    };
    MarketplaceDomainCreate: {
      org_id?: null | number;
      owner_id?: null | number;
      name?: string;
      description?: string;
      /** @description ID of the parent domain. Domains may build a hierarchy. */
      parent_id?: number;
      custodians?: components["schemas"]["CustodiansPayload"];
    };
    MarketplaceDomainsItem: {
      id?: number;
      name?: string;
      description?: null | string;
      /** @description Data samples coming from data sets that the marketplace item presents. */
      data_samples?: {
          [key: string]: unknown;
        }[];
      /** Format: date-time */
      created_at?: string;
      /** Format: date-time */
      updated_at?: string;
    };
    MarketplaceDomainsItemCreate: {
      name?: string;
      description?: null | string;
      /** @description ID of the org's dataset that marketplace item should present. User should have a `read` permission for the dataset. */
      data_set_id?: number;
    };
    CustodiansResponse: {
        id?: number;
        email?: string;
        full_name?: string;
      }[];
    UserBrief: {
      id?: number;
      full_name?: string;
      email?: string;
      org?: number;
      impersonated?: boolean;
      impersonator?: components["schemas"]["UserSimplified"] & {
        org?: number;
      };
    };
    OrgMembershipToken: {
      api_key?: string;
      status?: components["schemas"]["OrgMembershipStatus"];
      "is_admin?"?: boolean;
    };
    Token: {
      access_token?: string;
      /** @enum {string} */
      token_type?: "Bearer";
      expires_in?: number;
      user?: components["schemas"]["UserBrief"];
      org_membership?: components["schemas"]["OrgMembershipToken"];
      org?: components["schemas"]["OrgSimplified"];
    };
    AuthConfig: {
      id?: number;
      owner?: components["schemas"]["UserSimplified"];
      org?: components["schemas"]["OrgSimplified"];
      /** @description Unique external identifier for the authentication configuration. */
      uid?: string;
      /** @enum {string} */
      protocol?: "saml" | "oidc" | "google" | "password";
      name?: string;
      description?: string;
      /** @description If true, this configuration is available to all organizations in the environment. */
      global?: boolean;
      /** @description If true, Nexla will automatically create users in the environment when they log in using this authentication configuration. */
      auto_create_users_enabled?: boolean;
      /** @description The format of the NameID element in the SAML assertion. This is used to identify the user. */
      name_identifier_format?: string;
      /** @description The base URL of the Nexla environment where the user should be redirected after authentication. */
      nexla_base_url?: string;
      service_entity_id?: string;
      assertion_consumer_url?: string;
      logout_url?: string;
      metadata_url?: string;
      idp_entity_id?: string;
      idp_sso_target_url?: string;
      idp_slo_target_url?: string;
      idp_cert?: string;
      security_settings?: string;
      oidc_domain?: string;
      oidc_keys_url_key?: string;
      oidc_token_verify_url?: string;
      oidc_id_claims?: string;
      oidc_access_claims?: string;
      client_config?: {
        [key: string]: unknown;
      };
      /** Format: date-time */
      updated_at?: string;
      /** Format: date-time */
      created_at?: string;
    };
    AuthConfigPayload: {
      id?: number;
      owner_id?: number;
      org_id?: number;
      uid?: string;
      protocol?: string;
      name?: string;
      description?: string;
      global?: boolean;
      enabled_by_default?: boolean;
      auto_create_users_enabled?: boolean;
      name_identifier_format?: string;
      nexla_base_url?: string;
      service_entity_id?: string;
      assertion_consumer_url?: string;
      idp_entity_id?: string;
      idp_sso_target_url?: string;
      idp_slo_target_url?: string;
      idp_cert?: string;
      security_settings?: {
        [key: string]: unknown;
      };
      metadata?: string;
      oidc_domain?: string;
      oidc_keys_url_key?: string;
      oidc_id_claims?: {
        [key: string]: unknown;
      };
      oidc_access_claims?: {
        [key: string]: unknown;
      };
      client_config?: {
        [key: string]: unknown;
      };
      secret_config?: {
        [key: string]: unknown;
      };
      check_state?: boolean;
    };
    SignupRequest: {
      email?: string;
      full_name?: string;
      g_captcha_response?: string;
      /**
       * @description Invite code is required for self sign up. This is a unique code that is shared with the user to allow them to sign up.
       * Included in the signup link if invites is used.
       */
      invite?: string;
      /** @description Free form object to store marketing/private information about the user. */
      personal_info?: {
        [key: string]: unknown;
      };
    };
    AuthSetting: {
      id?: number;
      org?: components["schemas"]["OrgSimplified"];
      auth_config?: {
        id?: number;
        uid?: string;
        /** @enum {string} */
        protocol?: "saml" | "oidc" | "google" | "password";
        name?: string;
        description?: string;
        global?: boolean;
      };
      enabled?: boolean;
      /** Format: date-time */
      created_at?: string;
      /** Format: date-time */
      updated_at?: string;
    };
    AuthSettingPayload: {
      enabled?: boolean;
    };
    /** @enum {string} */
    async_task_types: "BulkDeleteNotifications" | "BulkMarkAsReadNotifications" | "BulkPauseFlows" | "CallProbe" | "ChownUserResources" | "DeactivateUser" | "GetAuditLogs";
    /**
     * @description The status of the task.
     * @enum {string}
     */
    async_task_statuses: "pending" | "running" | "completed" | "failed" | "cancelled";
    /** @description Success */
    AsyncTask: {
      /** @description The unique identifier of the task. */
      id?: string;
      type?: components["schemas"]["async_task_types"];
      status?: components["schemas"]["async_task_statuses"];
      /** @description The progress of the task. */
      progress?: number;
      /** @description The priority of the task. */
      priority?: number;
      /**
       * Format: date-time
       * @description The date and time the task was created.
       */
      created_at?: string;
      /**
       * Format: date-time
       * @description The date and time the task was completed, failed or stopped in another way.
       */
      stopped_at?: string;
      /** @description The result of the task. */
      result?: Record<string, never>;
      /** @description The URL to the result of the task. */
      result_url?: string;
      /** @description The error that occurred during the task. */
      error?: Record<string, never>;
      owner?: components["schemas"]["owner"];
      org?: components["schemas"]["org"];
    };
    AsyncTaskPayload: {
      /**
       * @description The type of the task.
       * @enum {string}
       */
      type?: "BulkDeleteNotifications" | "BulkMarkAsReadNotifications" | "BulkPauseFlows" | "CallProbe" | "ChownUserResources" | "DeactivateUser" | "GetAuditLogs";
      /** @description The priority of the task. At the moment doesn't have any effect. */
      priority?: number;
      /** @description The arguments for the task. Use `GET /async_tasks/explain_arguments/{task_type}` to get the list of possible arguments for task. */
      arguments?: {
        [key: string]: unknown;
      };
    };
    Runtime: {
      /** @description The unique identifier of the runtime. */
      id?: number;
      owner?: components["schemas"]["owner"];
      org?: components["schemas"]["org"];
      /** @description The name of the runtime. */
      name?: string;
      /** @description The description of the runtime. */
      description?: string;
      /**
       * Format: date-time
       * @description The date and time when the runtime was created.
       */
      created_at?: string;
      /**
       * Format: date-time
       * @description The date and time when the runtime was last updated.
       */
      updated_at?: string;
      /** @description Whether the runtime is active or not. */
      active?: boolean;
      /** @description The path to the Docker image. */
      dockerpath?: string;
      /** @description Whether the runtime is managed or not. */
      managed?: boolean;
      /** @description The configuration of the runtime. */
      config?: {
        [key: string]: unknown;
      };
    };
    RuntimePayload: {
      /** @description The name of the runtime. */
      name?: string;
      /** @description The description of the runtime. */
      description?: string;
      /** @description Whether the runtime is active or not. */
      active?: boolean;
      /** @description The path to the Docker image. */
      dockerpath?: string;
      /** @description Whether the runtime is managed or not. */
      managed?: boolean;
      /** @description The configuration of the runtime. */
      config?: {
        [key: string]: unknown;
      };
    };
    GenAiConfig: {
      /** Format: int32 */
      id?: number;
      owner?: components["schemas"]["UserSimplified"];
      org?: components["schemas"]["OrgSimplified"];
      data_credentials?: components["schemas"]["DataCredential"];
      name?: string;
      description?: string;
      /** @enum {string} */
      status?: "ACTIVE" | "PAUSED";
      config?: {
        api_version?: string;
        openai_model?: string;
        google_ai_model?: string;
        enable_doc_recommendations?: boolean;
        [key: string]: unknown;
      };
      /** @enum {string} */
      type?: "genai_openai" | "genai_googleai";
    };
    GenAiConfigPayload: {
      name?: string;
      description?: string | null;
      status?: ("active" | "paused") | null;
      config?: {
        api_version?: string | null;
        openai_model?: string | null;
        google_ai_model?: string | null;
        enable_doc_recommendations?: boolean;
        [key: string]: unknown;
      };
      /** @enum {string} */
      type?: "genai_openai" | "genai_googleai";
      data_credentials_id?: number;
    };
    GenAiConfigCreatePayload: components["schemas"]["GenAiConfigPayload"];
    GenAiOrgSetting: {
      id?: number;
      org_id?: number;
      /** @enum {string} */
      gen_ai_usage?: "gen_docs" | "check_code" | "all";
      get_ai_config_id?: number;
      /** @description GenAI configuration (only if accessible) */
      gen_ai_config?: components["schemas"]["GenAiConfig"];
    };
    GenAiOrgSettingPayload: {
      org_id?: number;
      gen_ai_config_id?: number;
      /** @enum {string} */
      gen_ai_usage?: "all" | "gen_docs" | "check_code";
    };
    nexset_record: {
      [key: string]: string;
    };
  };
  responses: {
    /** @description Success */
    data_credential_many: {
      content: {
        "application/json": ({
            id?: number;
            name?: string;
            description?: string | null;
            owner?: components["schemas"]["owner"];
            org?: components["schemas"]["org"];
            access_roles?: components["schemas"]["AccessRoles"];
            credentials_version?: string;
            credentials_type?: string;
            connector?: {
              id?: number;
              type?: string;
              connection_type?: string;
              name?: string;
              description?: string;
              nexset_api_compatible?: boolean;
            };
            verified_status?: string;
            /** Format: date-time */
            verified_at?: string;
            copied_from_id?: number | null;
            /** Format: date-time */
            updated_at?: string;
            /** Format: date-time */
            created_at?: string;
            vendor?: {
              id?: number;
              name?: string;
              display_name?: string;
              connection_type?: string;
            };
            template_config?: Record<string, never> | null;
          })[];
      };
    };
    /** @description Success */
    data_credential_one: {
      content: {
        "application/json": {
          id?: number;
          name?: string;
          description?: string;
          owner?: components["schemas"]["owner"];
          org?: components["schemas"]["org"];
          access_roles?: components["schemas"]["AccessRoles"];
          credentials_version?: string;
          managed?: boolean;
          credentials_type?: string;
          connector?: {
            id?: number;
            type?: string;
            connection_type?: string;
            name?: string;
            description?: string;
            nexset_api_compatible?: boolean;
          };
          api_keys?: unknown[];
          credentials_non_secure_data?: {
            [key: string]: string | Record<string, never> | number;
          };
          verified_status?: string;
          /** Format: date-time */
          verified_at?: string;
          copied_from_id?: null;
          /** Format: date-time */
          updated_at?: string;
          /** Format: date-time */
          created_at?: string;
          tags?: unknown[];
        };
      };
    };
    /** @description Success */
    FlowsManyWithMetric: {
      content: {
        "application/json": {
          flows?: components["schemas"]["FlowNodes"];
        } & components["schemas"]["FlowElements"] & {
          metrics?: {
              origin_node_id?: number;
              records?: number;
              size?: number;
              errors?: number;
              /** Format: date-time */
              reporting_date?: string;
              run_id?: number;
            }[];
        };
      };
    };
    /** @description Success */
    FlowsOne: {
      content: {
        "application/json": {
          flows?: components["schemas"]["FlowOriginNode"][];
        } & components["schemas"]["FlowElements"];
      };
    };
    /** @description Either success or failure */
    genai_recommendation_response: {
      content: {
        "application/json": {
          /**
           * @description Should be 200 or "ok" for normal response. If GenAI service is not available, you will get another status code.
           * @example ok
           */
          status: string;
          output?: {
            /** @description The response message from GenAI service. Contains Markdown text.  If there is an error, this field will not be present. */
            response?: string;
            /**
             * @description The status code from external GenAI service.
             * @example 200
             */
            statusCode?: number;
            /**
             * @description If there is an error, this field will contain the error message, and 'response' field will not be present.
             * @example GenAI Integration has not been enabled for your Nexla organization. Please contact your organization admin or Nexla support for enabling the integration.
             */
            errorMessage?: string;
          };
        };
      };
    };
    /** @description Success */
    data_source_many: {
      content: {
        "application/json": ({
            id?: number;
            name?: string;
            description?: string | null;
            status?: string;
            ingest_method?: string;
            source_format?: string;
            managed?: boolean;
            code_container_id?: number | null;
            copied_from_id?: number | null;
            /** Format: date-time */
            created_at?: string;
            /** Format: date-time */
            updated_at?: string;
            source_type?: string;
            connector_type?: string;
            connector?: {
              id?: number;
              type?: string;
              connection_type?: string;
              name?: string;
              description?: string;
              nexset_api_compatible?: boolean;
            };
            access_roles?: components["schemas"]["AccessRoles"];
            auto_generated?: boolean;
            owner?: components["schemas"]["owner"];
            org?: components["schemas"]["org"];
            data_sets?: unknown[];
            tags?: unknown[];
            flow_type?: string;
            ingestion_mode?: string;
            run_ids?: unknown[];
            has_template?: boolean;
            vendor_endpoint?: {
              id?: number;
              name?: string;
              display_name?: string;
            };
            vendor?: {
              id?: number;
              name?: string;
              display_name?: string;
              connection_type?: string;
            };
          })[];
      };
    };
    /** @description Success */
    data_source_one: {
      content: {
        "application/json": {
          id?: number;
          owner?: components["schemas"]["owner"];
          org?: components["schemas"]["org"];
          access_roles?: components["schemas"]["AccessRoles"];
          name?: string;
          description?: null;
          status?: string;
          data_sets?: {
              version?: number;
              id?: number;
              owner_id?: number;
              org_id?: number;
              name?: string;
              description?: string;
              /** Format: date-time */
              updated_at?: string;
              /** Format: date-time */
              created_at?: string;
            }[];
          ingest_method?: string;
          source_format?: string;
          /** @description The source configuration properties that were set as `source_config` in the payload-to-source create/update API calls. */
          source_config?: {
            [key: string]: string;
          };
          poll_schedule?: null;
          managed?: boolean;
          code_container_id?: null;
          source_type?: string;
          connector_type?: string;
          connector?: {
            id?: number;
            type?: string;
            connection_type?: string;
            name?: string;
            description?: string;
            nexset_api_compatible?: boolean;
          };
          api_keys?: unknown[];
          auto_generated?: boolean;
          data_credentials?: {
            id?: number;
            name?: string;
            description?: string;
            owner?: components["schemas"]["owner"];
            org?: components["schemas"]["org"];
            access_roles?: components["schemas"]["AccessRoles"];
            credentials_version?: string;
            managed?: boolean;
            credentials_type?: string;
            connector?: {
              id?: number;
              type?: string;
              connection_type?: string;
              name?: string;
              description?: string;
              nexset_api_compatible?: boolean;
            };
            api_keys?: unknown[];
            credentials_non_secure_data?: {
              [key: string]: string | Record<string, never> | number;
            };
            verified_status?: string;
            /** Format: date-time */
            verified_at?: string;
            copied_from_id?: null;
            /** Format: date-time */
            updated_at?: string;
            /** Format: date-time */
            created_at?: string;
            tags?: unknown[];
          };
          run_ids?: {
              id?: number;
              /** Format: date-time */
              created_at?: string;
            }[];
          copied_from_id?: null;
          /** Format: date-time */
          updated_at?: string;
          /** Format: date-time */
          created_at?: string;
          tags?: unknown[];
          flow_type?: string;
          ingestion_mode?: string;
        };
      };
    };
    /** @description Success */
    data_source_one_expand: {
      content: {
        "application/json": {
          id?: number;
          owner?: components["schemas"]["owner"];
          org?: components["schemas"]["org"];
          access_roles?: components["schemas"]["AccessRoles"];
          name?: string;
          description?: null;
          status?: string;
          data_sets?: {
              version?: number;
              id?: number;
              owner_id?: number;
              org_id?: number;
              name?: string;
              description?: string;
              /** Format: date-time */
              updated_at?: string;
              /** Format: date-time */
              created_at?: string;
              sample_service_id?: null;
              source_schema?: components["schemas"]["data_set_schema"];
              transform?: {
                version?: number;
                data_maps?: unknown[];
                transforms?: unknown[];
                custom_config?: Record<string, never>;
              };
              output_schema?: components["schemas"]["data_set_schema"];
            }[];
          ingest_method?: string;
          source_format?: string;
          source_config?: {
            [key: string]: string;
          };
          poll_schedule?: null;
          managed?: boolean;
          code_container_id?: null;
          source_type?: string;
          connector_type?: string;
          connector?: {
            id?: number;
            type?: string;
            connection_type?: string;
            name?: string;
            description?: string;
            nexset_api_compatible?: boolean;
          };
          api_keys?: unknown[];
          auto_generated?: boolean;
          data_credentials?: {
            id?: number;
            name?: string;
            description?: string;
            owner?: components["schemas"]["owner"];
            org?: components["schemas"]["org"];
            access_roles?: components["schemas"]["AccessRoles"];
            credentials_version?: string;
            managed?: boolean;
            credentials_type?: string;
            connector?: {
              id?: number;
              type?: string;
              connection_type?: string;
              name?: string;
              description?: string;
              nexset_api_compatible?: boolean;
            };
            api_keys?: unknown[];
            credentials_non_secure_data?: {
              [key: string]: string | Record<string, never> | number;
            };
            verified_status?: string;
            /** Format: date-time */
            verified_at?: string;
            copied_from_id?: null;
            /** Format: date-time */
            updated_at?: string;
            /** Format: date-time */
            created_at?: string;
            tags?: unknown[];
          };
          run_ids?: {
              id?: number;
              /** Format: date-time */
              created_at?: string;
            }[];
          copied_from_id?: null;
          /** Format: date-time */
          updated_at?: string;
          /** Format: date-time */
          created_at?: string;
          flow_type?: string;
          ingestion_mode?: string;
          tags?: unknown[];
        };
      };
    };
    /** @description Success */
    data_sets_many: {
      content: {
        "application/json": components["schemas"]["DataSet"][];
      };
    };
    /** @description Success */
    data_sets_one: {
      content: {
        "application/json": components["schemas"]["DataSet"];
      };
    };
    /** @description Success */
    data_sets_sample: {
      content: {
        "application/json": OneOf<[({
            [key: string]: number | string | boolean | unknown[] | Record<string, never>;
          })[], ({
            /** @description Contents of the record in this sample. */
            rawMessage?: {
              [key: string]: number | string | boolean | unknown[] | Record<string, never>;
            };
            /** @description Metadata about this record. */
            nexlaMetaData?: {
              /** @example GDRIVE */
              sourceType?: string;
              /**
               * Format: int64
               * @example 1657222945906
               */
              ingestTime?: number;
              /**
               * Format: int32
               * @example 0
               */
              sourceOffset?: number;
              /** @example aBcDeFg */
              sourceKey?: string;
              /** Format: nullable */
              topic?: string;
              /** @example SOURCE */
              resourceType?: string;
              /**
               * Format: int32
               * @example 1
               */
              resourceId?: number;
              trackerId?: {
                [key: string]: string;
              };
              eof?: boolean;
              /**
               * Format: int64
               * @example 1656524615000
               */
              lastModified?: number;
              /**
               * Format: int64
               * @example 1657222941374
               */
              runId?: number;
              tags?: {
                [key: string]: string;
              };
              /** @example streaming */
              flow_type?: string;
            };
          })[]]>;
      };
    };
    /** @description Success */
    data_sink_many: {
      content: {
        "application/json": ({
            id?: number;
            name?: string;
            description?: string | null;
            status?: string;
            data_set_id?: number | null;
            data_map_id?: number | null;
            data_source_id?: null;
            sink_format?: null;
            sink_schedule?: null;
            in_memory?: boolean;
            managed?: boolean;
            copied_from_id?: number | null;
            /** Format: date-time */
            updated_at?: string;
            /** Format: date-time */
            created_at?: string;
            sink_type?: string;
            connector_type?: string;
            connector?: {
              id?: number;
              type?: string;
              connection_type?: string;
              name?: string;
              description?: string;
              nexset_api_compatible?: boolean;
            };
            access_roles?: components["schemas"]["AccessRoles"];
            owner?: components["schemas"]["owner"];
            org?: components["schemas"]["org"];
            data_set?: ({
              id?: number;
              owner_id?: number;
              org_id?: number;
              name?: string;
              description?: string;
              status?: string;
              copied_from_id?: number | null;
              /** Format: date-time */
              created_at?: string;
              /** Format: date-time */
              updated_at?: string;
            }) | null;
            data_map?: {
              id?: number;
              owner_id?: number;
              org_id?: number;
              name?: string;
              description?: string;
              public?: boolean;
              /** Format: date-time */
              created_at?: string;
              /** Format: date-time */
              updated_at?: string;
            } | null;
            tags?: unknown[];
            flow_type?: string;
            has_template?: boolean;
            vendor_endpoint?: {
              id?: number;
              name?: string;
              display_name?: string;
            };
            vendor?: {
              id?: number;
              name?: string;
              display_name?: string;
              connection_type?: string;
            };
          })[];
      };
    };
    /** @description Success */
    data_sink_one: {
      content: {
        "application/json": {
          id?: number;
          owner?: components["schemas"]["owner"];
          org?: components["schemas"]["org"];
          access_roles?: components["schemas"]["AccessRoles"];
          name?: string;
          description?: null;
          status?: string;
          data_set_id?: number;
          data_map_id?: null;
          data_source_id?: null;
          sink_format?: null;
          /** @description The destination configuration properties that were set as `sink_config` in the payload-to-destination create/update API calls. */
          sink_config?: {
            [key: string]: string;
          };
          sink_schedule?: null;
          in_memory?: boolean;
          managed?: boolean;
          sink_type?: string;
          connector_type?: string;
          connector?: {
            id?: number;
            type?: string;
            connection_type?: string;
            name?: string;
            description?: string;
            nexset_api_compatible?: boolean;
          };
          data_set?: {
            id?: number;
            name?: string;
          };
          data_credentials?: {
            id?: number;
            name?: string;
            description?: string;
            owner?: components["schemas"]["owner"];
            org?: components["schemas"]["org"];
            access_roles?: components["schemas"]["AccessRoles"];
            credentials_version?: string;
            managed?: boolean;
            credentials_type?: string;
            connector?: {
              id?: number;
              type?: string;
              connection_type?: string;
              name?: string;
              description?: string;
              nexset_api_compatible?: boolean;
            };
            api_keys?: unknown[];
            credentials_non_secure_data?: {
              [key: string]: string | Record<string, never> | number;
            };
            verified_status?: string;
            /** Format: date-time */
            verified_at?: string;
            copied_from_id?: null;
            /** Format: date-time */
            updated_at?: string;
            /** Format: date-time */
            created_at?: string;
            tags?: unknown[];
          };
          copied_from_id?: null;
          /** Format: date-time */
          updated_at?: string;
          /** Format: date-time */
          created_at?: string;
          tags?: unknown[];
          flow_type?: string;
        };
      };
    };
    /** @description Success */
    data_sink_one_expand: {
      content: {
        "application/json": {
          id?: number;
          owner?: components["schemas"]["owner"];
          org?: components["schemas"]["org"];
          access_roles?: components["schemas"]["AccessRoles"];
          name?: string;
          description?: null;
          status?: string;
          data_set_id?: number;
          data_map_id?: null;
          data_source_id?: null;
          sink_format?: null;
          /** @description The destination configuration properties that were set as `sink_config` in the payload-to-destination create/update API calls. */
          sink_config?: {
            [key: string]: string;
          };
          sink_schedule?: null;
          in_memory?: boolean;
          managed?: boolean;
          sink_type?: string;
          connector_type?: string;
          connector?: {
            id?: number;
            type?: string;
            connection_type?: string;
            name?: string;
            description?: string;
            nexset_api_compatible?: boolean;
          };
          data_set?: {
            id?: number;
            name?: string;
            description?: string;
            output_schema?: components["schemas"]["data_set_schema"];
            status?: string;
            /** Format: date-time */
            updated_at?: string;
            /** Format: date-time */
            created_at?: string;
            version?: number;
          };
          data_credentials?: {
            id?: number;
            name?: string;
            description?: string;
            owner?: components["schemas"]["owner"];
            org?: components["schemas"]["org"];
            access_roles?: components["schemas"]["AccessRoles"];
            credentials_version?: string;
            managed?: boolean;
            credentials_type?: string;
            connector?: {
              id?: number;
              type?: string;
              connection_type?: string;
              name?: string;
              description?: string;
              nexset_api_compatible?: boolean;
            };
            api_keys?: unknown[];
            credentials_non_secure_data?: {
              [key: string]: string | Record<string, never> | number;
            };
            verified_status?: string;
            /** Format: date-time */
            verified_at?: string;
            copied_from_id?: null;
            /** Format: date-time */
            updated_at?: string;
            /** Format: date-time */
            created_at?: string;
            tags?: unknown[];
          };
          copied_from_id?: null;
          /** Format: date-time */
          updated_at?: string;
          /** Format: date-time */
          created_at?: string;
          tags?: unknown[];
        };
      };
    };
    /** @description Success */
    data_maps_many: {
      content: {
        "application/json": components["schemas"]["DataMap"][];
      };
    };
    /** @description Success */
    data_maps_one: {
      content: {
        "application/json": components["schemas"]["DataMap"];
      };
    };
    /** @description Success */
    data_map_entries: {
      content: {
        "application/json": ({
            [key: string]: string | number;
          })[];
      };
    };
    /** @description Success */
    Transform: {
      content: {
        "application/json": components["schemas"]["Transform"][];
      };
    };
    /** @description Success */
    code_containers_one_Transform: {
      content: {
        "application/json": components["schemas"]["Transform"];
      };
    };
    /** @description Success */
    CodeContainer: {
      content: {
        "application/json": components["schemas"]["CodeContainer"];
      };
    };
    /** @description Success */
    AttributeTransform: {
      content: {
        "application/json": components["schemas"]["AttributeTransform"][];
      };
    };
    /** @description Success */
    code_containers_one_AttributeTransform: {
      content: {
        "application/json": components["schemas"]["AttributeTransform"];
      };
    };
    /** @description Success */
    code_containers_many_CodeContainer: {
      content: {
        "application/json": components["schemas"]["CodeContainer"][];
      };
    };
    /** @description Success */
    projects_many: {
      content: {
        "application/json": components["schemas"]["Project"][];
      };
    };
    /** @description Success */
    projects_one: {
      content: {
        "application/json": components["schemas"]["Project"];
      };
    };
    /** @description Success */
    FlowsMany: {
      content: {
        "application/json": {
          flows?: components["schemas"]["FlowNodes"];
        } & components["schemas"]["FlowElements"];
      };
    };
    /** @description Success */
    ProjectFlowsOld: {
      content: {
        "application/json": components["schemas"]["ProjectDataFlow"][];
      };
    };
    /** @description Success */
    orgs_many: {
      content: {
        "application/json": ({
            id?: number;
            name?: string;
            description?: string | null;
            email_domain?: string;
            /** Format: email */
            email?: string | null;
            client_identifier?: string | null;
            /** Format: url */
            org_webhook_host?: string;
            default_cluster_id?: number;
            access_roles?: components["schemas"]["AccessRoles"];
            owner?: {
              id?: number;
              /** Format: email */
              email?: string;
              full_name?: string;
              super_user?: boolean;
              impersonated?: boolean;
              default_org?: {
                id?: number;
                name?: string;
              };
              user_tier?: null;
              status?: string;
              account_locked?: boolean;
              org_memberships?: unknown[];
              /** Format: date-time */
              email_verified_at?: string;
              /** Format: date-time */
              tos_signed_at?: string | null;
              /** Format: date-time */
              updated_at?: string;
              /** Format: date-time */
              created_at?: string;
            };
            billing_owner?: {
              id?: number;
              /** Format: email */
              email?: string;
              full_name?: string;
              super_user?: boolean;
              impersonated?: boolean;
              default_org?: {
                id?: number;
                name?: string;
              };
              user_tier?: null;
              status?: string;
              account_locked?: boolean;
              org_memberships?: unknown[];
              /** Format: date-time */
              email_verified_at?: string;
              /** Format: date-time */
              tos_signed_at?: string | null;
              /** Format: date-time */
              updated_at?: string;
              /** Format: date-time */
              created_at?: string;
            };
            admins?: unknown[];
            org_tier?: {
              id?: number;
              name?: string;
              display_name?: string;
              record_count_limit?: number;
              record_count_limit_time?: string;
              data_source_count_limit?: number;
              trial_period_days?: number;
            } | null;
            members_default_access_role?: string;
            status?: string;
            default_reusable_code_container_access_role?: string;
            require_org_admin_to_publish?: boolean;
            require_org_admin_to_subscribe?: boolean;
            /** Format: date-time */
            email_domain_verified_at?: string | null;
            /** Format: date-time */
            name_verified_at?: string | null;
            enable_nexla_password_login?: boolean;
            /** Format: date-time */
            updated_at?: string;
            /** Format: date-time */
            created_at?: string;
          })[];
      };
    };
    /** @description Success */
    orgs_one: {
      content: {
        "application/json": {
          id?: number;
          name?: string;
          description?: null;
          cluster_id?: number;
          new_cluster_id?: null;
          cluster_status?: string;
          email_domain?: string;
          email?: null;
          client_identifier?: string;
          /** Format: url */
          org_webhook_host?: string;
          access_roles?: components["schemas"]["AccessRoles"];
          owner?: {
            id?: number;
            /** Format: email */
            email?: string;
            full_name?: string;
            impersonated?: boolean;
            default_org?: {
              id?: number;
              name?: string;
            };
            user_tier?: null;
            status?: string;
            account_locked?: boolean;
            org_memberships?: {
                id?: number;
                name?: string;
                "is_admin?"?: boolean;
                org_membership_status?: string;
              }[];
            /** Format: date-time */
            email_verified_at?: string;
            tos_signed_at?: null;
            /** Format: date-time */
            updated_at?: string;
            /** Format: date-time */
            created_at?: string;
          };
          billing_owner?: {
            id?: number;
            /** Format: email */
            email?: string;
            full_name?: string;
            impersonated?: boolean;
            default_org?: {
              id?: number;
              name?: string;
            };
            user_tier?: null;
            status?: string;
            account_locked?: boolean;
            org_memberships?: {
                id?: number;
                name?: string;
                "is_admin?"?: boolean;
                org_membership_status?: string;
              }[];
            /** Format: date-time */
            email_verified_at?: string;
            tos_signed_at?: null;
            /** Format: date-time */
            updated_at?: string;
            /** Format: date-time */
            created_at?: string;
          };
          admins?: {
              id?: number;
              full_name?: string;
              /** Format: email */
              email?: string;
            }[];
          org_tier?: {
            id?: number;
            name?: string;
            display_name?: string;
            record_count_limit?: number;
            record_count_limit_time?: string;
            data_source_count_limit?: number;
            trial_period_days?: number;
          };
          members_default_access_role?: string;
          status?: string;
          default_reusable_code_container_access_role?: string;
          require_org_admin_to_publish?: boolean;
          require_org_admin_to_subscribe?: boolean;
          email_domain_verified_at?: null;
          name_verified_at?: null;
          enable_nexla_password_login?: boolean;
          /** Format: date-time */
          updated_at?: string;
          /** Format: date-time */
          created_at?: string;
        };
      };
    };
    /** @description Success */
    org_members: {
      content: {
        "application/json": components["schemas"]["OrgMember"][];
      };
    };
    /** @description Success */
    teams_many: {
      content: {
        "application/json": components["schemas"]["Team"][];
      };
    };
    /** @description Success */
    teams_one: {
      content: {
        "application/json": components["schemas"]["Team"];
      };
    };
    /** @description Success */
    team_members: {
      content: {
        "application/json": components["schemas"]["TeamMemberList"][];
      };
    };
    /** @description Success */
    users_many: {
      content: {
        "application/json": components["schemas"]["User"][];
      };
    };
    /** @description Success */
    users_one: {
      content: {
        "application/json": components["schemas"]["User"];
      };
    };
    /** @description Success */
    users_many_expand: {
      content: {
        "application/json": components["schemas"]["UserExpanded"][];
      };
    };
    /** @description Success */
    users_one_expand: {
      content: {
        "application/json": components["schemas"]["UserExpanded"];
      };
    };
    /** @description Success */
    users_transfer: {
      content: {
        "application/json": components["schemas"]["UserTransferred"];
      };
    };
    /** @description Success */
    user_settings_list: {
      content: {
        "application/json": components["schemas"]["UserSettings"][];
      };
    };
    /** @description Success */
    notifications_many: {
      content: {
        "application/json": components["schemas"]["Notification"][];
      };
    };
    /** @description Success */
    notifications_one: {
      content: {
        "application/json": components["schemas"]["Notification"];
      };
    };
    /** @description Success */
    notifications_count: {
      content: {
        "application/json": {
          count?: number;
        };
      };
    };
    /** @description Success */
    notification_types_many: {
      content: {
        "application/json": components["schemas"]["NotificationType"][];
      };
    };
    /** @description Success */
    notification_types_one: {
      content: {
        "application/json": components["schemas"]["NotificationType"];
      };
    };
    /** @description Success */
    notification_channel_settings_many: {
      content: {
        "application/json": components["schemas"]["NotificationChannelSetting"][];
      };
    };
    /** @description Success */
    notification_channel_settings_one: {
      content: {
        "application/json": components["schemas"]["NotificationChannelSetting"];
      };
    };
    /** @description Success */
    notification_settings_many: {
      content: {
        "application/json": components["schemas"]["NotificationSetting"][];
      };
    };
    /** @description Success */
    notification_settings_one: {
      content: {
        "application/json": components["schemas"]["NotificationSetting"];
      };
    };
    /** @description Success */
    notification_settings_many_type: {
      content: {
        "application/json": components["schemas"]["NotificationSettingTypeView"][];
      };
    };
    /** @description Success */
    flows_account_metrics: {
      content: {
        "application/json": {
          /**
           * Format: int32
           * @description Status of the report request. This must be `200` or `Ok` for the metrics object in the response to be considered valid.
           */
          status?: number;
          metrics?: {
              data?: {
                /**
                 * Format: int32
                 * @description The total number of records processed during the specified time range.
                 */
                records?: number;
                /**
                 * Format: int32
                 * @description The total volume of records processed (in bytes) during the specified time range.
                 */
                size?: number;
              };
              /** Format: date-time */
              start_time?: string;
              /** Format: date-time */
              end_time?: string;
            }[];
        };
      };
    };
    /** @description Success */
    flows_dashboard: {
      content: {
        "application/json": {
          /**
           * Format: int32
           * @description Status of the report request. This must be `200` or `Ok` for the metrics object in the response to be considered valid.
           */
          status?: number;
          metrics?: {
            sources?: {
              [key: string]: components["schemas"]["DashboardMetricSet"];
            };
            sinks?: {
              [key: string]: components["schemas"]["DashboardMetricSet"];
            };
            datasets?: {
              [key: string]: components["schemas"]["DashboardMetricSet"];
            };
            /** Format: date-time */
            start_time?: string;
            /** Format: date-time */
            end_time?: string;
          };
        };
      };
    };
    /** @description Success */
    user_metrics: {
      content: {
        "application/json": {
          metrics?: {
              /**
               * Format: date
               * @description The date (in UTC) that the metrics in this entry are applicable for.
               */
              time?: string;
              /**
               * Format: int32
               * @description The total number of records that were processed on the date indicated by the `time` property.
               */
              records?: number;
              /**
               * Format: int32
               * @description The total volume (in bytes) of records that were processed on the date indicated by the `time` property.
               */
              size?: number;
              /**
               * Format: int32
               * @description The total number of data processing errors that occurred on the date indicated by the `time` property.
               */
              errors?: number;
            }[];
          /**
           * Format: int32
           * @description Status of the report request. This must be `200` or `Ok` for the metrics object in the response to be considered valid.
           */
          status?: number;
        };
      };
    };
    /** @description Success */
    ResourceMetricsDaily: {
      content: {
        "application/json": {
          metrics?: components["schemas"]["ResourceMetricDaily"][];
          /**
           * Format: int32
           * @description Status of the report request. This must be `200` or `Ok` for the metrics object in the response to be considered valid.
           */
          status?: number;
        };
      };
    };
    /** @description Success */
    ResourceMetricsByRuns: {
      content: {
        "application/json": {
          metrics?: {
            data?: components["schemas"]["ResourceMetricByRun"][];
            /** @description A special metadata object that indicates the relevant response Nexla metadata for the metrics  responses. This is useful for iterating through multiple pages of valid data. */
            meta?: {
              /** @description Current page that this response corresponds to. */
              currentPage?: number;
              /** @description Total number of valid pages of metrics data given the current page size. */
              pageCount?: number;
              /** @description Total number of metrics entries that are available for this resource. */
              totalCount?: number;
            };
          };
          /**
           * Format: int32
           * @description Status of the report request. This must be `200` or `Ok` for the metrics object in the response to be considered valid.
           */
          status?: number;
        };
      };
    };
    /** @description Success */
    FlowMetricsResponse: {
      content: {
        "application/json": {
          /** @description Status of the report request. This must be 200 for the data object in the response to be considered valid. */
          status?: number;
          /** @description Message signifying status of the report request. This must be `Ok` for the data object in the response to be considered valid. */
          message?: string;
          metrics?: {
            /** @description Flow metrics data aggregated by resource id for the time period specified. If the request includes `groupby=runId` then the metrics are further grouped by `runId` to separate number of records processed per run id per resource. */
            data?: OneOf<[{
              [key: string]: {
                data_sources?: components["schemas"]["FlowResourceMetric"][];
                data_sets?: components["schemas"]["FlowResourceMetric"][];
                data_sinks?: components["schemas"]["FlowResourceMetric"][];
              };
            }, {
              data_sources?: components["schemas"]["FlowResourceMetric"][];
              data_sets?: components["schemas"]["FlowResourceMetric"][];
              data_sinks?: components["schemas"]["FlowResourceMetric"][];
            }]>;
            /** @description A special metadata object that indicates the relevant response Nexla metadata for the metrics  responses. This is useful for iterating through multiple pages of valid data. */
            meta?: {
              /** @description Current page that this response corresponds to. */
              currentPage?: number;
              /** @description Total number of valid pages of metrics data given the current page size. */
              pageCount?: number;
              /** @description Total number of metrics entries that are available for this resource. */
              totalCount?: number;
            };
          };
        };
      };
    };
    /** @description Success */
    FlowLogsResponse: {
      content: {
        "application/json": {
          /** @description Status of the report request. This must be 200 for the data object in the response to be considered valid. */
          status?: number;
          /** @description Message signifying status of the report request. This must be `Ok` for the data object in the response to be considered valid. */
          message?: string;
          logs?: {
            data?: components["schemas"]["FlowLogEntry"][];
            /** @description A special metadata object that indicates the relevant response Nexla metadata for the responses. This is useful for iterating through multiple pages of valid data. */
            meta?: {
              /** @description Current page that this response corresponds to. */
              current_page?: number;
              /** @description Total number of valid pages of logs data given the current page size. */
              pages_count?: number;
              /** @description Total number of log entries that are available for this resource. */
              total_count?: number;
              /** @description The id of the organization this flow belongs to. */
              org_id?: number;
              /** @description The run id (denoting ingestion cycle) that these log were generated as part of. */
              run_id?: number;
            };
          };
        };
      };
    };
    /** @description Success */
    quarantine_settings_one: {
      content: {
        "application/json": components["schemas"]["QuarantineSetting"];
      };
    };
    /** @description Success */
    approval_requests_many: {
      content: {
        "application/json": components["schemas"]["ApprovalRequest"][];
      };
    };
    /** @description Success */
    approval_requests_one: {
      content: {
        "application/json": components["schemas"]["ApprovalRequest"];
      };
    };
    /** @description Success */
    accessors_list: {
      content: {
        "application/json": components["schemas"]["AccessorsResponseSchema"][];
      };
    };
    /** @description List of marketplace domains */
    domains_many: {
      content: {
        "application/vnd.nexla.api.v1+json": components["schemas"]["MarketplaceDomain"][];
      };
    };
    /** @description Single marketplace domain */
    domains_one: {
      content: {
        "application/vnd.nexla.api.v1+json": components["schemas"]["MarketplaceDomain"];
      };
    };
    /** @description List of marketplace domain items */
    domain_items_many: {
      content: {
        "application/vnd.nexla.api.v1+json": components["schemas"]["MarketplaceDomainsItem"][];
      };
    };
    /** @description List of custodians */
    custodians_many: {
      content: {
        "application/vnd.nexla.api.v1+json": components["schemas"]["CustodiansResponse"];
      };
    };
    /** @description Success */
    token: {
      content: {
        "application/json": components["schemas"]["Token"];
      };
    };
    /** @description Success */
    auth_configs_many: {
      content: {
        "application/json": components["schemas"]["AuthConfig"][];
      };
    };
    /** @description Success */
    auth_config_one: {
      content: {
        "application/json": components["schemas"]["AuthConfig"];
      };
    };
    /** @description Success */
    self_signup_requests_response: {
      content: {
        "application/json": ({
            /** @description The unique identifier of the self sign up request. */
            id?: number;
            /**
             * @description The status of the self sign up request.
             * @enum {string}
             */
            status?: "pending" | "email_verified" | "approved" | "rejected";
            /** @description The email address of the user. */
            email?: string;
            /** @description The full name of the user. */
            full_name?: string;
            /** @description The unique identifier of the invite. */
            invite_id?: number;
            /**
             * Format: date-time
             * @description The date and time when the self sign up request was created.
             */
            created_at?: string;
            /**
             * Format: date-time
             * @description The date and time when the self sign up request was last updated.
             */
            updated_at?: string;
          })[];
      };
    };
    /** @description Success */
    self_signup_blocked_domains_response: {
      content: {
        "application/json": {
            /** @description The unique identifier of the blocked domain. */
            id?: number;
            /** @description The email domain that is blocked. */
            domain?: string;
          }[];
      };
    };
    /** @description Success */
    auth_settings_many: {
      content: {
        "application/json": components["schemas"]["AuthSetting"][];
      };
    };
    /** @description Success */
    auth_setting_one: {
      content: {
        "application/json": components["schemas"]["AuthSetting"];
      };
    };
    /** @description Success */
    async_tasks_many: {
      content: {
        "application/json": components["schemas"]["AsyncTask"][];
      };
    };
    /** @description Success */
    async_task_one: {
      content: {
        "application/json": components["schemas"]["AsyncTask"];
      };
    };
    /** @description Success */
    runtimes_many: {
      content: {
        "application/json": components["schemas"]["Runtime"][];
      };
    };
    /** @description Success */
    runtimes_one: {
      content: {
        "application/json": components["schemas"]["Runtime"];
      };
    };
    /** @description Success */
    gen_ai_configs_many: {
      content: {
        "application/json": components["schemas"]["GenAiConfig"][];
      };
    };
    /** @description Success */
    gen_ai_configs_one: {
      content: {
        "application/json": components["schemas"]["GenAiConfig"];
      };
    };
    /** @description Success */
    gen_ai_org_settings_many: {
      content: {
        "application/json": components["schemas"]["GenAiOrgSetting"][];
      };
    };
    /** @description Success */
    gen_ai_org_settings_one: {
      content: {
        "application/json": components["schemas"]["GenAiOrgSetting"];
      };
    };
  };
  parameters: {
    access_roles?: "collaborator" | "operator" | "admin" | "owner";
    accept?: "application/vnd.nexla.api.v1+json" | "application/json";
    expand?: 1;
    page?: number;
    per_page?: number;
    size?: number;
  };
  requestBodies: never;
  headers: never;
  pathItems: never;
}

export type $defs = Record<string, never>;

export type external = Record<string, never>;

export interface operations {

  /**
   * Get All Credentials
   * @description Returns all data credentials accessible to the authenticated user.
   */
  get_data_credentials: {
    parameters: {
      query?: {
        access_role?: components["parameters"]["access_roles"];
        /** @description (Optional) Set this to the type of credentials you want to filter by. Connection type or vendor name can be used there. */
        credentials_type?: string;
      };
      header?: {
        Accept?: components["parameters"]["accept"];
      };
    };
    responses: {
      200: components["responses"]["data_credential_many"];
      /** @description Forbidden */
      403: {
        content: never;
      };
      /** @description Not found */
      404: {
        content: never;
      };
    };
  };
  /**
   * Create a Credential
   * @description Creates a Nexla data credential with the specified configuration in your Nexla account.
   *
   * > Note: `name`, `credentials_type`, and `credentials` are required.
   */
  create_data_credential: {
    requestBody?: {
      content: {
        "application/json": {
          credentials_type: "json";
        } & Omit<components["schemas"]["data_credential"], "credentials_type">;
      };
    };
    responses: {
      200: components["responses"]["data_credential_one"];
      /** @description Unauthorized */
      400: {
        content: never;
      };
    };
  };
  /**
   * Get Credential by ID
   * @description Returns a credential object if a valid ID is provided.
   */
  get_data_credential: {
    parameters: {
      header?: {
        Accept?: components["parameters"]["accept"];
      };
      path: {
        /** @description The unique ID of the credential that needs to be fetched. */
        credential_id: number;
      };
    };
    responses: {
      200: components["responses"]["data_credential_one"];
      /** @description Forbidden */
      403: {
        content: never;
      };
      /** @description Not found error */
      404: {
        content: never;
      };
    };
  };
  /**
   * Update Credential
   * @description Updates a data credential in the authenticated user's account.
   *
   * > Note: This method does not perform partial updating of the `credentials` object. The entire `credentials` object will be updated if this is added to the payload.
   */
  update_data_credential: {
    parameters: {
      header?: {
        Accept?: components["parameters"]["accept"];
      };
      path: {
        /** @description The unique ID of the credential that needs to be fetched. */
        credential_id: number;
      };
    };
    requestBody?: {
      content: {
        "application/json": components["schemas"]["data_credential"];
      };
    };
    responses: {
      200: components["responses"]["data_credential_one"];
      /** @description Forbidden */
      403: {
        content: never;
      };
      /** @description Not found error */
      404: {
        content: never;
      };
    };
  };
  /**
   * Delete a Credential
   * @description Deletes a credential from your Nexla account.
   */
  delete_data_credential: {
    parameters: {
      header?: {
        Accept?: components["parameters"]["accept"];
      };
      path: {
        /** @description The unique ID of the credential that needs to be deleted. */
        credential_id: string;
      };
    };
    responses: {
      /** @description Success */
      200: {
        content: {
          "application/json": {
            /** @description Response status code */
            code?: string;
            /** @description Response status text */
            message?: string;
          };
        };
      };
      /** @description Not found error */
      404: {
        content: never;
      };
    };
  };
  /**
   * Get Credential by ID with expanded references
   * @description Returns a credential object along with advanced information about associated references if a valid ID is provided.
   */
  get_data_credential_expanded: {
    parameters: {
      query?: {
        expand?: components["parameters"]["expand"];
      };
      header?: {
        Accept?: components["parameters"]["accept"];
      };
      path: {
        /** @description The unique ID of the credential that needs to be fetched */
        credential_id: number;
      };
    };
    responses: {
      200: components["responses"]["data_credential_one"];
      /** @description Forbidden */
      403: {
        content: never;
      };
      /** @description Not found error */
      404: {
        content: never;
      };
    };
  };
  /**
   * Test credential validity
   * @description Use this endpoint to check whether or not a credential is valid.
   */
  data_credential_probe: {
    parameters: {
      query?: {
        /** @description If set to 'true', request will be executed in a deferred way, and results will be provided later. */
        async?: boolean;
        /** @description The unique ID of the asynchronous request. In case it's provided, returns info about the deferred request. */
        request_id?: number;
      };
      path: {
        /** @description The unique ID of the credential being used. */
        credential_id: number;
      };
    };
    responses: {
      /** @description OK */
      200: {
        content: {
          "application/json": components["schemas"]["probe_response_with_async_results"];
        };
      };
      /** @description Unauthorized */
      401: {
        content: never;
      };
      /** @description Invalid credential */
      403: {
        content: {
          "application/json": {
            /** @enum {integer} */
            status?: 403;
            /** @description Detailed reason for the credential authentication failure. */
            message?: string;
          };
        };
      };
      /** @description Not Found */
      404: {
        content: never;
      };
    };
  };
  /**
   * Preview Storage Structure
   * @description Use this endpoint to preview the structure/hierarchy of storage to which this credential grants access. For example, you can use this endpoint to see the folder and file structure of a file storage system or the table-column structure of a database.
   * This can be used to inspect the directory hierarchy of file content storage or the database schema of a database/warehouse storage system. Note that this endpoint is only valid for credentials for storage systems wherein a storage structure needs to be reviewed.
   */
  preview_storage_structure: {
    parameters: {
      query?: {
        /** @description If set to 'true', request will be executed in a deferred way, and results will be provided later. */
        async?: boolean;
        /** @description The unique ID of the asynchronous request. In case it's provided, returns info about the deferred request. */
        request_id?: number;
      };
      path: {
        /** @description The unique ID of the credential being used. */
        credential_id: number;
      };
    };
    requestBody?: {
      content: {
        "application/json": OneOf<[{
          /**
           * @description Specify the hierarchy depth that should be scanned and returned in the response.
           *
           * If no other payload properties are provided, the depth is relative to the storage root. If this request contains instructions about the slice of storage to be previewed (using the path/database/table properties), the depth will be applied relative to that storage slice.
           *
           * We recommend using a depth = 1 to ensure that only small, relevant slices of the storage system are scanned.
           */
          depth: number;
          /**
           * @description Folder or subfolder path for which you wish to retrieve the content structure. The path string should be structured from the root of the location to the credential. For example, `demo-out.nexla.com/users/test` will return the folder tree for the contents of the `test` subfolder.
           *
           * This is relevant for file-type connectors.
           */
          path?: string;
        }, {
          /**
           * @description Specify the hierarchy depth that should be scanned and returned in the response.
           *
           * If no other payload properties are provided, the depth is relative to the storage root. If this request contains instructions about the slice of storage to be previewed (using the path/database/table properties), the depth will be applied relative to that storage slice.
           *
           * We recommend using a depth = 1 to ensure that only small, relevant slices of storage are scanned.
           */
          depth: number;
          /**
           * @description Name of the database from which you wish to fetch table names or collections.
           *
           * Relevant for Database and NoSql document-type connectors.
           */
          database?: string;
          /**
           * @description Name of the table of which you wish to fetch the column structure.
           *
           * Relevant for database-type connectors.
           */
          table?: string;
        }]>;
      };
    };
    responses: {
      /** @description OK */
      200: {
        content: {
          "application/json": components["schemas"]["probe_tree_with_async"];
        };
      };
      /** @description Unauthorized */
      401: {
        content: never;
      };
      /** @description Not Found */
      404: {
        content: never;
      };
    };
  };
  /**
   * Preview Connector Content
   * @description Use this endpoint to preview the data content in a storage system.
   *
   * 1. For file systems, this can be used to preview the file content of any specific file.
   * 2. For database systems, it can be used to preview sample rows from a table or query result.
   * 3. For the rest connector, it can be used to preview the results of any API request.
   * 4. For streaming connectors, it can be used to preview some records in a topic.
   *
   * For most connectors, it can also be used to determine the type of records that might be detected in the resulting Nexset.
   */
  preview_connector_content: {
    parameters: {
      query?: {
        /** @description If set to 'true', request will be executed in a deferred way, and results will be provided later. */
        async?: boolean;
        /** @description The unique ID of the asynchronous request. In case it's provided, returns info about the deferred request. */
        request_id?: number;
      };
      path: {
        /** @description The unique ID of the credential being used. */
        credential_id: number;
      };
    };
    requestBody?: {
      content: {
        "application/json": OneOf<[{
          /** @description __For file type connectors__: Set the path to the file from which you wish to preview content. */
          path?: string;
        }, {
          [key: string]: string | Record<string, never> | number | unknown[];
        }]>;
      };
    };
    responses: {
      /** @description OK */
      200: {
        content: {
          "application/json": components["schemas"]["probe_sample_with_async"];
        };
      };
      /** @description Unauthorized */
      401: {
        content: never;
      };
      /** @description Not Found */
      404: {
        content: never;
      };
    };
  };
  /**
   * Get All Flows
   * @description Returns all flows accessible to the authenticated user.
   */
  get_flows: {
    parameters: {
      query?: {
        flows_only?: 1;
        include_run_metrics?: 1;
        page?: components["parameters"]["page"];
        per_page?: components["parameters"]["per_page"];
        access_role?: components["parameters"]["access_roles"];
      };
      header?: {
        Accept?: components["parameters"]["accept"];
      };
    };
    responses: {
      200: components["responses"]["FlowsManyWithMetric"];
      /** @description Forbidden */
      403: {
        content: never;
      };
      /** @description Not found */
      404: {
        content: never;
      };
    };
  };
  /**
   * Get Flow by ID
   * @description Returns a flow object if a valid flow ID is provided.
   */
  get_flow_by_id: {
    parameters: {
      query?: {
        flows_only?: 1;
      };
      header?: {
        Accept?: components["parameters"]["accept"];
      };
      path: {
        /** @description The unique ID of the flow that needs to be fetched. */
        flow_id: number;
      };
    };
    responses: {
      200: components["responses"]["FlowsOne"];
      /** @description Forbidden */
      403: {
        content: never;
      };
      /** @description Not found */
      404: {
        content: never;
      };
    };
  };
  /**
   * Delete a Flow
   * @description Deletes a flow from your Nexla account.
   */
  delete_flow: {
    parameters: {
      header?: {
        Accept?: components["parameters"]["accept"];
      };
      path: {
        /** @description The unique ID of the flow that needs to be deleted. */
        flow_id: number;
      };
    };
    responses: {
      /** @description Success */
      200: {
        content: {
          "application/json": {
            /** @description Response status code */
            code?: string;
            /** @description Response status text */
            message?: string;
          };
        };
      };
      /** @description Not found error */
      404: {
        content: never;
      };
    };
  };
  /**
   * Activate a Flow
   * @description To activate the entire flow, use either the `origin_node_id` from any data source, set or sink in the flow, or include the ?all=1 or ?full_tree=1 query parameter.
   *
   * >**Note**:
   * > 1. All endpoints for activating or pausing a flow operate on the specific resource given and all of the flow nodes downstream from that resource. This allows for pausing and activating sub-flows while leaving the rest of the flow state unchanged.
   * >
   * >  2. You can also activate a flow by using the id of the `data_source`/ `data_set` / `data_sink` that the flow node is linked to. See relevant endpoints in the API references for those resources.
   */
  flow_activate_with_flow_id: {
    parameters: {
      header?: {
        Accept?: components["parameters"]["accept"];
      };
      path: {
        /** @description The unique ID of the flow that needs to be activated. */
        flow_id: number;
        /**
         * @description Set this query parameter if the flow node ID you are making a call with is not an origin flow node but you want to activate the full flow chain.
         * Not necessary if the flow node is an origin flow node.
         */
        all: 1;
      };
    };
    responses: {
      200: components["responses"]["FlowsOne"];
      /** @description Forbidden */
      403: {
        content: never;
      };
      /** @description Not found */
      404: {
        content: never;
      };
    };
  };
  /**
   * Pause a Flow
   * @description To pause the entire flow, use either the `origin_node_id` from any data source, set or sink in the flow, or include the ?all=1 or ?full_tree=1 query parameter.
   *
   * >**Note**:
   * > 1. All endpoints for activating or pausing a flow operate on the specific resource given and all of the flow nodes  downstream from that resource. This allows for pausing and activating sub-flows while leaving the rest of the flow state unchanged.
   * >
   * >  2. You can also pause a flow by using the id of the `data_source`/ `data_set` / `data_sink` that the flow node is linked to. See relevant endpoints in the API references for those resources.
   */
  flow_pause_with_flow_id: {
    parameters: {
      query?: {
        /** @description If set to 'true', request will be executed in a deferred way, and results will be provided later. Notice: only works with all=1 or full_tree=1. */
        async?: boolean;
        /** @description The unique ID of the asynchronous request. In case it's provided, returns info about the deferred request. */
        request_id?: number;
      };
      header?: {
        Accept?: components["parameters"]["accept"];
      };
      path: {
        /** @description The unique ID of the flow that needs to be paused. */
        flow_id: number;
        /**
         * @description Set this query parameter if the flow node ID you are making a call with is not an origin flow node but you want to pause the full flow chain.
         * Not necessary if the flow node is an origin flow node.
         */
        all: 1;
      };
    };
    responses: {
      /** @description OK */
      200: {
        content: {
          "application/json": components["schemas"]["flow_one_with_async"];
        };
      };
      /** @description Forbidden */
      403: {
        content: never;
      };
      /** @description Not found */
      404: {
        content: never;
      };
    };
  };
  /**
   * Copy a Flow
   * @description Use this endpoint to create a copy of an existing flow.
   */
  flow_copy_with_flow_id: {
    parameters: {
      path: {
        /** @description The unique ID of the flow that needs to be paused. */
        flow_id: number;
      };
    };
    requestBody?: {
      content: {
        "application/vnd.nexla.api.v1+json": {
          /** @description Set this to `true` if you do want to reuse the credentials of this flow instead of creating a clone of the credentials also. */
          reuse_data_credentials?: boolean;
          /** @description Set this to `true` if you want the new flow to be accessible by all users who have access to the this flow. */
          copy_access_controls?: boolean;
          /** @description This is relevant for flows where one or more destinations have sources as their children. Set this to `true` if you want to create a clone of the flows that originate from those sources also. */
          copy_dependent_data_flows?: boolean;
          /** @description The default API behavior is to create the new flow in the account of the authenticated user making this call. Set this property if you want a different user to be the owner of the new flow. */
          owner_id?: number;
          /** @description The default API behavior is to create the new flow in the org that the authenticated user making this call belongs to. Set this property if you want the flow to be created in a different org. */
          org_id?: number;
        };
      };
    };
    responses: {
      200: components["responses"]["FlowsOne"];
      /** @description Forbidden */
      403: {
        content: never;
      };
      /** @description Not found */
      404: {
        content: never;
      };
    };
  };
  /**
   * Generate an AI suggestion for flow documentation
   * @description Request a suggestion for Flow documentation. GenAI has to be configured properly for this request, or else you get a message with an error.
   */
  flow_docs_recommendation: {
    parameters: {
      header?: {
        Accept?: components["parameters"]["accept"];
      };
      path: {
        /** @description The unique ID of the flow */
        flow_id: number;
      };
    };
    responses: {
      200: components["responses"]["genai_recommendation_response"];
      /** @description Unauthorized */
      401: {
        content: never;
      };
      /** @description Forbidden */
      403: {
        content: never;
      };
      /** @description Not Found */
      404: {
        content: never;
      };
    };
  };
  /**
   * Get Flow (by Resource ID)
   * @description Returns a flow object if a valid resource type and resource ID is provided.
   *
   * > Note: This is a variant of flow endpoints where the flow node can referenced not by its own ID, but by the ID of the unique resource that is linked to that flow node.
   */
  get_flow_by_resource_id: {
    parameters: {
      query?: {
        flows_only?: 1;
      };
      header?: {
        Accept?: components["parameters"]["accept"];
      };
      path: {
        /** @description The type of node linked to the flow you want to reference. For ex, set this to `data_sources` if you want to refer to the flow originating in a `data_source`. */
        resource_type: "data_sources" | "data_sinks" | "data_sets";
        /** @description The unique id of the resource whose flow you want to reference.  For ex, set this to id of the `data_source` if you want to refer to the flow originating in a specific `data_source`. */
        resource_id: number;
      };
    };
    responses: {
      200: components["responses"]["FlowsOne"];
      /** @description Forbidden */
      403: {
        content: never;
      };
      /** @description Not found */
      404: {
        content: never;
      };
    };
  };
  /**
   * Delete a Flow (by Resource ID)
   * @description Deletes a flow from your Nexla account.
   *
   * > Note: This is a variant of flow endpoints where the flow node can referenced not by its own ID, but by the ID of the unique resource that is linked to that flow node.
   */
  delete_flow_by_resource_id: {
    parameters: {
      header?: {
        Accept?: components["parameters"]["accept"];
      };
      path: {
        /** @description The type of node linked to the flow you want to reference. For ex, set this to `data_sources` if you want to refer to the flow originating in a `data_source`. */
        resource_type: "data_sources" | "data_sinks" | "data_sets";
        /** @description The unique id of the resource whose flow you want to reference.  For ex, set this to id of the `data_source` if you want to refer to the flow originating in a specific `data_source`. */
        resource_id: number;
      };
    };
    responses: {
      /** @description Success */
      200: {
        content: {
          "application/json": {
            /** @description Response status code */
            code?: string;
            /** @description Response status text */
            message?: string;
          };
        };
      };
      /** @description Not found error */
      404: {
        content: never;
      };
    };
  };
  /**
   * Activate a Flow (with Resource ID)
   * @description To activate the entire flow include the ?all=1 or ?full_tree=1 query parameter.
   *
   * >**Note**:
   * > 1. All endpoints for activating or pausing a flow operate on the specific resource given and all of the flow nodes downstream from that resource. This allows for pausing and activating sub-flows while leaving the rest of the flow state unchanged.
   * > 2. This is a variant of flow endpoints where the flow node can referenced not by its own ID, but by the ID of the unique resource that is linked to that flow node.
   */
  flow_activate_with_resource_id: {
    parameters: {
      header?: {
        Accept?: components["parameters"]["accept"];
      };
      path: {
        /** @description The type of node linked to the flow you want to reference. For ex, set this to `data_sources` if you want to refer to the flow originating in a `data_source`. */
        resource_type: "data_sources" | "data_sinks" | "data_sets";
        /** @description The unique id of the resource whose flow you want to reference.  For ex, set this to id of the `data_source` if you want to refer to the flow originating in a specific `data_source`. */
        resource_id: number;
        /**
         * @description Set this query parameter if the resource ID you are making a call with is not an origin flow node but you want to activate the full flow chain.
         * Not necessary if the flow node is an origin flow node.
         */
        all: 1;
      };
    };
    responses: {
      200: components["responses"]["FlowsOne"];
      /** @description Forbidden */
      403: {
        content: never;
      };
      /** @description Not found */
      404: {
        content: never;
      };
    };
  };
  /**
   * Pause a Flow (with Resource ID)
   * @description To pause the entire flow include the entire flow include the ?all=1 or ?full_tree=1 query parameter.
   *
   * >**Note**:
   * > 1. All endpoints for activating or pausing a flow operate on the specific resource given and all of the flow nodes  downstream from that resource. This allows for pausing and activating sub-flows while leaving the rest of the flow state unchanged.
   * >
   * > 2. This is a variant of flow endpoints where the flow node can referenced not by its own ID, but by the ID of the unique resource that is linked to that flow node.
   */
  flow_pause_with_resource_id: {
    parameters: {
      header?: {
        Accept?: components["parameters"]["accept"];
      };
      path: {
        /** @description The type of node linked to the flow you want to reference. For ex, set this to `data_sources` if you want to refer to the flow originating in a `data_source`. */
        resource_type: "data_sources" | "data_sinks" | "data_sets";
        /** @description The unique id of the resource whose flow you want to reference.  For ex, set this to id of the `data_source` if you want to refer to the flow originating in a specific `data_source`. */
        resource_id: number;
        /**
         * @description Set this query parameter if the flow node ID you are making a call with is not an origin flow node but you want to pause the full flow chain.
         * Not necessary if the flow node is an origin flow node.
         */
        all: 1;
      };
    };
    responses: {
      200: components["responses"]["FlowsOne"];
      /** @description Forbidden */
      403: {
        content: never;
      };
      /** @description Not found */
      404: {
        content: never;
      };
    };
  };
  /**
   * Get All Sources
   * @description Returns all data sources accessible to the authenticated user.
   */
  get_data_sources: {
    parameters: {
      query?: {
        access_role?: components["parameters"]["access_roles"];
      };
      header?: {
        Accept?: components["parameters"]["accept"];
      };
    };
    responses: {
      200: components["responses"]["data_source_many"];
      /** @description Forbidden */
      403: {
        content: never;
      };
      /** @description Not found */
      404: {
        content: never;
      };
    };
  };
  /**
   * Create a Source
   * @description Creates a new data source in the authenticated user's account.
   *
   * Depending on the type of source you want to create (`source_type`), properties like `source_config` and `data_credentials_id` will require appropriate configuration.
   *
   * > Note: `name`, `source_type`, `source_config` and `data_credentials_id` are required.
   */
  create_data_source: {
    requestBody?: {
      content: {
        "application/json": {
          source_type: "json";
        } & Omit<components["schemas"]["data_source"], "source_type">;
      };
    };
    responses: {
      200: components["responses"]["data_source_one"];
      /** @description Unauthorized */
      400: {
        content: never;
      };
    };
  };
  /**
   * Get Source by ID
   * @description Returns a source object if a valid ID is provided.
   */
  get_data_source: {
    parameters: {
      query?: {
        expand?: components["parameters"]["expand"];
      };
      header?: {
        Accept?: components["parameters"]["accept"];
      };
      path: {
        /** @description The unique ID of the source that needs to be fetched. */
        source_id: number;
      };
    };
    responses: {
      200: components["responses"]["data_source_one"];
      /** @description Forbidden */
      403: {
        content: never;
      };
      /** @description Not found */
      404: {
        content: never;
      };
    };
  };
  /**
   * Update a Source
   * @description Updates a data source in the authenticated user's account.
   *
   * Depending on the type of source you want to update (`source_type`), properties like `source_config` and `data_credentials_id` will require appropriate configuration.
   *
   * > Note: This method does not perform partial updating of `source_config`. The entire `source_config` object will be updated if this is added to the payload.
   */
  update_data_source: {
    parameters: {
      path: {
        /** @description The unique ID of the source that needs to be updated. */
        source_id: number;
      };
    };
    requestBody?: {
      content: {
        "application/json": components["schemas"]["data_source"];
      };
    };
    responses: {
      200: components["responses"]["data_source_one"];
      /** @description Unauthorized */
      400: {
        content: never;
      };
    };
  };
  /**
   * Delete a Source
   * @description Deletes a source from your Nexla account.
   */
  delete_data_source: {
    parameters: {
      header?: {
        Accept?: components["parameters"]["accept"];
      };
      path: {
        /** @description The unique ID of the source that needs to be deleted. */
        source_id: string;
      };
    };
    responses: {
      /** @description Success */
      200: {
        content: {
          "application/json": {
            /** @description Response status code */
            code?: string;
            /** @description Response status text */
            message?: string;
          };
        };
      };
      /** @description Not found error */
      404: {
        content: never;
      };
    };
  };
  /**
   * Get Source by ID with Expanded References
   * @description Returns a source object along with advanced information about associated references if a valid ID is provided.
   */
  get_data_source_expanded: {
    parameters: {
      query?: {
        expand?: components["parameters"]["expand"];
      };
      header?: {
        Accept?: components["parameters"]["accept"];
      };
      path: {
        /** @description The unique ID of the source that needs to be fetched */
        source_id: number;
      };
    };
    responses: {
      200: components["responses"]["data_source_one_expand"];
      /** @description Forbidden */
      403: {
        content: never;
      };
      /** @description Not found */
      404: {
        content: never;
      };
    };
  };
  /**
   * Activate a Source
   * @description Activate a paused data source.
   */
  activate_source: {
    parameters: {
      header?: {
        Accept?: components["parameters"]["accept"];
      };
      path: {
        /** @description The unique ID of the source that needs to be activated. */
        source_id: number;
      };
    };
    responses: {
      200: components["responses"]["data_source_one"];
      /** @description Forbidden */
      403: {
        content: never;
      };
      /** @description Not found */
      404: {
        content: never;
      };
    };
  };
  /**
   * Pause a Source
   * @description Pause an active data source.
   */
  pause_source: {
    parameters: {
      header?: {
        Accept?: components["parameters"]["accept"];
      };
      path: {
        /** @description The unique ID of the source that needs to be paused. */
        source_id: number;
      };
    };
    responses: {
      200: components["responses"]["data_source_one"];
      /** @description Forbidden */
      403: {
        content: never;
      };
      /** @description Not found */
      404: {
        content: never;
      };
    };
  };
  /**
   * Copy a Source
   * @description Use this endpoint to create a copy of an existing flow.
   */
  copy_source: {
    parameters: {
      path: {
        /** @description The unique ID of the source that needs to be copied. */
        source_id: number;
      };
    };
    requestBody?: {
      content: {
        "application/vnd.nexla.api.v1+json": {
          /** @description Set this to `true` if you do want to reuse the credentials of this source instead of creating a clone of the credentials also. */
          reuse_data_credentials?: boolean;
          /** @description Set this to `true` if you want the new source to be accessible by all users who have access to the this sink. */
          copy_access_controls?: boolean;
          /** @description The default API behavior is to create the new source in the account of the authenticated user making this call. Set this property if you want a different user to be the owner of the new source. */
          owner_id?: number;
          /** @description The default API behavior is to create the new source in the org that the authenticated user making this call belongs to. Set this property if you want the source to be created in a different org. */
          org_id?: number;
        };
      };
    };
    responses: {
      200: components["responses"]["data_source_one"];
      /** @description Forbidden */
      403: {
        content: never;
      };
      /** @description Not found */
      404: {
        content: never;
      };
    };
  };
  /**
   * Get All Nexsets
   * @description Retrieves all Nexsets accessible to the authenticated user.
   */
  get_nexsets: {
    parameters: {
      query?: {
        access_role?: components["parameters"]["access_roles"];
      };
      header?: {
        Accept?: components["parameters"]["accept"];
      };
    };
    responses: {
      200: components["responses"]["data_sets_many"];
      /** @description Unauthorized */
      401: {
        content: never;
      };
    };
  };
  /**
   * Create a Nexset
   * @description Creates a Nexset from another Nexset.
   *
   * The endpoint accepts a parent Nexset ID along with all transform and validation rules that should be applied to the parent Nexset.
   *
   * The two payload variants reflect the following two ways of specifying transform rules:
   * 1. Attach the transform code that should be applied: Set `has_custom_transform: false`, and attach a `transform` code snippet.
   * 2. Use the ID of a reusable record transform: Set `has_custom_transform: false`, and attach the `transform_id` of the record transform to be applied.
   */
  create_nexset: {
    requestBody?: {
      content: {
        "application/vnd.nexla.api.v1+json": components["schemas"]["DataSetCreate"];
      };
    };
    responses: {
      200: components["responses"]["data_sets_one"];
      /** @description Bad Request */
      400: {
        content: never;
      };
      /** @description Unauthorized */
      401: {
        content: never;
      };
      /** @description Forbidden */
      403: {
        content: never;
      };
    };
  };
  /**
   * Get a Nexset
   * @description Returns a Nexset object if a valid ID is provided.
   */
  get_nexset: {
    parameters: {
      query?: {
        expand?: components["parameters"]["expand"];
      };
      header?: {
        Accept?: components["parameters"]["accept"];
      };
      path: {
        /** @description The unique ID of the Nexset that needs to be fetched. */
        set_id: number;
      };
    };
    responses: {
      200: components["responses"]["data_sets_one"];
      /** @description Forbidden */
      403: {
        content: never;
      };
      /** @description Not found */
      404: {
        content: never;
      };
    };
  };
  /**
   * Update a Nexset
   * @description Updates a Nexset in the authenticated user's account.
   */
  update_nexset: {
    parameters: {
      header?: {
        Accept?: components["parameters"]["accept"];
      };
      path: {
        /** @description The unique ID of the Nexset to be updated. */
        set_id: number;
      };
    };
    requestBody?: {
      content: {
        "application/vnd.nexla.api.v1+json": components["schemas"]["DataSetMutable"];
      };
    };
    responses: {
      200: components["responses"]["data_sets_one"];
      /** @description Unauthorized */
      401: {
        content: never;
      };
      /** @description Forbidden */
      403: {
        content: never;
      };
      /** @description Not Found */
      404: {
        content: never;
      };
    };
  };
  /**
   * Delete a Nexset
   * @description Deletes a Nexset from the authenticated user's account.
   */
  delete_nexset: {
    parameters: {
      header?: {
        Accept?: components["parameters"]["accept"];
      };
      path: {
        /** @description The unique ID of the Nexset that needs to be deleted. */
        set_id: string;
      };
    };
    responses: {
      /** @description Success */
      200: {
        content: never;
      };
      /** @description Unauthorized */
      401: {
        content: never;
      };
      /** @description Forbidden */
      403: {
        content: never;
      };
      /** @description Not Found */
      404: {
        content: never;
      };
    };
  };
  /**
   * Activate Nexset
   * @description Activates a paused Nexset.
   */
  activate_nexset: {
    parameters: {
      header?: {
        Accept?: components["parameters"]["accept"];
      };
      path: {
        /** @description The unique ID of the Nexset that needs to be activated. */
        set_id: number;
      };
    };
    responses: {
      200: components["responses"]["data_sets_one"];
      /** @description Unauthorized */
      401: {
        content: never;
      };
      /** @description Forbidden */
      403: {
        content: never;
      };
      /** @description Not Found */
      404: {
        content: never;
      };
    };
  };
  /**
   * Pause Nexset
   * @description Pauses an active Nexset.
   */
  pause_nexset: {
    parameters: {
      header?: {
        Accept?: components["parameters"]["accept"];
      };
      path: {
        /** @description The unique ID of the Nexset that needs to be paused. */
        set_id: number;
      };
    };
    responses: {
      200: components["responses"]["data_sets_one"];
      /** @description Unauthorized */
      401: {
        content: never;
      };
      /** @description Forbidden */
      403: {
        content: never;
      };
      /** @description Not Found */
      404: {
        content: never;
      };
    };
  };
  /**
   * Copy Nexset
   * @description Use this endpoint to create a clone of an existing Nexset.
   */
  copy_nexset: {
    parameters: {
      header?: {
        Accept?: components["parameters"]["accept"];
      };
      path: {
        /** @description The unique ID of the Nexset that needs to be copied. */
        set_id: number;
      };
    };
    requestBody?: {
      content: {
        "application/vnd.nexla.api.v1+json": {
          /** @description Set this to `true` if you want the new Nexset to be accessible by all users who have access to the this Nexset. */
          copy_access_controls?: boolean;
          /** @description The default API behavior is to create the new Nexset in the account of the authenticated user making this call. Set this property if you want a different user to be the owner of the new Nexset. */
          owner_id?: number;
          /** @description The default API behavior is to create the new Nexset in the org that the authenticated user making this call belongs to. Set this property if you want the Nexset to be created in a different org. */
          org_id?: number;
        };
      };
    };
    responses: {
      200: components["responses"]["data_sets_one"];
      /** @description Unauthorized */
      401: {
        content: never;
      };
      /** @description Forbidden */
      403: {
        content: never;
      };
      /** @description Not Found */
      404: {
        content: never;
      };
    };
  };
  /**
   * Get Nexset Samples
   * @description Use this endpoint to fetch some sample records from this Nexset. Use the relevant query parameters to control whether the samples returned are from the live Nexset topic or the Nexset sample cache.
   */
  get_nexset_samples: {
    parameters: {
      query?: {
        /** @description The maximum number of samples that should be returned in the response. */
        count?: number;
        /** @description Set this to true to fetch Nexla metadata about each sample record along with the record content. */
        include_metadata?: boolean;
        /** @description Set this to true to fetch live sample records from the Nexset topic. */
        live?: boolean;
      };
      header?: {
        Accept?: components["parameters"]["accept"];
      };
      path: {
        /** @description The unique ID of the Nexset that needs to be fetched. */
        set_id: number;
      };
    };
    responses: {
      200: components["responses"]["data_sets_sample"];
      /** @description Unauthorized */
      401: {
        content: never;
      };
      /** @description Forbidden */
      403: {
        content: never;
      };
      /** @description Not Found */
      404: {
        content: never;
      };
    };
  };
  /**
   * Generate an AI suggestion for Nexset documentation
   * @description Request a suggestion for Nexset documentation. GenAI has to be configured properly for this request, or else you get a message with an error.
   */
  data_set_docs_recommendation: {
    parameters: {
      header?: {
        Accept?: components["parameters"]["accept"];
      };
      path: {
        /** @description The unique ID of the Nexset that needs to be activated. */
        set_id: number;
      };
    };
    responses: {
      200: components["responses"]["genai_recommendation_response"];
      /** @description Unauthorized */
      401: {
        content: never;
      };
      /** @description Forbidden */
      403: {
        content: never;
      };
      /** @description Not Found */
      404: {
        content: never;
      };
    };
  };
  /**
   * Get All Sinks
   * @description Retrieves all data sinks accessible to the authenticated user.
   */
  get_data_sinks: {
    parameters: {
      query?: {
        access_role?: components["parameters"]["access_roles"];
      };
      header?: {
        Accept?: components["parameters"]["accept"];
      };
    };
    responses: {
      200: components["responses"]["data_sink_many"];
      /** @description Forbidden */
      403: {
        content: never;
      };
      /** @description Not found */
      404: {
        content: never;
      };
    };
  };
  /**
   * Create a Sink
   * @description Creates a Nexla data_sink with the specified configuration in your Nexla account.
   *
   * > Note: `name` ,`data_set_id`, `sink_type`, `sink_config` and `data_credentials_id` are required.
   */
  create_data_sink: {
    requestBody?: {
      content: {
        "application/json": {
          sink_type: "json";
        } & Omit<components["schemas"]["data_sink"], "sink_type">;
      };
    };
    responses: {
      200: components["responses"]["data_sink_one"];
      /** @description Unauthorized */
      400: {
        content: never;
      };
    };
  };
  /**
   * Get Sink by ID
   * @description Returns a data_sink object if a valid ID is provided.
   */
  get_data_sink: {
    parameters: {
      header?: {
        Accept?: components["parameters"]["accept"];
      };
      path: {
        /** @description The unique ID of the sink that needs to be fetched. */
        sink_id: number;
      };
    };
    responses: {
      200: components["responses"]["data_sink_one"];
      /** @description Forbidden */
      403: {
        content: never;
      };
      /** @description Not found error */
      404: {
        content: never;
      };
    };
  };
  /**
   * Update Sink
   * @description Updates a data_sink object in the authenticated user's account.
   *
   * > Note: This method does not perform partial updating of the `sink_config` object. The entire `sink_config` object will be updated if this is added to the payload.
   */
  update_data_sink: {
    parameters: {
      header?: {
        Accept?: components["parameters"]["accept"];
      };
      path: {
        /** @description The unique ID of the sink that needs to be fetched. */
        sink_id: number;
      };
    };
    requestBody?: {
      content: {
        "application/json": components["schemas"]["data_sink"];
      };
    };
    responses: {
      200: components["responses"]["data_sink_one"];
      /** @description Forbidden */
      403: {
        content: never;
      };
      /** @description Not found error */
      404: {
        content: never;
      };
    };
  };
  /**
   * Delete a Sink
   * @description Deletes a sink from your Nexla account.
   */
  delete_data_sink: {
    parameters: {
      header?: {
        Accept?: components["parameters"]["accept"];
      };
      path: {
        /** @description The unique ID of the sink that needs to be deleted. */
        sink_id: string;
      };
    };
    responses: {
      /** @description Success */
      200: {
        content: {
          "application/json": {
            /** @description Response status code */
            code?: string;
            /** @description Response status text */
            message?: string;
          };
        };
      };
      /** @description Not found error */
      404: {
        content: never;
      };
    };
  };
  /**
   * Get Sink by ID with Expanded References
   * @description Returns a data_sink object along with advanced information about associated references if a valid ID is provided.
   */
  get_data_sink_expanded: {
    parameters: {
      query?: {
        expand?: components["parameters"]["expand"];
      };
      header?: {
        Accept?: components["parameters"]["accept"];
      };
      path: {
        /** @description The unique ID of the sink that needs to be fetched. */
        sink_id: number;
      };
    };
    responses: {
      200: components["responses"]["data_sink_one_expand"];
      /** @description Forbidden */
      403: {
        content: never;
      };
      /** @description Not found error */
      404: {
        content: never;
      };
    };
  };
  /**
   * Activate a Sink
   * @description Activate a paused data sink.
   */
  activate_data_sink: {
    parameters: {
      header?: {
        Accept?: components["parameters"]["accept"];
      };
      path: {
        /** @description The unique ID of the sink that needs to be activated. */
        sink_id: number;
      };
    };
    responses: {
      200: components["responses"]["data_sink_one"];
      /** @description Forbidden */
      403: {
        content: never;
      };
      /** @description Not found */
      404: {
        content: never;
      };
    };
  };
  /**
   * Pause a Sink
   * @description Pause an active data sink.
   */
  pause_data_sink: {
    parameters: {
      header?: {
        Accept?: components["parameters"]["accept"];
      };
      path: {
        /** @description The unique ID of the sink that needs to be paused. */
        sink_id: number;
      };
    };
    responses: {
      200: components["responses"]["data_sink_one"];
      /** @description Forbidden */
      403: {
        content: never;
      };
      /** @description Not found */
      404: {
        content: never;
      };
    };
  };
  /**
   * Copy a Sink
   * @description Use this endpoint to create a copy of an existing data sink.
   */
  copy_data_sink_source: {
    parameters: {
      path: {
        /** @description The unique ID of the sink that needs to be copied. */
        sink_id: number;
      };
    };
    requestBody?: {
      content: {
        "application/vnd.nexla.api.v1+json": {
          /** @description Set this to `true` if you do want to reuse the credentials of this sink instead of creating a clone of the credentials also. */
          reuse_data_credentials?: boolean;
          /** @description Set this to `true` if you want the new sink to be accessible by all users who have access to the this sink. */
          copy_access_controls?: boolean;
          /** @description The default API behavior is to create the new sink in the account of the authenticated user making this call. Set this property if you want a different user to be the owner of the new sink. */
          owner_id?: number;
          /** @description The default API behavior is to create the new sink in the org that the authenticated user making this call belongs to. Set this property if you want the sink to be created in a different org. */
          org_id?: number;
        };
      };
    };
    responses: {
      200: components["responses"]["data_sink_one"];
      /** @description Forbidden */
      403: {
        content: never;
      };
      /** @description Not found */
      404: {
        content: never;
      };
    };
  };
  /**
   * Get all Data Maps
   * @description Retrieves all lookups (data maps) accessible to the authenticated user.
   */
  get_data_maps: {
    parameters: {
      query?: {
        access_role?: components["parameters"]["access_roles"];
      };
      header?: {
        Accept?: components["parameters"]["accept"];
      };
    };
    responses: {
      200: components["responses"]["data_maps_many"];
      /** @description Forbidden */
      403: {
        content: never;
      };
    };
  };
  /**
   * Create a Static Data Map
   * @description Creates a new static data map in the authenticated user's account. Dynamic data maps can only be created by creating a Destination (Sink) of the type `data_map`.
   *
   * For statically assigned data maps, you can choose to add data rows to the data map by either of the following methods:
   * 1. Send data map entries with this request. In this case, the rows of data are sent as a `data_map` array of objects.
   * 2. Send data map entries as a separate call to add/update entries.
   *
   * You must include `map_primary_key` to specify which map attribute should be used for data matching.
   */
  create_static_data_map: {
    requestBody?: {
      content: {
        "application/json": components["schemas"]["DataMapCreate"];
      };
    };
    responses: {
      200: components["responses"]["data_maps_one"];
      /** @description Unauthorized */
      401: {
        content: never;
      };
      /** @description Forbidden */
      403: {
        content: never;
      };
    };
  };
  /**
   * Get Data Map by ID
   * @description Retrieves a data map object if a valid ID is provided.
   *
   * This call to `/data_maps` **does not** return data map entries, as they can be a large array of objects for big data maps.
   *
   * You can include the `expand` query parameter to fetch the data map entries of smaller static data maps.
   */
  get_data_map: {
    parameters: {
      query?: {
        expand?: components["parameters"]["expand"];
      };
      header?: {
        Accept?: components["parameters"]["accept"];
      };
      path: {
        /** @description The unique ID of the data map that needs to be fetched. */
        data_map_id: number;
      };
    };
    responses: {
      200: components["responses"]["data_maps_one"];
      /** @description Unauthorized */
      401: {
        content: never;
      };
      /** @description Forbidden */
      403: {
        content: never;
      };
      /** @description Not Found */
      404: {
        content: never;
      };
    };
  };
  /**
   * Update Data Map Metadata
   * @description Updates a data map in the authenticated user's account.
   *
   * This endpoint is suitable for updating the metadata of a data map. We recommend using the data map entries update and delete endpoints to update data map rows.
   */
  update_data_map_metadata: {
    parameters: {
      header?: {
        Accept?: components["parameters"]["accept"];
      };
      path: {
        /** @description The unique ID of the data map that needs to be updated. */
        data_map_id: number;
      };
    };
    requestBody?: {
      content: {
        "application/json": components["schemas"]["DataMapMutable"];
      };
    };
    responses: {
      200: components["responses"]["data_maps_one"];
      /** @description Unauthorized */
      401: {
        content: never;
      };
      /** @description Forbidden */
      403: {
        content: never;
      };
      /** @description Not Found */
      404: {
        content: never;
      };
    };
  };
  /**
   * Delete a Data Map
   * @description Deletes a data map from your Nexla account.
   */
  delete_data_map: {
    parameters: {
      header?: {
        Accept?: components["parameters"]["accept"];
      };
      path: {
        /** @description The unique ID of the data map that needs to be deleted. */
        data_map_id: number;
      };
    };
    responses: {
      /** @description Success */
      200: {
        content: {
          "application/json": {
            /** @description Response status code */
            code?: string;
            /** @description Response status text */
            message?: string;
          };
        };
      };
      /** @description Unauthorized */
      401: {
        content: never;
      };
      /** @description Forbidden */
      403: {
        content: never;
      };
      /** @description Not Found */
      404: {
        content: never;
      };
    };
  };
  /**
   * Upsert Static Data Map Entries
   * @description Updates the entries in a static data map. Use this endpoint to add new entries or update the row corresponding to a specific key.
   */
  upsert_data_map_entries: {
    parameters: {
      header?: {
        Accept?: components["parameters"]["accept"];
      };
      path: {
        /** @description The unique ID of the data map that needs to be updated. */
        data_map_id: number;
      };
    };
    requestBody?: {
      content: {
        "application/json": {
          /** @description Enter the array of data map entries that you wish to upsert. This call will result in an upsert on the data map, i.e., new rows will be added for keys not present in the data map, and relevant rows will be updated for keys that are already present. */
          entries?: ({
              [key: string]: string | number;
            })[];
        };
      };
    };
    responses: {
      200: components["responses"]["data_map_entries"];
      /** @description Unauthorized */
      401: {
        content: never;
      };
      /** @description Forbidden */
      403: {
        content: never;
      };
      /** @description Not Found */
      404: {
        content: never;
      };
    };
  };
  /**
   * Check Data Map Entries
   * @description Returns the rows of data from the data map that matches a desired key or key pattern.
   *
   * This endpoint can be used to check whether the data map contains rows of data that match the desired key, keys, or key patterns. Key names should be provided in the path in the format described below.
   */
  check_data_map_entries: {
    parameters: {
      header?: {
        Accept?: components["parameters"]["accept"];
      };
      path: {
        /** @description The unique ID of the data map that needs to be fetched. */
        data_map_id: number;
        /** @description One or more comma-separated keys for accessing data map entries. These keys may contain simple matching expressions with `*` wildcard characters. The response will contain entries whose primary key values match the pattern. */
        entry_keys: string | number;
      };
    };
    responses: {
      200: components["responses"]["data_map_entries"];
      /** @description Unauthorized */
      401: {
        content: never;
      };
      /** @description Forbidden */
      403: {
        content: never;
      };
      /** @description Not Found */
      404: {
        content: never;
      };
    };
  };
  /**
   * Delete Data Map Entries
   * @description Deletes specific entries from the data map.
   *
   * Use this endpoint to remove specific entries from the data map.
   */
  delete_data_map_entries: {
    parameters: {
      header?: {
        Accept?: components["parameters"]["accept"];
      };
      path: {
        /** @description The unique ID of the data map that needs to be fetched. */
        data_map_id: number;
        /** @description One or more comma-separated keys for accessing access data map entries. These keys may contain simple matching expressions with `*` wildcard characters. */
        entry_keys: string | number;
      };
    };
    responses: {
      /** @description OK */
      200: {
        content: never;
      };
      /** @description Unauthorized */
      401: {
        content: never;
      };
      /** @description Forbidden */
      403: {
        content: never;
      };
      /** @description Not Found */
      404: {
        content: never;
      };
    };
  };
  /**
   * Get all Reusable Record Transforms
   * @description Reusable record transforms are reusable code blocks that can be used to modify an input record of a Nexset into an output record of that Nexset.
   * Use this endpoint to fetch all reusable record transforms.
   */
  get_reusable_record_transforms: {
    parameters: {
      header?: {
        Accept?: components["parameters"]["accept"];
      };
    };
    responses: {
      200: components["responses"]["Transform"];
      /** @description Forbidden */
      403: {
        content: never;
      };
    };
  };
  /**
   * Create a Reusable Record Transform
   * @description Create a new reusable record transform.
   */
  create_reusable_record_transform: {
    requestBody?: {
      content: {
        "application/json": components["schemas"]["TransformMutable"];
      };
    };
    responses: {
      200: components["responses"]["code_containers_one_Transform"];
      /** @description Unauthorized */
      401: {
        content: never;
      };
      /** @description Forbidden */
      403: {
        content: never;
      };
    };
  };
  /**
   * Get A Reusable Record Transform
   * @description Returns a reusable record transform object if a valid ID is provided.
   */
  get_reusable_record_transform: {
    parameters: {
      header?: {
        Accept?: components["parameters"]["accept"];
      };
      path: {
        /** @description The unique ID of the transform that needs to be fetched. */
        transform_id: number;
      };
    };
    responses: {
      200: components["responses"]["code_containers_one_Transform"];
      /** @description Unauthorized */
      401: {
        content: never;
      };
      /** @description Forbidden */
      403: {
        content: never;
      };
      /** @description Not found */
      404: {
        content: never;
      };
    };
  };
  /**
   * Update Reusable Record Transform
   * @description Updates a transform in the authenticated user's account.
   */
  update_reusable_record_transform: {
    parameters: {
      header?: {
        Accept?: components["parameters"]["accept"];
      };
      path: {
        /** @description The unique ID of the transform that needs to be updated. */
        transform_id: number;
      };
    };
    requestBody?: {
      content: {
        "application/json": components["schemas"]["CodeContainerMutable"];
      };
    };
    responses: {
      200: components["responses"]["CodeContainer"];
      /** @description Unauthorized */
      401: {
        content: never;
      };
      /** @description Forbidden */
      403: {
        content: never;
      };
      /** @description Not found */
      404: {
        content: never;
      };
    };
  };
  /**
   * Delete a Reusable Record Transform
   * @description Use this endpoint to delete a reusable record transform.
   */
  delete_reusable_record_transform: {
    parameters: {
      header?: {
        Accept?: components["parameters"]["accept"];
      };
      path: {
        /** @description The unique ID of the transform that needs to be deleted. */
        transform_id: number;
      };
    };
    responses: {
      /** @description Success */
      200: {
        content: {
          "application/json": {
            /** @description Response status code */
            code?: string;
            /** @description Response status text */
            message?: string;
          };
        };
      };
      /** @description Unauthorized */
      401: {
        content: never;
      };
      /** @description Forbidden */
      403: {
        content: never;
      };
      /** @description Not found */
      404: {
        content: never;
      };
    };
  };
  /**
   * Copy a Reusable Record Transform
   * @description Use this endpoint to create a copy of an existing reusable record transform.
   */
  copy_transform: {
    parameters: {
      header?: {
        Accept?: components["parameters"]["accept"];
      };
      path: {
        /** @description The unique ID of the transform to be copied. */
        transform_id: number;
      };
    };
    responses: {
      200: components["responses"]["code_containers_one_Transform"];
      /** @description Unauthorized */
      401: {
        content: never;
      };
      /** @description Forbidden */
      403: {
        content: never;
      };
      /** @description Not Found */
      404: {
        content: never;
      };
    };
  };
  /**
   * Get all Public Reusable Record Transforms
   * @description The Nexla team regularly adds common reusable record transforms that are made available to all Nexla accounts.
   *
   * Use this endpoint to fetch all such "publicly" available reusable record transforms.
   */
  get_public_reusable_record_transforms: {
    parameters: {
      header?: {
        Accept?: components["parameters"]["accept"];
      };
    };
    responses: {
      200: components["responses"]["Transform"];
      /** @description Unauthorized */
      401: {
        content: never;
      };
      /** @description Forbidden */
      403: {
        content: never;
      };
    };
  };
  /**
   * Get all Attribute Transforms
   * @description Reusable attribute transforms are reusable code blocks that can be used to define the value of an output attribute in a Nexset. These code blocks can be used to enhance the set of transforms available to end users when using the Nexset Designer.
   *
   * Use this endpoint to fetch all attribute transforms accessible to the authenticated user.
   */
  get_attribute_transforms: {
    parameters: {
      header?: {
        Accept?: components["parameters"]["accept"];
      };
    };
    responses: {
      200: components["responses"]["AttributeTransform"];
      /** @description Forbidden */
      403: {
        content: never;
      };
    };
  };
  /**
   * Create an Attribute Transform
   * @description Create a new attribute transform.
   */
  create_attribute_transform: {
    requestBody?: {
      content: {
        "application/json": components["schemas"]["AttributeTransformMutable"];
      };
    };
    responses: {
      200: components["responses"]["code_containers_one_AttributeTransform"];
      /** @description Unauthorized */
      401: {
        content: never;
      };
      /** @description Forbidden */
      403: {
        content: never;
      };
    };
  };
  /**
   * Get Attribute Transform by ID
   * @description Returns an attribute transform object if a valid ID is provided.
   */
  get_attribute_transform: {
    parameters: {
      header?: {
        Accept?: components["parameters"]["accept"];
      };
      path: {
        /** @description The unique ID of the attribute transform that needs to be fetched. */
        attribute_transform_id: number;
      };
    };
    responses: {
      200: components["responses"]["code_containers_one_AttributeTransform"];
      /** @description Unauthorized */
      401: {
        content: never;
      };
      /** @description Forbidden */
      403: {
        content: never;
      };
      /** @description Not found */
      404: {
        content: never;
      };
    };
  };
  /**
   * Update Attribute Transform
   * @description Updates an attribute transform in the authenticated user's account.
   */
  update_attribute_transform: {
    parameters: {
      header?: {
        Accept?: components["parameters"]["accept"];
      };
      path: {
        /** @description The unique ID of the attribute transform. */
        attribute_transform_id: number;
      };
    };
    requestBody?: {
      content: {
        "application/json": components["schemas"]["AttributeTransformMutable"];
      };
    };
    responses: {
      200: components["responses"]["code_containers_one_AttributeTransform"];
      /** @description Unauthorized */
      401: {
        content: never;
      };
      /** @description Forbidden */
      403: {
        content: never;
      };
      /** @description Not found */
      404: {
        content: never;
      };
    };
  };
  /**
   * Delete an Attribute Transform
   * @description Deletes an attribute transform from your Nexla account.
   */
  delete_attribute_transform: {
    parameters: {
      header?: {
        Accept?: components["parameters"]["accept"];
      };
      path: {
        /** @description The unique ID of the attribute transform that needs to be deleted. */
        attribute_transform_id: number;
      };
    };
    responses: {
      /** @description Success */
      200: {
        content: never;
      };
      /** @description Unauthorized */
      401: {
        content: never;
      };
      /** @description Forbidden */
      403: {
        content: never;
      };
      /** @description Not found */
      404: {
        content: never;
      };
    };
  };
  /**
   * Get all Public Attribute Transforms
   * @description The Nexla team regularly adds common reusable attribute transforms that are made available to all Nexla accounts.
   *
   * Use this endpoint to fetch all such "publicly" available reusable attribute transforms.
   */
  get_public_attribute_transforms: {
    parameters: {
      header?: {
        Accept?: components["parameters"]["accept"];
      };
    };
    responses: {
      200: components["responses"]["AttributeTransform"];
      /** @description Unauthorized */
      401: {
        content: never;
      };
      /** @description Forbidden */
      403: {
        content: never;
      };
    };
  };
  /**
   * Get all Code Containers
   * @description Use this endpoint to fetch all code containers accessible to the authenticated user.
   */
  get_code_containers: {
    parameters: {
      header?: {
        Accept?: components["parameters"]["accept"];
      };
    };
    responses: {
      200: components["responses"]["code_containers_many_CodeContainer"];
      /** @description Unauthorized */
      401: {
        content: never;
      };
      /** @description Forbidden */
      403: {
        content: never;
      };
    };
  };
  /**
   * Create a Code Container
   * @description Use this endpoint to create a new code container.
   */
  create_code_container: {
    requestBody?: {
      content: {
        "application/json": components["schemas"]["CodeContainerMutable"];
      };
    };
    responses: {
      200: components["responses"]["CodeContainer"];
      /** @description Unauthorized */
      401: {
        content: never;
      };
      /** @description Forbidden */
      403: {
        content: never;
      };
    };
  };
  /**
   * Get Code Container by ID
   * @description Returns a code container object if a valid ID is provided.
   */
  get_code_container: {
    parameters: {
      header?: {
        Accept?: components["parameters"]["accept"];
      };
      path: {
        /** @description The unique ID of the container that needs to be fetched. */
        code_container_id: number;
      };
    };
    responses: {
      200: components["responses"]["CodeContainer"];
      /** @description Unauthorized */
      401: {
        content: never;
      };
      /** @description Forbidden */
      403: {
        content: never;
      };
      /** @description Not found */
      404: {
        content: never;
      };
    };
  };
  /**
   * Update a Code Container
   * @description Updates a code container in the authenticated user's account.
   */
  update_code_container: {
    parameters: {
      header?: {
        Accept?: components["parameters"]["accept"];
      };
      path: {
        /** @description The unique ID of the container that needs to be updated. */
        code_container_id: number;
      };
    };
    requestBody?: {
      content: {
        "application/json": components["schemas"]["CodeContainerMutable"];
      };
    };
    responses: {
      200: components["responses"]["CodeContainer"];
      /** @description Unauthorized */
      401: {
        content: never;
      };
      /** @description Forbidden */
      403: {
        content: never;
      };
      /** @description Not found */
      404: {
        content: never;
      };
    };
  };
  /**
   * Delete a Code Container
   * @description Deletes a code container from the authenticated user's account.
   */
  delete_code_container: {
    parameters: {
      header?: {
        Accept?: components["parameters"]["accept"];
      };
      path: {
        /** @description The unique ID of the container that needs to be deleted. */
        code_container_id: number;
      };
    };
    responses: {
      /** @description Success */
      200: {
        content: {
          "application/json": {
            /** @description Response status code */
            code?: string;
            /** @description Response status text */
            message?: string;
          };
        };
      };
      /** @description Unauthorized */
      401: {
        content: never;
      };
      /** @description Forbidden */
      403: {
        content: never;
      };
      /** @description Not found */
      404: {
        content: never;
      };
    };
  };
  /**
   * Copy a Code Container
   * @description Use this endpoint to create a copy of an existing code container.
   */
  copy_code_container: {
    parameters: {
      header?: {
        Accept?: components["parameters"]["accept"];
      };
      path: {
        /** @description The unique ID of the code container to be copied. */
        code_container_id: number;
      };
    };
    responses: {
      200: components["responses"]["CodeContainer"];
      /** @description Unauthorized */
      401: {
        content: never;
      };
      /** @description Forbidden */
      403: {
        content: never;
      };
      /** @description Not Found */
      404: {
        content: never;
      };
    };
  };
  /**
   * Get all Public Code Containers
   * @description The Nexla team regularly adds common code containers that are made available to all Nexla accounts.
   *
   * Use this endpoint to fetch all such "publicly" available code containers.
   */
  get_public_code_containers: {
    parameters: {
      header?: {
        Accept?: components["parameters"]["accept"];
      };
    };
    responses: {
      200: components["responses"]["code_containers_many_CodeContainer"];
      /** @description Unauthorized */
      401: {
        content: never;
      };
      /** @description Forbidden */
      403: {
        content: never;
      };
    };
  };
  /**
   * Get all Projects
   * @description Retrieves a list of all projects accessible to the authenticated user.
   */
  get_projects: {
    parameters: {
      query?: {
        access_role?: components["parameters"]["access_roles"];
      };
      header?: {
        Accept?: components["parameters"]["accept"];
      };
    };
    responses: {
      200: components["responses"]["projects_many"];
      /** @description Unauthorized */
      401: {
        content: never;
      };
      /** @description Forbidden */
      403: {
        content: never;
      };
    };
  };
  /**
   * Create a project
   * @description Creates a project with the specified configuration. Note that flows can also be attached to the project later by calling endpoints to update the project.
   */
  create_project: {
    requestBody?: {
      content: {
        "application/vnd.nexla.api.v1+json": components["schemas"]["ProjectCreate"];
      };
    };
    responses: {
      200: components["responses"]["projects_one"];
      /** @description Unauthorized */
      401: {
        content: never;
      };
      /** @description Forbidden */
      403: {
        content: never;
      };
    };
  };
  /**
   * Get Project by ID
   * @description Returns a project if a valid ID is provided.
   */
  get_project: {
    parameters: {
      path: {
        /** @description The unique ID of the project */
        project_id: number;
      };
    };
    responses: {
      200: components["responses"]["projects_one"];
      /** @description Unauthorized */
      401: {
        content: never;
      };
      /** @description Forbidden */
      403: {
        content: never;
      };
      /** @description Not Found */
      404: {
        content: never;
      };
    };
  };
  /**
   * Modify a Project
   * @description Modifies a project's information and settings if a valid ID and body are provided.
   */
  update_project: {
    parameters: {
      path: {
        /** @description The unique ID of the project. */
        project_id: number;
      };
    };
    requestBody?: {
      content: {
        "application/vnd.nexla.api.v1+json": components["schemas"]["ProjectMutable"];
      };
    };
    responses: {
      200: components["responses"]["projects_one"];
      /** @description Unauthorized */
      401: {
        content: never;
      };
      /** @description Forbidden */
      403: {
        content: never;
      };
      /** @description Not Found */
      404: {
        content: never;
      };
    };
  };
  /**
   * Delete Project by ID
   * @description Deletes a project if a valid ID is provided. Note that flows belonging to the project will only be removed from the project and will not be deleted.
   */
  delete_project: {
    parameters: {
      path: {
        /** @description The unique ID of the project. */
        project_id: number;
      };
    };
    responses: {
      /** @description OK */
      200: {
        content: never;
      };
      /** @description Unauthorized */
      401: {
        content: never;
      };
      /** @description Forbidden */
      403: {
        content: never;
      };
      /** @description Not Found */
      404: {
        content: never;
      };
    };
  };
  /**
   * Get Project Flows
   * @description Returns a list of flows belonging to a project.
   */
  get_project_flows: {
    parameters: {
      path: {
        /** @description The unique ID of the project. */
        project_id: number;
      };
    };
    responses: {
      200: components["responses"]["FlowsMany"];
      /** @description Unauthorized */
      401: {
        content: never;
      };
      /** @description Forbidden */
      403: {
        content: never;
      };
      /** @description Not Found */
      404: {
        content: never;
      };
    };
  };
  /**
   * Add Flows to Project
   * @description Adds a list of flows to a project. The existing flow list is retained and merged with the new flow list.
   */
  add_project_flows: {
    parameters: {
      path: {
        /** @description The unique ID of the project. */
        project_id: number;
      };
    };
    requestBody?: {
      content: {
        "application/vnd.nexla.api.v1+json": components["schemas"]["ProjectFlowListFlowNodes"];
      };
    };
    responses: {
      200: components["responses"]["FlowsMany"];
      /** @description Unauthorized */
      401: {
        content: never;
      };
      /** @description Forbidden */
      403: {
        content: never;
      };
      /** @description Not Found */
      404: {
        content: never;
      };
    };
  };
  /**
   * Replace Project Flows List
   * @description Replaces the list of flows belonging to a project. Existing flows are removed from the project.
   */
  replace_project_flows: {
    parameters: {
      path: {
        /** @description The unique ID of the project. */
        project_id: number;
      };
    };
    requestBody?: {
      content: {
        "application/vnd.nexla.api.v1+json": components["schemas"]["ProjectFlowListFlowNodes"];
      };
    };
    responses: {
      200: components["responses"]["FlowsMany"];
      /** @description Unauthorized */
      401: {
        content: never;
      };
      /** @description Forbidden */
      403: {
        content: never;
      };
      /** @description Not Found */
      404: {
        content: never;
      };
    };
  };
  /**
   * Remove Flows From A Project
   * @description Removes data flows from a project. If no request body is provided, all flows belonging to the project will be removed. The flows themselves will not be deleted, but they will no longer belong to the project.
   */
  remove_project_flows: {
    parameters: {
      path: {
        /** @description The unique ID of the project. */
        project_id: number;
      };
    };
    /** @description Optional list of flow identifiers. Data flows must be referenced by the resource associated with them in the GET response. */
    requestBody?: {
      content: {
        "application/vnd.nexla.api.v1+json": components["schemas"]["ProjectFlowListFlowNodes"];
      };
    };
    responses: {
      200: components["responses"]["FlowsMany"];
      /** @description Unauthorized */
      401: {
        content: never;
      };
      /** @description Forbidden */
      403: {
        content: never;
      };
      /** @description Not Found */
      404: {
        content: never;
      };
    };
  };
  /**
   * Get Project Flows (Deprecated)
   * @description Returns a list of flows belonging to a project.
   *
   * > **Note**: This version of the endpoint has been deprecated. The returned flow response does not reference the new unique flow ids, instead references composite data flow ids of the type `{resource_type}/{resource_id}`. See get_project_flows for a new version of this endpoint that references unique `flow_id`.
   */
  "get_project_flows_(deprecated)": {
    parameters: {
      path: {
        /** @description The unique ID of the project. */
        project_id: number;
      };
    };
    responses: {
      200: components["responses"]["ProjectFlowsOld"];
      /** @description Unauthorized */
      401: {
        content: never;
      };
      /** @description Forbidden */
      403: {
        content: never;
      };
      /** @description Not Found */
      404: {
        content: never;
      };
    };
  };
  /**
   * Add Flows to Project (Deprecated)
   * @description Adds a list of flows to a project. The existing flow list is retained and merged with the new flow list.
   *
   * > **Note**: This version of the endpoint has been deprecated. The request body and response does not reference flows with new unique flow_ids, instead references composite data flow ids of the type `{resource_type}/{resource_id}`. See add_project_flows for a new version of this endpoint that references unique `flow_id`.
   */
  "add_project_flows_(deprecated)": {
    parameters: {
      path: {
        /** @description The unique ID of the project. */
        project_id: number;
      };
    };
    requestBody?: {
      content: {
        "application/vnd.nexla.api.v1+json": components["schemas"]["ProjectFlowList"];
      };
    };
    responses: {
      200: components["responses"]["ProjectFlowsOld"];
      /** @description Unauthorized */
      401: {
        content: never;
      };
      /** @description Forbidden */
      403: {
        content: never;
      };
      /** @description Not Found */
      404: {
        content: never;
      };
    };
  };
  /**
   * Replace Project Flows List (Deprecated)
   * @description Replaces the list of flows belonging to a project. Existing flows are removed from the project.
   *
   * > **Note**: This version of the endpoint has been deprecated. The request body and response does not reference flows with new unique flow_ids, instead references composite data flow ids of the type `{resource_type}/{resource_id}`. See replace_project_flows for a new version of this endpoint that references unique `flow_id`.
   */
  "replace_project_flows_(deprecated)": {
    parameters: {
      path: {
        /** @description The unique ID of the project. */
        project_id: number;
      };
    };
    requestBody?: {
      content: {
        "application/vnd.nexla.api.v1+json": components["schemas"]["ProjectFlowList"];
      };
    };
    responses: {
      200: components["responses"]["ProjectFlowsOld"];
      /** @description Unauthorized */
      401: {
        content: never;
      };
      /** @description Forbidden */
      403: {
        content: never;
      };
      /** @description Not Found */
      404: {
        content: never;
      };
    };
  };
  /**
   * Remove Flows From A Project (Deprecated)
   * @description Removes data flows from a project. If no request body is provided, all flows belonging to the project will be removed. The flows themselves will not be deleted, but they will no longer belong to the project.
   *
   * > **Note**: This version of the endpoint has been deprecated. The request body and response does not reference flows with new unique flow_ids, instead references composite data flow ids of the type `{resource_type}/{resource_id}`. See remove_project_flows for a new version of this endpoint that references unique `flow_id`.
   */
  "remove_project_flows_(deprecated)": {
    parameters: {
      path: {
        /** @description The unique ID of the project. */
        project_id: number;
      };
    };
    /** @description Optional list of flow identifiers. Data flows must be referenced by the resource associated with them in the GET response. */
    requestBody?: {
      content: {
        "application/vnd.nexla.api.v1+json": components["schemas"]["ProjectFlowList"];
      };
    };
    responses: {
      200: components["responses"]["ProjectFlowsOld"];
      /** @description Unauthorized */
      401: {
        content: never;
      };
      /** @description Forbidden */
      403: {
        content: never;
      };
      /** @description Not Found */
      404: {
        content: never;
      };
    };
  };
  /**
   * Get all Organizations
   * @description Returns all organizations accessible to the authenticated user.
   */
  get_orgs: {
    parameters: {
      header?: {
        Accept?: components["parameters"]["accept"];
      };
    };
    responses: {
      200: components["responses"]["orgs_many"];
      /** @description Forbidden */
      403: {
        content: never;
      };
    };
  };
  /**
   * Get Organization by ID
   * @description Returns an organization if a valid ID is provided.
   */
  get_org: {
    parameters: {
      header?: {
        Accept?: components["parameters"]["accept"];
      };
      path: {
        /** @description The unique ID of the organization that needs to be fetched. */
        org_id: number;
      };
    };
    responses: {
      200: components["responses"]["orgs_one"];
      /** @description Forbidden */
      403: {
        content: never;
      };
    };
  };
  /**
   * Update an Organization
   * @description Updates properties of an organization.
   */
  update_org: {
    parameters: {
      path: {
        /** @description The unique ID of the organization that needs to be updated. */
        org_id: number;
      };
    };
    requestBody?: {
      content: {
        "application/json": components["schemas"]["OrgsUpdate"];
      };
    };
    responses: {
      200: components["responses"]["orgs_one"];
      /** @description Forbidden */
      403: {
        content: never;
      };
    };
  };
  /**
   * Get All Members in Organization
   * @description Retrieves a list of all users in an organization.
   */
  get_org_members: {
    parameters: {
      header?: {
        Accept?: components["parameters"]["accept"];
      };
      path: {
        /** @description The unique ID of the organization. */
        org_id: number;
      };
    };
    responses: {
      200: components["responses"]["org_members"];
      /** @description Unauthorized */
      401: {
        content: never;
      };
      /** @description Forbidden */
      403: {
        content: never;
      };
      /** @description Not Found */
      404: {
        content: never;
      };
    };
  };
  /**
   * Update Organization Members
   * @description Add or update members in an organization. This endpoint can also be used to modify an existing member's role in the organization.
   *
   * When adding a new member using their email id, if a user account for that email id does not exist on the platform then a new user account will be created. If the user already exists on the platform as a member of a different organization then their membership will get updated to include this organization also.
   */
  update_org_members: {
    parameters: {
      path: {
        /** @description The unique ID of the organization. */
        org_id: number;
      };
    };
    requestBody?: {
      content: {
        "application/vnd.nexla.api.v1+json": components["schemas"]["OrgMemberList"];
      };
    };
    responses: {
      200: components["responses"]["org_members"];
      /** @description Unauthorized */
      401: {
        content: never;
      };
      /** @description Forbidden */
      403: {
        content: never;
      };
      /** @description Not Found */
      404: {
        content: never;
      };
    };
  };
  /**
   * Remove Members from an Organization.
   * @description Removes one or more members from the organization. Note that this will not delete the user account from the platform, but will remove the user's ability to access this organization's resources.
   */
  delete_org_members: {
    parameters: {
      path: {
        /** @description The unique ID of the organization. */
        org_id: number;
      };
    };
    requestBody?: {
      content: {
        "application/vnd.nexla.api.v1+json": components["schemas"]["OrgMemberDelete"];
      };
    };
    responses: {
      /** @description Success */
      200: {
        content: {
          "application/json": {
            /** @description Response status code */
            code?: string;
            /** @description Response status text */
            message?: string;
          };
        };
      };
      /** @description Unauthorized */
      401: {
        content: never;
      };
      /** @description Forbidden */
      403: {
        content: never;
      };
      /** @description Not Found */
      404: {
        content: never;
      };
    };
  };
  /**
   * Get all Teams
   * @description Returns all teams accessible to the authenticated user.
   */
  get_teams: {
    parameters: {
      query?: {
        access_role?: components["parameters"]["access_roles"];
      };
      header?: {
        Accept?: components["parameters"]["accept"];
      };
    };
    responses: {
      200: components["responses"]["teams_many"];
      /** @description Unauthorized */
      401: {
        content: never;
      };
      /** @description Forbidden */
      403: {
        content: never;
      };
    };
  };
  /**
   * Create a team
   * @description Creates a team with the specified configuration and members.
   */
  create_team: {
    requestBody?: {
      content: {
        "application/vnd.nexla.api.v1+json": components["schemas"]["TeamCreate"];
      };
    };
    responses: {
      200: components["responses"]["teams_one"];
      /** @description Unauthorized */
      401: {
        content: never;
      };
      /** @description Forbidden */
      403: {
        content: never;
      };
    };
  };
  /**
   * Get Team by ID
   * @description Returns a team if a valid ID is provided.
   */
  get_team: {
    parameters: {
      path: {
        /** @description The unique ID of the team. */
        team_id: number;
      };
    };
    responses: {
      200: components["responses"]["teams_one"];
      /** @description Unauthorized */
      401: {
        content: never;
      };
      /** @description Forbidden */
      403: {
        content: never;
      };
      /** @description Not Found */
      404: {
        content: never;
      };
    };
  };
  /**
   * Modify a Team
   * @description Modifies a team's information and settings if a valid ID and body are provided.
   */
  update_team: {
    parameters: {
      path: {
        /** @description The unique ID of the team. */
        team_id: number;
      };
    };
    requestBody?: {
      content: {
        "application/vnd.nexla.api.v1+json": components["schemas"]["TeamMutable"];
      };
    };
    responses: {
      200: components["responses"]["teams_one"];
      /** @description Unauthorized */
      401: {
        content: never;
      };
      /** @description Forbidden */
      403: {
        content: never;
      };
      /** @description Not Found */
      404: {
        content: never;
      };
    };
  };
  /**
   * Delete Team by ID
   * @description Deletes a team if a valid ID is provided.
   */
  delete_team: {
    parameters: {
      path: {
        /** @description The unique ID of the team. */
        team_id: number;
      };
    };
    responses: {
      /** @description OK */
      200: {
        content: never;
      };
      /** @description Unauthorized */
      401: {
        content: never;
      };
      /** @description Forbidden */
      403: {
        content: never;
      };
      /** @description Not Found */
      404: {
        content: never;
      };
    };
  };
  /**
   * Get Team Members
   * @description Returns a list of the members belonging to a team.
   */
  get_team_members: {
    parameters: {
      path: {
        /** @description The unique ID of the team. */
        team_id: number;
      };
    };
    responses: {
      200: components["responses"]["team_members"];
      /** @description Unauthorized */
      401: {
        content: never;
      };
      /** @description Forbidden */
      403: {
        content: never;
      };
      /** @description Not Found */
      404: {
        content: never;
      };
    };
  };
  /**
   * Add Members to A Team
   * @description Adds a list of members to a team. The existing list of members will be retained and merged with the new list of members.
   */
  add_team_members: {
    parameters: {
      path: {
        /** @description The unique ID of the team. */
        team_id: number;
      };
    };
    requestBody?: {
      content: {
        "application/vnd.nexla.api.v1+json": components["schemas"]["TeamMemberList"];
      };
    };
    responses: {
      200: components["responses"]["team_members"];
      /** @description Unauthorized */
      401: {
        content: never;
      };
      /** @description Forbidden */
      403: {
        content: never;
      };
      /** @description Not Found */
      404: {
        content: never;
      };
    };
  };
  /**
   * Replace Team Members List
   * @description Replaces the list of members belonging to a team. Existing members will be removed from the team.
   */
  replace_team_members: {
    parameters: {
      path: {
        /** @description The unique ID of the team. */
        team_id: number;
      };
    };
    requestBody?: {
      content: {
        "application/vnd.nexla.api.v1+json": components["schemas"]["TeamMemberList"];
      };
    };
    responses: {
      200: components["responses"]["team_members"];
      /** @description Unauthorized */
      401: {
        content: never;
      };
      /** @description Forbidden */
      403: {
        content: never;
      };
      /** @description Not Found */
      404: {
        content: never;
      };
    };
  };
  /**
   * Remove Team Members
   * @description Removes members from a team. If no request body is provided, all members belonging to the team will be removed.
   */
  delete_team_members: {
    parameters: {
      path: {
        /** @description The unique ID of the team. */
        team_id: number;
      };
    };
    /** @description Optional list of members. */
    requestBody?: {
      content: {
        "application/vnd.nexla.api.v1+json": components["schemas"]["TeamMemberList"];
      };
    };
    responses: {
      200: components["responses"]["team_members"];
      /** @description Unauthorized */
      401: {
        content: never;
      };
      /** @description Forbidden */
      403: {
        content: never;
      };
      /** @description Not Found */
      404: {
        content: never;
      };
    };
  };
  /**
   * Get All Users
   * @description Returns all users that can be viewed by authenticated user.
   */
  get_users: {
    parameters: {
      header?: {
        Accept?: components["parameters"]["accept"];
      };
    };
    responses: {
      200: components["responses"]["users_many"];
      /** @description Forbidden */
      403: {
        content: never;
      };
    };
  };
  /**
   * Create a User
   * @description Create a new user in this environment.
   *
   * > This requires admin access to the provided organization.
   */
  create_user: {
    requestBody?: {
      content: {
        "application/json": components["schemas"]["UsersCreateRequired"];
      };
    };
    responses: {
      200: components["responses"]["users_one"];
      /** @description Forbidden */
      403: {
        content: never;
      };
    };
  };
  /**
   * Get All Users with Expanded References
   * @description Returns all users that can be viewed by the authenticated user.
   */
  get_users_expand: {
    parameters: {
      header?: {
        Accept?: components["parameters"]["accept"];
      };
    };
    responses: {
      200: components["responses"]["users_many_expand"];
      /** @description Forbidden */
      403: {
        content: never;
      };
    };
  };
  /**
   * Get User by ID
   * @description Returns a user if a valid ID is provided.
   */
  get_user: {
    parameters: {
      path: {
        /** @description The unique ID of the user. */
        user_id: number;
      };
    };
    responses: {
      200: components["responses"]["users_one"];
      /** @description Forbidden */
      403: {
        content: never;
      };
    };
  };
  /**
   * Modify a User
   * @description Modifies a user's information and settings if a valid ID and body are provided
   */
  update_user: {
    parameters: {
      path: {
        /** @description The unique ID of the user. */
        user_id: number;
      };
    };
    requestBody?: {
      content: {
        "application/json": components["schemas"]["UsersUpdate"];
      };
    };
    responses: {
      200: components["responses"]["users_one"];
      /** @description Forbidden */
      403: {
        content: never;
      };
    };
  };
  /**
   * Get User by ID with Expanded References
   * @description Returns a user if a valid ID is provided.
   */
  get_user_expand: {
    parameters: {
      query: {
        /** @description Truthy parameter for requesting expanded references. */
        expand: number | boolean;
      };
      path: {
        /** @description The unique ID of the user. */
        user_id: number;
      };
    };
    responses: {
      200: components["responses"]["users_one_expand"];
      /** @description Forbidden */
      403: {
        content: never;
      };
    };
  };
  /**
   * Get info on current user
   * @description Returns the user information of the currently logged-in user, including org memberships and current org info.
   */
  get_current_user: {
    responses: {
      200: components["responses"]["users_transfer"];
      /** @description Unauthorized */
      401: {
        content: never;
      };
      /** @description Forbidden */
      403: {
        content: never;
      };
      /** @description Not Found */
      404: {
        content: never;
      };
    };
  };
  /**
   * Get the current user's settings
   * @description Returns all the settings for the current user.
   */
  get_user_settings: {
    responses: {
      200: components["responses"]["user_settings_list"];
      /** @description Forbidden */
      403: {
        content: never;
      };
    };
  };
  /**
   * Get All Notifications
   * @description Returns all notifications in the authenticated user's account. Note that this only includes notifications generated to be displayed in the Nexla UI.
   */
  get_notifications: {
    parameters: {
      query?: {
        /** @description Filter by level of notifications. Values are: 'DEBUG', 'INFO', 'WARN', 'ERROR', 'RECOVERED', 'RESOLVED'." */
        level?: "DEBUG" | "INFO" | "WARN" | "ERROR" | "RECOVERED";
        /** @description Filter notifications starting from timestamp. Format is unix timestamp. */
        from?: number;
        /** @description Filter notifications ending at timestamp. Format is unix timestamp. */
        to?: number;
      };
      path: {
        /** @description Set the read query parameter to 0 to fetch only notifications that have not yet been read, or set it to 1 to fetch only those that have been read. */
        read: number;
      };
    };
    responses: {
      /** @description Success */
      200: components["responses"]["notifications_many"];
      /** @description Forbidden */
      403: {
        content: never;
      };
    };
  };
  /**
   * Get a Notification
   * @description Returns a notification if a valid ID is provided.
   */
  get_notification: {
    parameters: {
      path: {
        /** @description The unique ID of the notification. */
        notification_id: number;
      };
    };
    responses: {
      200: components["responses"]["notifications_one"];
      /** @description Forbidden */
      403: {
        content: never;
      };
    };
  };
  /**
   * Delete a Notification
   * @description Deletes a notification if a valid ID is provided.
   */
  delete_notifications: {
    parameters: {
      path: {
        /** @description The unique ID of the notification. */
        notification_id: number;
      };
    };
    responses: {
      /** @description Success */
      200: {
        content: never;
      };
      /** @description Forbidden */
      403: {
        content: never;
      };
    };
  };
  /**
   * Delete All Notifications
   * @description Deletes all notifications belonging to the authenticated user. Note that this is only the list of notifications generated to be displayed in the Nexla UI.
   */
  delete_all_notifications: {
    parameters: {
      query?: {
        /** @description If set to 'true', request will be executed in a deferred way, and results will be provided later. */
        async?: boolean;
        /** @description The unique ID of the asynchronous request. In case it's provided, returns info about the deferred request. */
        request_id?: number;
      };
    };
    responses: {
      /** @description Success */
      200: {
        content: {
          "application/json": components["schemas"]["async_or_null"];
        };
      };
      /** @description Forbidden */
      403: {
        content: never;
      };
    };
  };
  /**
   * Get Notifications Count
   * @description Returns the total number of notifications in the authenticated user's account. Note that this only includes notifications generated to be displayed in the Nexla UI.
   */
  get_notification_count: {
    parameters: {
      path: {
        /** @description Set the read query parameter to 0 to fetch only notifications that have not yet been read, or set it to 1 to fetch only those that have been read. If you don't send a read query parameter, all notifications (both read and unread) will be fetched. */
        read: number;
      };
    };
    responses: {
      200: components["responses"]["notifications_count"];
      /** @description Forbidden */
      403: {
        content: never;
      };
    };
  };
  /**
   * Mark Notification Read
   * @description Use this endpoint to mark one, multiple, or all notifications as read. To mark a list of notifications, send an array of notification IDs as the payload. To mark all notifications, send the notification_id query parameter with the value `all`.
   */
  notifications_mark_read: {
    parameters: {
      query?: {
        /**
         * @description The unique ID of one or more notifications, or enter "all" to mark all notifications as read.
         * This can be used in place of an array of IDs in the request body.
         */
        notification_id?: "all" | number;
        /** @description If set to 'true', request will be executed in a deferred way, and results will be provided later. */
        async?: boolean;
        /** @description The unique ID of the asynchronous request. In case it's provided, returns info about the deferred request. */
        request_id?: number;
      };
    };
    requestBody?: {
      content: {
        "application/json": number[];
      };
    };
    responses: {
      /** @description Success */
      200: {
        content: {
          "application/json": components["schemas"]["async_or_null"];
        };
      };
      /** @description Forbidden */
      403: {
        content: never;
      };
    };
  };
  /**
   * Mark Notification Unread
   * @description Use this endpoint to mark one, multiple, or all notifications as read. To mark a list of notifications, send an array of notification IDs as the payload. To mark all notifications, send the notification_id query parameter with the value `all`.
   */
  notifications_mark_unread: {
    parameters: {
      query?: {
        /**
         * @description The unique ID of one or more notifications, or enter "all" to mark all notifications as unread.
         * This can be used in place of an array of IDs in the request body.
         */
        notification_id?: "all" | number;
      };
    };
    requestBody?: {
      content: {
        "application/json": number[];
      };
    };
    responses: {
      /** @description Success */
      200: {
        content: never;
      };
      /** @description Forbidden */
      403: {
        content: never;
      };
    };
  };
  /**
   * Get All Notification Types
   * @description Fetches a list of all notifications supported by Nexla in this environment.
   *
   * When users choose whether or not some notifications are enabled, their choices are saved in `notification_settings` and linked to the ID of the relevant notification type.
   */
  get_notification_types: {
    parameters: {
      query?: {
        status?: "ACTIVE" | "PAUSE";
      };
    };
    responses: {
      200: components["responses"]["notification_types_many"];
      /** @description Forbidden */
      403: {
        content: never;
      };
    };
  };
  /**
   * Get One Notification Type
   * @description Fetches details about a specific notification type supported by Nexla in this environment.
   */
  list_notification_type: {
    parameters: {
      query: {
        event_type: components["schemas"]["NotificationEventType"];
        resource_type: components["schemas"]["NotificationResourceType"];
      };
    };
    responses: {
      200: components["responses"]["notification_types_one"];
      /** @description Forbidden */
      403: {
        content: never;
      };
      /** @description Not Found */
      404: {
        content: never;
      };
    };
  };
  /**
   * List Notification Channel Settings
   * @description Notification channel settings contain configuration settings relevant to where notifications should be delivered. For example, the settings for the `EMAIL` channel contain the email addresses to which notifications can be sent.
   *
   * You can maintain multiple configuration settings for the same channel to route notifications for specific resources and types to different locations.
   *
   * This endpoint lists all notification channel settings in the authenticated user's account.
   */
  list_notification_channel_settings: {
    responses: {
      200: components["responses"]["notification_channel_settings_many"];
      /** @description Forbidden */
      403: {
        content: never;
      };
    };
  };
  /**
   * Create a Notification Channel Setting
   * @description Create a new configuration for a notification channel.
   *
   * You can maintain multiple configuration settings for the same channel to route notifications for specific resources and types to different locations.
   */
  create_notification_channel_setting: {
    requestBody?: {
      content: {
        "application/json": components["schemas"]["NotificationChannelSettingCreateRequired"];
      };
    };
    responses: {
      200: components["responses"]["notification_channel_settings_one"];
      /** @description Bad Request */
      400: {
        content: never;
      };
      /** @description Forbidden */
      403: {
        content: never;
      };
    };
  };
  /**
   * Get a Notification Channel Setting
   * @description Returns a notification channel setting if a valid ID is provided.
   */
  get_notification_channel_setting: {
    parameters: {
      path: {
        /** @description The unique ID of the notification channel setting. */
        notification_channel_setting_id: number;
      };
    };
    responses: {
      200: components["responses"]["notification_channel_settings_one"];
      /** @description Forbidden */
      403: {
        content: never;
      };
      /** @description Not Found */
      404: {
        content: never;
      };
    };
  };
  /**
   * Update a Notification Channel Setting
   * @description Update the configuration of a notification channel setting.
   */
  update_notification_channel_setting: {
    parameters: {
      path: {
        /** @description The unique ID of the notification channel setting. */
        notification_channel_setting_id: number;
      };
    };
    requestBody?: {
      content: {
        "application/json": components["schemas"]["NotificationChannelSettingUpdate"];
      };
    };
    responses: {
      200: components["responses"]["notification_channel_settings_one"];
      /** @description Bad Request */
      400: {
        content: never;
      };
      /** @description Forbidden */
      403: {
        content: never;
      };
      /** @description Not Found */
      404: {
        content: never;
      };
    };
  };
  /**
   * Delete a Notification Channel Setting
   * @description Deletes a notification channel setting if a valid ID is provided.
   */
  delete_notification_channel_setting: {
    parameters: {
      path: {
        /** @description The unique ID of the notification channel setting. */
        notification_channel_setting_id: number;
      };
    };
    responses: {
      /** @description Success */
      200: {
        content: never;
      };
      /** @description Forbidden */
      403: {
        content: never;
      };
      /** @description Not Found */
      404: {
        content: never;
      };
    };
  };
  /**
   * List Notification Settings
   * @description This endpoint lists all notification settings in the authenticated user's account.
   *
   *
   * Notification settings contain the following user settings:
   * 1. Whether the user wants to be notified about a specific event (`status` of a `notification_type` on a `notification_resource_type`)
   * 2. If yes, on what `channel` the user wants to be notified
   * 3. The configuration of the channel (`notification_channel_setting_id`)
   * 4. Configuration parameters affect when the notification should be fired. This is usually left empty to use platform defaults, but it is relevant when users want to override the default settings of some notifications, such as `Source Data Delayed`
   */
  list_notification_settings: {
    parameters: {
      query?: {
        event_type?: components["schemas"]["NotificationEventType"];
        resource_type?: components["schemas"]["NotificationResourceType"];
        status?: components["schemas"]["NotificationSettingStatus"];
      };
    };
    responses: {
      200: components["responses"]["notification_settings_many"];
      /** @description Bad Request */
      400: {
        content: never;
      };
      /** @description Forbidden */
      403: {
        content: never;
      };
    };
  };
  /**
   * Create a Notification Setting
   * @description Create a setting to designate whether, when, and how a specific notification should be fired.
   */
  create_notification_setting: {
    requestBody?: {
      content: {
        "application/json": components["schemas"]["NotificationSettingCreateRequired"];
      };
    };
    responses: {
      200: components["responses"]["notification_settings_one"];
      /** @description Bad Request */
      400: {
        content: never;
      };
      /** @description Forbidden */
      403: {
        content: never;
      };
    };
  };
  /**
   * Get a Notification Setting
   * @description Returns a notification if a valid ID is provided.
   */
  get_notification_setting: {
    parameters: {
      path: {
        /** @description The unique ID of the notification setting. */
        notification_setting_id: number;
      };
    };
    responses: {
      200: components["responses"]["notification_settings_one"];
      /** @description Forbidden */
      403: {
        content: never;
      };
      /** @description Not Found */
      404: {
        content: never;
      };
    };
  };
  /**
   * Modify a Notification Setting
   * @description Modifies a notification if a valid ID and body are provided.
   */
  update_notification_setting: {
    parameters: {
      path: {
        /** @description The unique ID of the notification setting. */
        notification_setting_id: number;
      };
    };
    requestBody?: {
      content: {
        "application/json": components["schemas"]["NotificationSettingUpdate"];
      };
    };
    responses: {
      200: components["responses"]["notification_settings_one"];
      /** @description Bad Request */
      400: {
        content: never;
      };
      /** @description Forbidden */
      403: {
        content: never;
      };
      /** @description Not Found */
      404: {
        content: never;
      };
    };
  };
  /**
   * Delete a Notification Setting
   * @description Delete a notification setting if a valid ID is provided.
   */
  delete_notification_setting: {
    parameters: {
      path: {
        /** @description The unique ID of the notification setting. */
        notification_setting_id: number;
      };
    };
    responses: {
      /** @description Success */
      200: {
        content: never;
      };
      /** @description Forbidden */
      403: {
        content: never;
      };
      /** @description Not Found */
      404: {
        content: never;
      };
    };
  };
  /**
   * Get Notification Settings for an Event
   * @description Use this endpoint to fetch all notification settings of a specific type.
   *
   * This can be used as a filter that is easy to use to understand, which returns all notifications that a user can expect to receive for a specific event.
   */
  list_notification_settings_by_type: {
    parameters: {
      query?: {
        expand?: boolean;
      };
      path: {
        /** @description The unique ID of the notification type. */
        notification_type_id: number;
      };
    };
    responses: {
      200: components["responses"]["notification_settings_many_type"];
      /** @description Bad Request */
      400: {
        content: never;
      };
      /** @description Forbidden */
      403: {
        content: never;
      };
    };
  };
  /**
   * Get Notification Settings For a Resource
   * @description Use this endpoint to fetch all notification settings for a given resource.
   *
   * This can be used as a filter that is easy to understand, which returns all notifications that a user can expect to receive for a specific resource.
   */
  list_resource_notification_settings: {
    parameters: {
      query?: {
        expand?: boolean;
        filter_overridden_settings?: boolean;
        /** @example 1 */
        notification_type_id?: number;
      };
      path: {
        /** @example 2 */
        resource_id: number;
        resource_type: components["schemas"]["NotificationResourceType"];
      };
    };
    responses: {
      200: components["responses"]["notification_settings_many"];
      /** @description Bad Request */
      400: {
        content: never;
      };
      /** @description Forbidden */
      403: {
        content: never;
      };
    };
  };
  /**
   * Get Total Account Metrics for An Organization
   * @description Retrieves total account utilization metrics for an organization. The result consists of aggregated information about records processed within the specified date range by all resources owned by users in the organization.
   */
  org_account_metrics_total: {
    parameters: {
      query: {
        /** @description The date that should be considered as the start of the metrics aggregation period. */
        from: string;
        /** @description The date that should be considered as the end of the metrics aggregation period. In the absence of this parameter, the API returns metrics aggregated up to the current date. */
        to?: string;
      };
      header?: {
        Accept?: components["parameters"]["accept"];
      };
      path: {
        /** @description The unique ID of the organization. The result will be an aggregate of metrics for all resources owned by users in the organization. */
        org_id: number;
      };
    };
    responses: {
      200: components["responses"]["flows_account_metrics"];
      /** @description Unauthorized */
      401: {
        content: never;
      };
      /** @description Forbidden */
      403: {
        content: never;
      };
      /** @description Not found error */
      404: {
        content: never;
      };
    };
  };
  /**
   * Get Total Account Metrics for a User
   * @description Retrieves total account utilization metrics for a user in an organization. The result consists of aggregated information about records processed within the specified date range by all resources owned by the user.
   */
  user_account_metrics_total: {
    parameters: {
      query: {
        /** @description The ID of the organization this user belongs to. This parameter is relevant for users who belong to multiple organizations. In the absence of this parameter, the API returns an aggregate of metrics for all resources owned by the user in the user's default organization. Set this query parameter to fetch metrics for a different organization. */
        org_id?: number;
        /** @description The date that should be considered as the start of the metrics aggregation period. */
        from: string;
        /** @description The date that should be considered as the end of the metrics aggregation period. In the absence of this parameter, the API returns metrics aggregated up to the current date. */
        to?: string;
      };
      header?: {
        Accept?: components["parameters"]["accept"];
      };
      path: {
        /** @description The unique ID of the user. The result will be an aggregate of metrics for all resources owned by this user. */
        user_id: number;
      };
    };
    responses: {
      200: components["responses"]["flows_account_metrics"];
      /** @description Unauthorized */
      401: {
        content: never;
      };
      /** @description Forbidden */
      403: {
        content: never;
      };
      /** @description Not found error */
      404: {
        content: never;
      };
    };
  };
  /**
   * Get 24 Hour Flow Stats for a User
   * @description Retrieves the metrics and processing status of each flow that processed data in the last 24 hours.
   *
   * Each item reflects the total number of records processed by each stage of all flows accessible by the user that processed any data in the specified time window.
   */
  user_24_hour_flow_stats: {
    parameters: {
      query?: {
        access_role?: components["parameters"]["access_roles"];
      };
      header?: {
        Accept?: components["parameters"]["accept"];
      };
      path: {
        /** @description The unique ID of the user whose flows are to be fetched. */
        user_id: number;
      };
    };
    responses: {
      200: components["responses"]["flows_dashboard"];
      /** @description Unauthorized */
      401: {
        content: never;
      };
      /** @description Forbidden */
      403: {
        content: never;
      };
      /** @description Not found error */
      404: {
        content: never;
      };
    };
  };
  /**
   * Get Daily Data Processing Metrics for a User
   * @description Retrieves daily data processing metrics of all sources or all destinations owned by a user.
   */
  user_metrics_daily: {
    parameters: {
      query: {
        /** @description The ID of the organization this user belongs to. This parameter is relevant for users who belong to multiple organizations. In the absence of this parameter, the API returns an aggregate of metrics for all resources owned by the user in the user's default organization. Set this query parameter to fetch metrics for a different organization. */
        org_id?: number;
        /** @description The type of resource that metrics should be fetched for. Select `SOURCE` for the total data ingested by all sources owned by the user. Select `SINK` for the total data written out by all sinks owned by the user. */
        resource_type: "SOURCE" | "SINK";
        /** @description The date that should be considered as the start of the metrics reporting period. */
        from: string;
        /** @description The date that should be considered as the end of the metrics reporting period. In the absence of this parameter, the API returns metrics up to the current date. */
        to?: string;
        /** @description This should be set to 1 for fetching daily aggregated metrics over the specified time range. */
        aggregate: number;
      };
      path: {
        /** @description The unique ID of the user. The result will be an aggregate of metrics for all resources owned by this user. */
        user_id: number;
      };
    };
    responses: {
      200: components["responses"]["user_metrics"];
      /** @description Forbidden */
      403: {
        content: never;
      };
      /** @description Not found error */
      404: {
        content: never;
      };
    };
  };
  /**
   * Get Daily Metrics for a Resource of a Flow
   * @description Retrieves daily data processing metrics of a `data_source`, `data_set`, or `data_sink`.
   */
  get_resource_metrics_daily: {
    parameters: {
      query: {
        /** @description The date that should be considered as the start of the metrics reporting period. */
        from: string;
        /** @description The date that should be considered as the end of the metrics reporting period. In the absence of this parameter, the API returns metrics up to the current date. */
        to?: string;
        /** @description This should be set to 1 for fetching daily aggregated metrics over the specified time range. */
        aggregate: number;
      };
      path: {
        /** @description The type of resource that metrics should be fetched for. */
        resource_type: "data_sources" | "data_sinks" | "data_sets";
        /** @description The ID of resource that metrics should be fetched for. */
        resource_id: number;
      };
    };
    responses: {
      200: components["responses"]["ResourceMetricsDaily"];
      /** @description Forbidden */
      403: {
        content: never;
      };
      /** @description Not found error */
      404: {
        content: never;
      };
    };
  };
  /**
   * Get Metrics By Run ID for a Resource of a Flow
   * @description Retrieves data processing metrics of a `data_source`, `data_set`, or `data_sink`. The reported metrics are grouped by run id to indicate the number of records processed during each ingestion cycle of this flow.
   */
  get_resource_metrics_by_run: {
    parameters: {
      query?: {
        page?: components["parameters"]["page"];
        size?: components["parameters"]["size"];
      };
      path: {
        /** @description The type of resource that metrics should be fetched for. */
        resource_type: "data_sources" | "data_sinks" | "data_sets";
        /** @description The unique id of the resource you wish to fetch metrics for.  For ex, set this to id of the `data_source` if you want to fetch metrics of a specific `data_source`. */
        resource_id: number;
        /**
         * @description Specify the rule based on which metrics should be grouped for aggregation.
         *
         * Default API behavior is to group by `runId`. This choice is only applicable for data sinks where the run summary could be reported by `runId` ( for reporting number of records written out per ingestion cycle) or `lastWritten` (for reporting number of records written out in each destination write batch).
         */
        groupby: "runId" | "lastWritten";
        /** @description Specify the order in which paginated results should be sorted. Default API behavior is to order by `runId`. This choice is only applicable for data sinks where the run summary could be reported by `runId` ( for reporting number of records written out per ingestion cycle) or `lastWritten` (for reporting number of records written out in each destination write batch). */
        orderby: "runId" | "lastWritten";
      };
    };
    responses: {
      200: components["responses"]["ResourceMetricsByRuns"];
      /** @description Forbidden */
      403: {
        content: never;
      };
      /** @description Not found error */
      404: {
        content: never;
      };
    };
  };
  /**
   * Get Metrics for a Flow
   * @description Retrieves data processing metrics of a flow. Metrics are aggregated for each node of the flow for the specified time range. They can be be further grouped by run id to indicate the number of records processed during each ingestion cycle of this flow.
   *
   * > Note: This is a variant of flow endpoints where the flow node can referenced not by its own ID, but by the ID of the unique resource that is linked to that flow node.
   */
  get_flow_metrics: {
    parameters: {
      query: {
        /** @description The date that should be considered as the start of the metrics aggregation period. */
        from: string;
        /** @description The date that should be considered as the end of the metrics aggregation period. In the absence of this parameter, the API returns metrics aggregated up to the current date. */
        to?: string;
        page?: components["parameters"]["page"];
        per_page?: components["parameters"]["per_page"];
      };
      path: {
        /** @description The type of node linked to the flow you want to reference. For ex, set this to `data_sources` if you want to refer to the flow originating in a `data_source`. */
        resource_type: "data_sources" | "data_sinks" | "data_sets";
        /** @description The unique id of the resource whose flow you want to reference.  For ex, set this to id of the `data_source` if you want to refer to the flow originating in a specific `data_source`. */
        resource_id: number;
        /**
         * @description Specify the rule based on which metrics should be grouped for aggregation. This is an optional property.
         *
         * If present and set to `runId` the response will contain one entry per run id, with each entry containing metrics for all resources that processed data during that run.
         */
        groupby: "runId";
        /** @description Specify the order in which paginated results should be sorted. */
        orderby: "runId" | "created_at";
      };
    };
    responses: {
      200: components["responses"]["FlowMetricsResponse"];
      /** @description Forbidden */
      403: {
        content: never;
      };
      /** @description Not found error */
      404: {
        content: never;
      };
    };
  };
  /**
   * Get Flow Execution Logs for Run ID of a Flow
   * @description Retrieves flow execution logs for a specific run id of a flow.
   *
   * > Note: This is a variant of flow endpoints where the flow node can referenced not by its own ID, but by the ID of the unique resource that is linked to that flow node.
   */
  get_flow_logs_for_run_id: {
    parameters: {
      query: {
        /** @description The run id (denoting the ingestion cycle) for which logs have to be fetched. */
        run_id: number;
        /** @description The timestamp that should be considered as the start of the logs reporting period. */
        from: number;
        /** @description The timestamp that should be considered as the end of the logs reporting period. In the absence of this parameter, the API returns metrics up to the current time. */
        to?: number;
        page?: components["parameters"]["page"];
        per_page?: components["parameters"]["per_page"];
      };
      path: {
        /** @description The type of node linked to the flow you want to reference. For ex, set this to `data_sources` if you want to refer to the flow originating in a `data_source`. */
        resource_type: "data_sources" | "data_sinks" | "data_sets";
        /** @description The unique id of the resource whose flow you want to reference.  For ex, set this to id of the `data_source` if you want to refer to the flow originating in a specific `data_source`. */
        resource_id: number;
      };
    };
    responses: {
      200: components["responses"]["FlowLogsResponse"];
      /** @description Forbidden */
      403: {
        content: never;
      };
      /** @description Not found error */
      404: {
        content: never;
      };
    };
  };
  /**
   * Get Audit Log for a Data Source
   * @description Retrieves the history of changes made to the properties of a data source.
   */
  get_data_source_audit_log: {
    parameters: {
      query?: {
        /** @description If set to 'true', request will be executed in a deferred way, and results will be provided later. */
        async?: boolean;
        /** @description The unique ID of the asynchronous request. In case it's provided, returns info about the deferred request. */
        request_id?: number;
      };
      header?: {
        Accept?: components["parameters"]["accept"];
      };
      path: {
        /** @description The unique ID of the resource being queried. */
        data_source_id: number;
      };
    };
    responses: {
      /** @description Success */
      200: {
        content: {
          "application/json": components["schemas"]["audit_log_response"];
        };
      };
      /** @description Unauthorized */
      401: {
        content: never;
      };
      /** @description Forbidden */
      403: {
        content: never;
      };
      /** @description Not found */
      404: {
        content: never;
      };
    };
  };
  /**
   * Get Audit Log for a Data Sink
   * @description Retrieves the history of changes made to the properties of a data sink.
   */
  get_data_sink_audit_log: {
    parameters: {
      header?: {
        Accept?: components["parameters"]["accept"];
      };
      path: {
        /** @description The unique ID of the resource being queried. */
        data_sink_id: number;
      };
    };
    responses: {
      /** @description Success */
      200: {
        content: {
          "application/json": components["schemas"]["audit_log_response"];
        };
      };
      /** @description Unauthorized */
      401: {
        content: never;
      };
      /** @description Forbidden */
      403: {
        content: never;
      };
      /** @description Not found */
      404: {
        content: never;
      };
    };
  };
  /**
   * Get Audit Log for a Nexset
   * @description Retrieves the history of changes made to the properties of a Nexset.
   */
  get_nexset_audit_log: {
    parameters: {
      header?: {
        Accept?: components["parameters"]["accept"];
      };
      path: {
        /** @description The unique ID of the resource being queried. */
        data_set_id: number;
      };
    };
    responses: {
      /** @description Success */
      200: {
        content: {
          "application/json": components["schemas"]["audit_log_response"];
        };
      };
      /** @description Unauthorized */
      401: {
        content: never;
      };
      /** @description Forbidden */
      403: {
        content: never;
      };
      /** @description Not found */
      404: {
        content: never;
      };
    };
  };
  /**
   * Get Audit Log for a Data Credential
   * @description Retrieves the history of changes made to the properties of a data credential.
   */
  get_data_credential_audit_log: {
    parameters: {
      header?: {
        Accept?: components["parameters"]["accept"];
      };
      path: {
        /** @description The unique ID of the resource being queried. */
        data_credential_id: number;
      };
    };
    responses: {
      /** @description Success */
      200: {
        content: {
          "application/json": components["schemas"]["audit_log_response"];
        };
      };
      /** @description Unauthorized */
      401: {
        content: never;
      };
      /** @description Forbidden */
      403: {
        content: never;
      };
      /** @description Not found */
      404: {
        content: never;
      };
    };
  };
  /**
   * Get Audit Log for a Data Map
   * @description Retrieves the history of changes made to the properties of a data map.
   */
  get_data_map_audit_log: {
    parameters: {
      header?: {
        Accept?: components["parameters"]["accept"];
      };
      path: {
        /** @description The unique ID of the resource being queried. */
        data_map_id: number;
      };
    };
    responses: {
      /** @description Success */
      200: {
        content: {
          "application/json": components["schemas"]["audit_log_response"];
        };
      };
      /** @description Unauthorized */
      401: {
        content: never;
      };
      /** @description Forbidden */
      403: {
        content: never;
      };
      /** @description Not found */
      404: {
        content: never;
      };
    };
  };
  /**
   * Get Audit Log for a Data Schema
   * @description Retrieves the history of changes made to the properties of a data schema.
   */
  get_data_schema_audit_log: {
    parameters: {
      header?: {
        Accept?: components["parameters"]["accept"];
      };
      path: {
        /** @description The unique ID of the resource being queried. */
        data_schema_id: number;
      };
    };
    responses: {
      /** @description Success */
      200: {
        content: {
          "application/json": components["schemas"]["audit_log_response"];
        };
      };
      /** @description Unauthorized */
      401: {
        content: never;
      };
      /** @description Forbidden */
      403: {
        content: never;
      };
      /** @description Not found */
      404: {
        content: never;
      };
    };
  };
  /**
   * Get Audit Log for a Code Container
   * @description Retrieves the history of changes made to the properties of a code container. This endpoint can also be used to fetch the history of changes made to any transform object.
   */
  get_code_container_audit_log: {
    parameters: {
      query?: {
        /** @description If set to 'true', request will be executed in a deferred way, and results will be provided later. */
        async?: boolean;
        /** @description The unique ID of the asynchronous request. In case it's provided, returns info about the deferred request. */
        request_id?: number;
      };
      header?: {
        Accept?: components["parameters"]["accept"];
      };
      path: {
        /** @description The unique ID of the resource being queried. */
        code_container_id: number;
      };
    };
    responses: {
      /** @description Success */
      200: {
        content: {
          "application/json": components["schemas"]["audit_log_response"];
        };
      };
      /** @description Unauthorized */
      401: {
        content: never;
      };
      /** @description Forbidden */
      403: {
        content: never;
      };
      /** @description Not found */
      404: {
        content: never;
      };
    };
  };
  /**
   * Get Audit Log for a Project
   * @description Retrieves the history of changes made to the properties of a project.
   */
  get_project_audit_log: {
    parameters: {
      query?: {
        /** @description If set to 'true', request will be executed in a deferred way, and results will be provided later. */
        async?: boolean;
        /** @description The unique ID of the asynchronous request. In case it's provided, returns info about the deferred request. */
        request_id?: number;
      };
      header?: {
        Accept?: components["parameters"]["accept"];
      };
      path: {
        /** @description The unique ID of the resource being queried. */
        project_id: number;
      };
    };
    responses: {
      /** @description Success */
      200: {
        content: {
          "application/json": components["schemas"]["audit_log_response"];
        };
      };
      /** @description Unauthorized */
      401: {
        content: never;
      };
      /** @description Forbidden */
      403: {
        content: never;
      };
      /** @description Not found */
      404: {
        content: never;
      };
    };
  };
  /**
   * Get Audit Log for a Document
   * @description Retrieves the history of changes made to the properties of a document.
   */
  get_doc_container_audit_log: {
    parameters: {
      query?: {
        /** @description If set to 'true', request will be executed in a deferred way, and results will be provided later. */
        async?: boolean;
        /** @description The unique ID of the asynchronous request. In case it's provided, returns info about the deferred request. */
        request_id?: number;
      };
      header?: {
        Accept?: components["parameters"]["accept"];
      };
      path: {
        /** @description The unique ID of the resource being queried. */
        doc_container_id: number;
      };
    };
    responses: {
      /** @description Success */
      200: {
        content: {
          "application/json": components["schemas"]["audit_log_response"];
        };
      };
      /** @description Unauthorized */
      401: {
        content: never;
      };
      /** @description Forbidden */
      403: {
        content: never;
      };
      /** @description Not found */
      404: {
        content: never;
      };
    };
  };
  /**
   * Get Audit Log for a User
   * @description Retrieves the history of changes made to the properties of a user.
   */
  get_user_audit_log: {
    parameters: {
      query?: {
        /** @description If set to 'true', request will be executed in a deferred way, and results will be provided later. */
        async?: boolean;
        /** @description The unique ID of the asynchronous request. In case it's provided, returns info about the deferred request. */
        request_id?: number;
      };
      header?: {
        Accept?: components["parameters"]["accept"];
      };
      path: {
        /** @description The unique ID of the resource being queried. */
        user_id: number;
      };
    };
    responses: {
      /** @description Success */
      200: {
        content: {
          "application/json": components["schemas"]["audit_log_response"];
        };
      };
      /** @description Unauthorized */
      401: {
        content: never;
      };
      /** @description Forbidden */
      403: {
        content: never;
      };
      /** @description Not found */
      404: {
        content: never;
      };
    };
  };
  /**
   * Get Audit Log for an Organization
   * @description Retrieves the history of changes made to the properties of an organization.
   */
  get_org_audit_log: {
    parameters: {
      query?: {
        /** @description If set to 'true', request will be executed in a deferred way, and results will be provided later. */
        async?: boolean;
        /** @description The unique ID of the asynchronous request. In case it's provided, returns info about the deferred request. */
        request_id?: number;
      };
      header?: {
        Accept?: components["parameters"]["accept"];
      };
      path: {
        /** @description The unique ID of the resource being queried. */
        org_id: number;
      };
    };
    responses: {
      /** @description Success */
      200: {
        content: {
          "application/json": components["schemas"]["audit_log_response"];
        };
      };
      /** @description Unauthorized */
      401: {
        content: never;
      };
      /** @description Forbidden */
      403: {
        content: never;
      };
      /** @description Not found */
      404: {
        content: never;
      };
    };
  };
  /**
   * Get Audit Log for a Team
   * @description Retrieves the history of changes made to the properties of a team.
   */
  get_team_audit_log: {
    parameters: {
      query?: {
        /** @description If set to 'true', request will be executed in a deferred way, and results will be provided later. */
        async?: boolean;
        /** @description The unique ID of the asynchronous request. In case it's provided, returns info about the deferred request. */
        request_id?: number;
      };
      header?: {
        Accept?: components["parameters"]["accept"];
      };
      path: {
        /** @description The unique ID of the resource being queried. */
        team_id: number;
      };
    };
    responses: {
      /** @description Success */
      200: {
        content: {
          "application/json": components["schemas"]["audit_log_response"];
        };
      };
      /** @description Unauthorized */
      401: {
        content: never;
      };
      /** @description Forbidden */
      403: {
        content: never;
      };
      /** @description Not found */
      404: {
        content: never;
      };
    };
  };
  /**
   * Get Quarantine Data Export Settings for A User
   * @description Retrieve Quarantine Data Export Settings for all resources owned by a user.
   *
   * Nexla detects errors during different stages of data flow such as ingestion, transformation, and output. Error records are quarantined and accessible to the user via APIs as well as files. With Quarantine Data Export Settings, you can configure Nexla to write files containing information about erroneous records across all resources owned by a user.
   *
   * > This endpoint returns a 404 status code if no Quarantine Data Export Settings have been configured for the user.
   */
  get_user_quarantine_data_export_settings: {
    parameters: {
      header?: {
        Accept?: components["parameters"]["accept"];
      };
      path: {
        /** @description The unique ID of the user whose quarantine settings you wish to retrieve. */
        user_id: number;
      };
    };
    responses: {
      200: components["responses"]["quarantine_settings_one"];
      /** @description Unauthorized */
      401: {
        content: never;
      };
      /** @description Forbidden */
      403: {
        content: never;
      };
      /** @description Not Found */
      404: {
        content: never;
      };
    };
  };
  /**
   * Update Quarantine Data Export Settings for A User
   * @description Updates Quarantine Data Export Settings for all resources owned by a user so that all erroneous records can be automatically exported by the platform to a file system regularly.
   */
  update_user_quarantine_data_export_settings: {
    parameters: {
      header?: {
        Accept?: components["parameters"]["accept"];
      };
      path: {
        /** @description The unique ID of the user. */
        user_id: number;
      };
    };
    requestBody?: {
      content: {
        "application/vnd.nexla.api.v1+json": components["schemas"]["QuarantineSettingMutable"];
      };
    };
    responses: {
      200: components["responses"]["quarantine_settings_one"];
      /** @description Unauthorized */
      401: {
        content: never;
      };
      /** @description Forbidden */
      403: {
        content: never;
      };
      /** @description Not Found */
      404: {
        content: never;
      };
    };
  };
  /**
   * Set Quarantine Data Export Settings for A User
   * @description Sets Quarantine Data Export Settings for all resources owned by a user so that all erroneous records can be automatically exported by the platform to a file system regularly.
   */
  create_quarantine_data_export_settings: {
    parameters: {
      header?: {
        Accept?: components["parameters"]["accept"];
      };
      path: {
        /** @description The unique ID of the user. */
        user_id: number;
      };
    };
    requestBody?: {
      content: {
        "application/vnd.nexla.api.v1+json": components["schemas"]["QuarantineSettingCreate"];
      };
    };
    responses: {
      200: components["responses"]["quarantine_settings_one"];
      /** @description Unauthorized */
      401: {
        content: never;
      };
      /** @description Forbidden */
      403: {
        content: never;
      };
      /** @description Not Found */
      404: {
        content: never;
      };
    };
  };
  /**
   * Delete Quarantine Data Export Settings for A User
   * @description Deletes Updates Quarantine Data Export Settings for all resources owned by a user. Deleting this setting will ensure the platform stops exporting all erroneous records for resources owned by the user to a file storage.
   */
  delete_user_quarantine_data_export_settings: {
    parameters: {
      path: {
        /** @description The unique id of the user. */
        user_id: number;
      };
    };
    responses: {
      /** @description OK */
      200: {
        content: never;
      };
      /** @description Unauthorized */
      401: {
        content: never;
      };
      /** @description Forbidden */
      403: {
        content: never;
      };
      /** @description Not Found */
      404: {
        content: never;
      };
    };
  };
  /**
   * Get all pending approval requests.
   * @description Use this endpoint to fetch all pending approval requests that are not assigned to any users.
   */
  get_pending_approval_requests: {
    parameters: {
      header?: {
        Accept?: components["parameters"]["accept"];
      };
    };
    responses: {
      200: components["responses"]["approval_requests_many"];
      /** @description Forbidden */
      403: {
        content: never;
      };
    };
  };
  /**
   * Get all requested approval requests by the user.
   * @description Use this endpoint to fetch all approval requests that are requested by the user.
   */
  get_requested_approval_requests: {
    parameters: {
      header?: {
        Accept?: components["parameters"]["accept"];
      };
    };
    responses: {
      200: components["responses"]["approval_requests_many"];
      /** @description Forbidden */
      403: {
        content: never;
      };
    };
  };
  /**
   * Approve pending approval requests
   * @description Use this endpoint to approve pending approval requests that are assigned to user or it's unassigned.
   */
  approve_approval_request: {
    parameters: {
      header?: {
        Accept?: components["parameters"]["accept"];
      };
      path: {
        /** @description The unique ID of the Approval Request that needs to be approved. */
        request_id: number;
      };
    };
    responses: {
      200: components["responses"]["approval_requests_one"];
      /** @description Forbidden */
      403: {
        content: never;
      };
    };
  };
  /**
   * Reject pending approval requests
   * @description Use this endpoint to reject pending approval requests that are assigned to user or it's unassigned.
   */
  reject_approval_request: {
    parameters: {
      header?: {
        Accept?: components["parameters"]["accept"];
      };
      path: {
        /** @description The unique ID of the Approval Request that needs to be approved. */
        request_id: number;
      };
    };
    requestBody?: {
      content: {
        "application/vnd.nexla.api.v1+json": {
          reason?: string;
        };
      };
    };
    responses: {
      /** @description Successfully deleted */
      200: {
        content: never;
      };
      /** @description Forbidden */
      403: {
        content: never;
      };
    };
  };
  /**
   * Get Access Rules on Data Source
   * @description Returns a list of the access-control rules set for this data source.
   */
  get_data_source_accessors: {
    parameters: {
      path: {
        /** @description The unique ID of the data source. */
        data_source_id: number;
      };
    };
    responses: {
      200: components["responses"]["accessors_list"];
      /** @description Unauthorized */
      401: {
        content: never;
      };
      /** @description Forbidden */
      403: {
        content: never;
      };
      /** @description Not Found */
      404: {
        content: never;
      };
    };
  };
  /**
   * Add Access Rules on Data Source
   * @description Adds a list of accessors to a data source. The existing accessors list is retained and merged with the new accessors list.
   */
  add_data_source_accessors: {
    parameters: {
      path: {
        /** @description The unique ID of the data source. */
        data_source_id: number;
      };
    };
    requestBody?: {
      content: {
        "application/vnd.nexla.api.v1+json": components["schemas"]["AccessorsRequestSchema"];
      };
    };
    responses: {
      200: components["responses"]["accessors_list"];
      /** @description Unauthorized */
      401: {
        content: never;
      };
      /** @description Forbidden */
      403: {
        content: never;
      };
      /** @description Not Found */
      404: {
        content: never;
      };
    };
  };
  /**
   * Replace Access Rules on Data Source
   * @description Replaces the list of accessors belonging to a data source. Existing accessors will be removed from the data source.
   */
  replace_data_source_accessors: {
    parameters: {
      path: {
        /** @description The unique ID of the data source. */
        data_source_id: number;
      };
    };
    requestBody?: {
      content: {
        "application/vnd.nexla.api.v1+json": components["schemas"]["AccessorsRequestSchema"];
      };
    };
    responses: {
      200: components["responses"]["accessors_list"];
      /** @description Unauthorized */
      401: {
        content: never;
      };
      /** @description Forbidden */
      403: {
        content: never;
      };
      /** @description Not Found */
      404: {
        content: never;
      };
    };
  };
  /**
   * Delete Access Rules on Data Source
   * @description Removes access-control rules from a data source. If no request body is provided, all rules associated with the data source will be removed.
   */
  delete_data_source_accessors: {
    parameters: {
      path: {
        /** @description The unique ID of the data source. */
        data_source_id: number;
      };
    };
    /** @description Optional list of accessors. */
    requestBody?: {
      content: {
        "application/vnd.nexla.api.v1+json": components["schemas"]["AccessorsRequestSchema"];
      };
    };
    responses: {
      200: components["responses"]["accessors_list"];
      /** @description Unauthorized */
      401: {
        content: never;
      };
      /** @description Forbidden */
      403: {
        content: never;
      };
      /** @description Not Found */
      404: {
        content: never;
      };
    };
  };
  /**
   * Get Access Rules on Nexset
   * @description Returns a list of the access-control rules set for this Nexset.
   */
  get_nexset_accessors: {
    parameters: {
      path: {
        /** @description The unique ID of the Nexset. */
        data_set_id: number;
      };
    };
    responses: {
      200: components["responses"]["accessors_list"];
      /** @description Unauthorized */
      401: {
        content: never;
      };
      /** @description Forbidden */
      403: {
        content: never;
      };
      /** @description Not Found */
      404: {
        content: never;
      };
    };
  };
  /**
   * Add Access Rules on Nexset
   * @description Adds new access-control rules to this Nexset.
   */
  add_nexset_accessors: {
    parameters: {
      path: {
        /** @description The unique ID of the Nexset. */
        data_set_id: number;
      };
    };
    requestBody?: {
      content: {
        "application/vnd.nexla.api.v1+json": components["schemas"]["AccessorsRequestSchema"];
      };
    };
    responses: {
      200: components["responses"]["accessors_list"];
      /** @description Unauthorized */
      401: {
        content: never;
      };
      /** @description Forbidden */
      403: {
        content: never;
      };
      /** @description Not Found */
      404: {
        content: never;
      };
    };
  };
  /**
   * Replace Access Rules on Nexset
   * @description Replaces the list of access-control rules set for this Nexset. Existing rules will be removed from the Nexset, and only these new rules will be applied.
   */
  replace_nexset_accessors: {
    parameters: {
      path: {
        /** @description The unique ID of the Nexset. */
        data_set_id: number;
      };
    };
    requestBody?: {
      content: {
        "application/vnd.nexla.api.v1+json": components["schemas"]["AccessorsRequestSchema"];
      };
    };
    responses: {
      200: components["responses"]["accessors_list"];
      /** @description Unauthorized */
      401: {
        content: never;
      };
      /** @description Forbidden */
      403: {
        content: never;
      };
      /** @description Not Found */
      404: {
        content: never;
      };
    };
  };
  /**
   * Delete Access Rules on Nexset
   * @description Removes access-control rules from a Nexset. If no request body is provided, all rules associated with the Nexset will be removed.
   */
  delete_nexset_accessors: {
    parameters: {
      path: {
        /** @description The unique ID of the Nexset. */
        data_set_id: number;
      };
    };
    /** @description Optional list of accessors. */
    requestBody?: {
      content: {
        "application/vnd.nexla.api.v1+json": components["schemas"]["AccessorsRequestSchema"];
      };
    };
    responses: {
      200: components["responses"]["accessors_list"];
      /** @description Unauthorized */
      401: {
        content: never;
      };
      /** @description Forbidden */
      403: {
        content: never;
      };
      /** @description Not Found */
      404: {
        content: never;
      };
    };
  };
  /**
   * Get Access Rules on Data Sink
   * @description Returns a list of the access-control rules set for this data sink.
   */
  get_data_sink_accessors: {
    parameters: {
      path: {
        /** @description The unique ID of the data sink. */
        data_sink_id: number;
      };
    };
    responses: {
      200: components["responses"]["accessors_list"];
      /** @description Unauthorized */
      401: {
        content: never;
      };
      /** @description Forbidden */
      403: {
        content: never;
      };
      /** @description Not Found */
      404: {
        content: never;
      };
    };
  };
  /**
   * Add Access Rules on Data Sink
   * @description Adds new access-control rules to this data sink.
   */
  add_data_sink_accessors: {
    parameters: {
      path: {
        /** @description The unique ID of the data sink. */
        data_sink_id: number;
      };
    };
    requestBody?: {
      content: {
        "application/vnd.nexla.api.v1+json": components["schemas"]["AccessorsRequestSchema"];
      };
    };
    responses: {
      200: components["responses"]["accessors_list"];
      /** @description Unauthorized */
      401: {
        content: never;
      };
      /** @description Forbidden */
      403: {
        content: never;
      };
      /** @description Not Found */
      404: {
        content: never;
      };
    };
  };
  /**
   * Replace Access Rules on Data Sink
   * @description Replaces the list of access-control rules set for this data sink. Existing rules will be removed from the data sink, and only these new rules will be applied.
   */
  replace_data_sink_accessors: {
    parameters: {
      path: {
        /** @description The unique ID of the data sink. */
        data_sink_id: number;
      };
    };
    requestBody?: {
      content: {
        "application/vnd.nexla.api.v1+json": components["schemas"]["AccessorsRequestSchema"];
      };
    };
    responses: {
      200: components["responses"]["accessors_list"];
      /** @description Unauthorized */
      401: {
        content: never;
      };
      /** @description Forbidden */
      403: {
        content: never;
      };
      /** @description Not Found */
      404: {
        content: never;
      };
    };
  };
  /**
   * Delete Access Rules on Data Sink
   * @description Removes access-control rules from a data sink. If no request body is provided, all rules associated with the data sink will be removed.
   */
  delete_data_sink_accessors: {
    parameters: {
      path: {
        /** @description The unique ID of the data sink. */
        data_sink_id: number;
      };
    };
    /** @description Optional list of accessors. */
    requestBody?: {
      content: {
        "application/vnd.nexla.api.v1+json": components["schemas"]["AccessorsRequestSchema"];
      };
    };
    responses: {
      200: components["responses"]["accessors_list"];
      /** @description Unauthorized */
      401: {
        content: never;
      };
      /** @description Forbidden */
      403: {
        content: never;
      };
      /** @description Not Found */
      404: {
        content: never;
      };
    };
  };
  /**
   * Get Access Rules on Data Map
   * @description Returns a list of the access-control rules set for this data map.
   */
  get_data_map_accessors: {
    parameters: {
      path: {
        /** @description The unique ID of the data map. */
        data_map_id: number;
      };
    };
    responses: {
      200: components["responses"]["accessors_list"];
      /** @description Unauthorized */
      401: {
        content: never;
      };
      /** @description Forbidden */
      403: {
        content: never;
      };
      /** @description Not Found */
      404: {
        content: never;
      };
    };
  };
  /**
   * Add Access Rules on Data Map
   * @description Adds new access-control rules to this data map.
   */
  add_data_map_accessors: {
    parameters: {
      path: {
        /** @description The unique ID of the data map. */
        data_map_id: number;
      };
    };
    requestBody?: {
      content: {
        "application/vnd.nexla.api.v1+json": components["schemas"]["AccessorsRequestSchema"];
      };
    };
    responses: {
      200: components["responses"]["accessors_list"];
      /** @description Unauthorized */
      401: {
        content: never;
      };
      /** @description Forbidden */
      403: {
        content: never;
      };
      /** @description Not Found */
      404: {
        content: never;
      };
    };
  };
  /**
   * Replace Access Rules on Data Map
   * @description Replaces the list of access-control rules set for this data map. Existing rules will be removed from the data map, and only these new rules will be applied.
   */
  replace_data_map_accessors: {
    parameters: {
      path: {
        /** @description The unique ID of the data map. */
        data_map_id: number;
      };
    };
    requestBody?: {
      content: {
        "application/vnd.nexla.api.v1+json": components["schemas"]["AccessorsRequestSchema"];
      };
    };
    responses: {
      200: components["responses"]["accessors_list"];
      /** @description Unauthorized */
      401: {
        content: never;
      };
      /** @description Forbidden */
      403: {
        content: never;
      };
      /** @description Not Found */
      404: {
        content: never;
      };
    };
  };
  /**
   * Delete Access Rules on Data Map
   * @description Removes access-control rules from a data map. If no request body is provided, all rules associated with the data map will be removed.
   */
  delete_data_map_accessors: {
    parameters: {
      path: {
        /** @description The unique ID of the data map. */
        data_map_id: number;
      };
    };
    /** @description Optional list of accessors. */
    requestBody?: {
      content: {
        "application/vnd.nexla.api.v1+json": components["schemas"]["AccessorsRequestSchema"];
      };
    };
    responses: {
      200: components["responses"]["accessors_list"];
      /** @description Unauthorized */
      401: {
        content: never;
      };
      /** @description Forbidden */
      403: {
        content: never;
      };
      /** @description Not Found */
      404: {
        content: never;
      };
    };
  };
  /**
   * Get Access Rules on Data Credential
   * @description Returns a list of the access-control rules set for this data credential.
   */
  get_data_credential_accessors: {
    parameters: {
      path: {
        /** @description The unique ID of the data credential. */
        data_credential_id: number;
      };
    };
    responses: {
      200: components["responses"]["accessors_list"];
      /** @description Unauthorized */
      401: {
        content: never;
      };
      /** @description Forbidden */
      403: {
        content: never;
      };
      /** @description Not Found */
      404: {
        content: never;
      };
    };
  };
  /**
   * Add Access Rules on Data Credential
   * @description Adds new access-control rules to this data credential.
   */
  add_data_credential_accessors: {
    parameters: {
      path: {
        /** @description The unique ID of the data credential. */
        data_credential_id: number;
      };
    };
    requestBody?: {
      content: {
        "application/vnd.nexla.api.v1+json": components["schemas"]["AccessorsRequestSchema"];
      };
    };
    responses: {
      200: components["responses"]["accessors_list"];
      /** @description Unauthorized */
      401: {
        content: never;
      };
      /** @description Forbidden */
      403: {
        content: never;
      };
      /** @description Not Found */
      404: {
        content: never;
      };
    };
  };
  /**
   * Replace Access Rules on Data Credential
   * @description Replaces the list of access-control rules set for this data credential. Existing rules will be removed from the data credential, and only these new rules will be applied.
   */
  replace_data_credential_accessors: {
    parameters: {
      path: {
        /** @description The unique ID of the data credential. */
        data_credential_id: number;
      };
    };
    requestBody?: {
      content: {
        "application/vnd.nexla.api.v1+json": components["schemas"]["AccessorsRequestSchema"];
      };
    };
    responses: {
      200: components["responses"]["accessors_list"];
      /** @description Unauthorized */
      401: {
        content: never;
      };
      /** @description Forbidden */
      403: {
        content: never;
      };
      /** @description Not Found */
      404: {
        content: never;
      };
    };
  };
  /**
   * Delete Access Rules on Data Credential
   * @description Removes access-control rules from a data credential. If no request body is provided, all rules associated with the data credential will be removed.
   */
  delete_data_credential_accessors: {
    parameters: {
      path: {
        /** @description The unique ID of the data credential. */
        data_credential_id: number;
      };
    };
    /** @description Optional list of accessors. */
    requestBody?: {
      content: {
        "application/vnd.nexla.api.v1+json": components["schemas"]["AccessorsRequestSchema"];
      };
    };
    responses: {
      200: components["responses"]["accessors_list"];
      /** @description Unauthorized */
      401: {
        content: never;
      };
      /** @description Forbidden */
      403: {
        content: never;
      };
      /** @description Not Found */
      404: {
        content: never;
      };
    };
  };
  /**
   * Get Project Accessors
   * @description Returns a list of the access-control rules set for this project.
   */
  get_project_accessors: {
    parameters: {
      path: {
        /** @description The unique ID of the project. */
        project_id: number;
      };
    };
    responses: {
      200: components["responses"]["accessors_list"];
      /** @description Unauthorized */
      401: {
        content: never;
      };
      /** @description Forbidden */
      403: {
        content: never;
      };
      /** @description Not Found */
      404: {
        content: never;
      };
    };
  };
  /**
   * Add Project Accessors
   * @description Adds new access-control rules to this project.
   */
  add_project_accessors: {
    parameters: {
      path: {
        /** @description The unique ID of the project. */
        project_id: number;
      };
    };
    requestBody?: {
      content: {
        "application/vnd.nexla.api.v1+json": components["schemas"]["AccessorsRequestSchema"];
      };
    };
    responses: {
      200: components["responses"]["accessors_list"];
      /** @description Unauthorized */
      401: {
        content: never;
      };
      /** @description Forbidden */
      403: {
        content: never;
      };
      /** @description Not Found */
      404: {
        content: never;
      };
    };
  };
  /**
   * Replace Access Rules on Project
   * @description Replaces the list of access-control rules set for this project. Existing rules will be removed from the project, and only these new rules will be applied.
   */
  replace_project_accessors: {
    parameters: {
      path: {
        /** @description The unique ID of the project. */
        project_id: number;
      };
    };
    requestBody?: {
      content: {
        "application/vnd.nexla.api.v1+json": components["schemas"]["AccessorsRequestSchema"];
      };
    };
    responses: {
      200: components["responses"]["accessors_list"];
      /** @description Unauthorized */
      401: {
        content: never;
      };
      /** @description Forbidden */
      403: {
        content: never;
      };
      /** @description Not Found */
      404: {
        content: never;
      };
    };
  };
  /**
   * Delete Project Accessors
   * @description Removes access-control rules from a project. If no request body is provided, all rules associated with the project will be removed.
   */
  delete_project_accessors: {
    parameters: {
      path: {
        /** @description The unique ID of the project. */
        project_id: number;
      };
    };
    /** @description Optional list of accessors. */
    requestBody?: {
      content: {
        "application/vnd.nexla.api.v1+json": components["schemas"]["AccessorsRequestSchema"];
      };
    };
    responses: {
      200: components["responses"]["accessors_list"];
      /** @description Unauthorized */
      401: {
        content: never;
      };
      /** @description Forbidden */
      403: {
        content: never;
      };
      /** @description Not Found */
      404: {
        content: never;
      };
    };
  };
  /**
   * Get Access Rules on Flow
   * @description Returns a list of the access-control rules set for this flow.
   */
  get_flow_accessors: {
    parameters: {
      path: {
        /** @description The unique ID of the flow. */
        data_flow_id: string;
      };
    };
    responses: {
      200: components["responses"]["accessors_list"];
      /** @description Unauthorized */
      401: {
        content: never;
      };
      /** @description Forbidden */
      403: {
        content: never;
      };
      /** @description Not Found */
      404: {
        content: never;
      };
    };
  };
  /**
   * Add Access Rules on Flow
   * @description Adds new access-control rules to this data flow.
   */
  add_flow_accessors: {
    parameters: {
      path: {
        /** @description The unique ID of the data flow. */
        flow_id: string;
      };
    };
    requestBody?: {
      content: {
        "application/vnd.nexla.api.v1+json": components["schemas"]["AccessorsRequestSchema"];
      };
    };
    responses: {
      200: components["responses"]["accessors_list"];
      /** @description Unauthorized */
      401: {
        content: never;
      };
      /** @description Forbidden */
      403: {
        content: never;
      };
      /** @description Not Found */
      404: {
        content: never;
      };
    };
  };
  /**
   * Replace Access Rules on Flow
   * @description Replaces the list of access-control rules set for this flow. Existing rules will be removed from the flow, and only these new rules will be applied.
   */
  replace_flow_accessors: {
    parameters: {
      path: {
        /** @description The unique ID of the data flow. */
        flow_id: string;
      };
    };
    requestBody?: {
      content: {
        "application/vnd.nexla.api.v1+json": components["schemas"]["AccessorsRequestSchema"];
      };
    };
    responses: {
      200: components["responses"]["accessors_list"];
      /** @description Unauthorized */
      401: {
        content: never;
      };
      /** @description Forbidden */
      403: {
        content: never;
      };
      /** @description Not Found */
      404: {
        content: never;
      };
    };
  };
  /**
   * Delete Access Rules on Flow
   * @description Removes access-control rules from a data flow. If no request body is provided, all rules associated with the data flow will be removed.
   */
  delete_flow_accessors: {
    parameters: {
      path: {
        /** @description The unique ID of the data flow. */
        data_flow_id: string;
      };
    };
    /** @description Optional list of accessors. */
    requestBody?: {
      content: {
        "application/vnd.nexla.api.v1+json": components["schemas"]["AccessorsRequestSchema"];
      };
    };
    responses: {
      200: components["responses"]["accessors_list"];
      /** @description Unauthorized */
      401: {
        content: never;
      };
      /** @description Forbidden */
      403: {
        content: never;
      };
      /** @description Not Found */
      404: {
        content: never;
      };
    };
  };
  /**
   * Get Access Rules on Flow (Deprecated)
   * @description Returns a list of the access-control rules set for this data flow.
   *
   * > **Note**: This version of the endpoint has been deprecated. It uses a composite data flow id of the type `{resource_type}/{resource_id}`. See get_flow_accessors for a new version of this endpoint that uses unique `flow_id`.
   */
  "get_flow_accessors_(deprecated)": {
    parameters: {
      path: {
        /** @description The unique ID of the data flow. This ID is of the type `{resource_type}/{resource_id}`, where the resource is the root node of the flow - for example, `data_source/1001`. */
        data_flow_id: string;
      };
    };
    responses: {
      200: components["responses"]["accessors_list"];
      /** @description Unauthorized */
      401: {
        content: never;
      };
      /** @description Forbidden */
      403: {
        content: never;
      };
      /** @description Not Found */
      404: {
        content: never;
      };
    };
  };
  /**
   * Add Access Rules on Flow (Deprecated)
   * @description Add new access-control rules to this data flow. This version uses a composite data flow id of the type `{resource_type}/{resource_id}`.
   *
   * > **Note**: This version of the endpoint has been deprecated. It uses a composite data flow id of the type `{resource_type}/{resource_id}`. See add_flow_accessors for a new version of this endpoint that uses unique `flow_id`.
   */
  "add_flow_accessors_(deprecated)": {
    parameters: {
      path: {
        /** @description The unique ID of the data flow. This ID is of the type `{resource_type}/{resource_id}`, where the resource is the root node of the flow - for example, `data_source/1001`. */
        data_flow_id: string;
      };
    };
    requestBody?: {
      content: {
        "application/vnd.nexla.api.v1+json": components["schemas"]["AccessorsRequestSchema"];
      };
    };
    responses: {
      200: components["responses"]["accessors_list"];
      /** @description Unauthorized */
      401: {
        content: never;
      };
      /** @description Forbidden */
      403: {
        content: never;
      };
      /** @description Not Found */
      404: {
        content: never;
      };
    };
  };
  /**
   * Replace Access Rules on Flow (Deprecated)
   * @description Replace the list of access-control rules set for this data flow. Existing rules will be removed from the data flow, and only these new rules will be applied. This version uses a composite data flow id of the type `{resource_type}/{resource_id}`.
   *
   * > **Note**: This version of the endpoint has been deprecated. It uses a composite data flow id of the type `{resource_type}/{resource_id}`. See replace_flow_accessors for a new version of this endpoint that uses unique `flow_id`.
   */
  "replace_flow_accessors_(deprecated)": {
    parameters: {
      path: {
        /** @description The unique ID of the data flow. This ID is of the type `{resource_type}/{resource_id}`, where the resource is the root node of the flow - for example, `data_source/1001`. */
        data_flow_id: string;
      };
    };
    requestBody?: {
      content: {
        "application/vnd.nexla.api.v1+json": components["schemas"]["AccessorsRequestSchema"];
      };
    };
    responses: {
      200: components["responses"]["accessors_list"];
      /** @description Unauthorized */
      401: {
        content: never;
      };
      /** @description Forbidden */
      403: {
        content: never;
      };
      /** @description Not Found */
      404: {
        content: never;
      };
    };
  };
  /**
   * Delete Access Rules on Flow (Deprecated)
   * @description Remove access-control rules from a data flow. If no request body is provided, all rules associated with the data flow will be removed. This version uses a composite data flow id of the type `{resource_type}/{resource_id}`.
   *
   * > **Note**: This version of the endpoint has been deprecated. It uses a composite data flow id of the type `{resource_type}/{resource_id}`. See delete_flow_accessors for a new version of this endpoint that uses unique `flow_id`.
   */
  "delete_flow_accessors_(deprecated)": {
    parameters: {
      path: {
        /** @description The unique ID of the data flow. This ID is of the type `{resource_type}/{resource_id}`, where the resource is the root node of the flow - for example, `data_source/1001`. */
        data_flow_id: string;
      };
    };
    /** @description Optional list of accessors. */
    requestBody?: {
      content: {
        "application/vnd.nexla.api.v1+json": components["schemas"]["AccessorsRequestSchema"];
      };
    };
    responses: {
      200: components["responses"]["accessors_list"];
      /** @description Unauthorized */
      401: {
        content: never;
      };
      /** @description Forbidden */
      403: {
        content: never;
      };
      /** @description Not Found */
      404: {
        content: never;
      };
    };
  };
  /**
   * Get Access Rules on Data Schema
   * @description Returns a list of the access-control rules set for this data schema.
   */
  get_data_schema_accessors: {
    parameters: {
      path: {
        /** @description The unique ID of the data schema. */
        data_schema_id: number;
      };
    };
    responses: {
      200: components["responses"]["accessors_list"];
      /** @description Unauthorized */
      401: {
        content: never;
      };
      /** @description Forbidden */
      403: {
        content: never;
      };
      /** @description Not Found */
      404: {
        content: never;
      };
    };
  };
  /**
   * Add Access Rules on Data Schema
   * @description Adds new access-control rules to this data schema.
   */
  add_data_schema_accessors: {
    parameters: {
      path: {
        /** @description The unique ID of the data schema. */
        data_schema_id: number;
      };
    };
    requestBody?: {
      content: {
        "application/vnd.nexla.api.v1+json": components["schemas"]["AccessorsRequestSchema"];
      };
    };
    responses: {
      200: components["responses"]["accessors_list"];
      /** @description Unauthorized */
      401: {
        content: never;
      };
      /** @description Forbidden */
      403: {
        content: never;
      };
      /** @description Not Found */
      404: {
        content: never;
      };
    };
  };
  /**
   * Replace Access Rules on Data Schema
   * @description Replaces the list of access-control rules set for this data schema. Existing rules will be removed from the data schema, and only these new rules will be applied.
   */
  replace_data_schema_accessors: {
    parameters: {
      path: {
        /** @description The unique ID of the data schema. */
        data_schema_id: number;
      };
    };
    requestBody?: {
      content: {
        "application/vnd.nexla.api.v1+json": components["schemas"]["AccessorsRequestSchema"];
      };
    };
    responses: {
      200: components["responses"]["accessors_list"];
      /** @description Unauthorized */
      401: {
        content: never;
      };
      /** @description Forbidden */
      403: {
        content: never;
      };
      /** @description Not Found */
      404: {
        content: never;
      };
    };
  };
  /**
   * Delete Access Rules on Data Schema
   * @description Removes access-control rules from a data schema. If no request body is provided, all rules associated with the data schema will be removed.
   */
  delete_data_schema_accessors: {
    parameters: {
      path: {
        /** @description The unique ID of the data schema. */
        data_schema_id: number;
      };
    };
    /** @description Optional list of accessors. */
    requestBody?: {
      content: {
        "application/vnd.nexla.api.v1+json": components["schemas"]["AccessorsRequestSchema"];
      };
    };
    responses: {
      200: components["responses"]["accessors_list"];
      /** @description Unauthorized */
      401: {
        content: never;
      };
      /** @description Forbidden */
      403: {
        content: never;
      };
      /** @description Not Found */
      404: {
        content: never;
      };
    };
  };
  /**
   * Get Access Rules on Document
   * @description Returns a list of the access-control rules set for this document.
   */
  get_doc_container_accessors: {
    parameters: {
      path: {
        /** @description The unique ID of the document. */
        doc_container_id: number;
      };
    };
    responses: {
      200: components["responses"]["accessors_list"];
      /** @description Unauthorized */
      401: {
        content: never;
      };
      /** @description Forbidden */
      403: {
        content: never;
      };
      /** @description Not Found */
      404: {
        content: never;
      };
    };
  };
  /**
   * Add Access Rules on Document
   * @description Adds new access-control rules to this document.
   */
  add_doc_container_accessors: {
    parameters: {
      path: {
        /** @description The unique ID of the document container. */
        doc_container_id: number;
      };
    };
    requestBody?: {
      content: {
        "application/vnd.nexla.api.v1+json": components["schemas"]["AccessorsRequestSchema"];
      };
    };
    responses: {
      200: components["responses"]["accessors_list"];
      /** @description Unauthorized */
      401: {
        content: never;
      };
      /** @description Forbidden */
      403: {
        content: never;
      };
      /** @description Not Found */
      404: {
        content: never;
      };
    };
  };
  /**
   * Replace Access Rules on Document
   * @description Replaces the list of access-control rules set for this document. Existing rules will be removed from the document, and only these new rules will be applied.
   */
  replace_doc_container_accessors: {
    parameters: {
      path: {
        /** @description The unique ID of the document. */
        doc_container_id: number;
      };
    };
    requestBody?: {
      content: {
        "application/vnd.nexla.api.v1+json": components["schemas"]["AccessorsRequestSchema"];
      };
    };
    responses: {
      200: components["responses"]["accessors_list"];
      /** @description Unauthorized */
      401: {
        content: never;
      };
      /** @description Forbidden */
      403: {
        content: never;
      };
      /** @description Not Found */
      404: {
        content: never;
      };
    };
  };
  /**
   * Delete Access Rules on Document
   * @description Removes access-control rules from a document. If no request body is provided, all rules associated with the document will be removed.
   */
  delete_doc_container_accessors: {
    parameters: {
      path: {
        /** @description The unique ID of the document. */
        doc_container_id: number;
      };
    };
    /** @description Optional list of accessors. */
    requestBody?: {
      content: {
        "application/vnd.nexla.api.v1+json": components["schemas"]["AccessorsRequestSchema"];
      };
    };
    responses: {
      200: components["responses"]["accessors_list"];
      /** @description Unauthorized */
      401: {
        content: never;
      };
      /** @description Forbidden */
      403: {
        content: never;
      };
      /** @description Not Found */
      404: {
        content: never;
      };
    };
  };
  /**
   * Get Access Rules on Code Container
   * @description Returns a list of the access-control rules set for this code container.
   */
  get_code_container_accessors: {
    parameters: {
      path: {
        /** @description The unique ID of the code container. */
        code_container_id: number;
      };
    };
    responses: {
      200: components["responses"]["accessors_list"];
      /** @description Unauthorized */
      401: {
        content: never;
      };
      /** @description Forbidden */
      403: {
        content: never;
      };
      /** @description Not Found */
      404: {
        content: never;
      };
    };
  };
  /**
   * Add Access Rules on Code Container
   * @description Adds new access-control rules to this code container.
   */
  add_code_container_accessors: {
    parameters: {
      path: {
        /** @description The unique ID of the code container. */
        code_container_id: number;
      };
    };
    requestBody?: {
      content: {
        "application/vnd.nexla.api.v1+json": components["schemas"]["AccessorsRequestSchema"];
      };
    };
    responses: {
      200: components["responses"]["accessors_list"];
      /** @description Unauthorized */
      401: {
        content: never;
      };
      /** @description Forbidden */
      403: {
        content: never;
      };
      /** @description Not Found */
      404: {
        content: never;
      };
    };
  };
  /**
   * Replace Access Rules on Code Container
   * @description Replaces the list of access-control rules set for this code container. Existing rules will be removed from the code container, and only these new rules will be applied.
   */
  replace_code_container_accessors: {
    parameters: {
      path: {
        /** @description The unique ID of the code container. */
        code_container_id: number;
      };
    };
    requestBody?: {
      content: {
        "application/vnd.nexla.api.v1+json": components["schemas"]["AccessorsRequestSchema"];
      };
    };
    responses: {
      200: components["responses"]["accessors_list"];
      /** @description Unauthorized */
      401: {
        content: never;
      };
      /** @description Forbidden */
      403: {
        content: never;
      };
      /** @description Not Found */
      404: {
        content: never;
      };
    };
  };
  /**
   * Delete Access Rules on Code Container
   * @description Removes access-control rules from a code container. If no request body is provided, all rules associated with the code container will be removed.
   */
  delete_code_container_accessors: {
    parameters: {
      path: {
        /** @description The unique ID of the code container. */
        code_container_id: number;
      };
    };
    /** @description Optional list of accessors. */
    requestBody?: {
      content: {
        "application/vnd.nexla.api.v1+json": components["schemas"]["AccessorsRequestSchema"];
      };
    };
    responses: {
      200: components["responses"]["accessors_list"];
      /** @description Unauthorized */
      401: {
        content: never;
      };
      /** @description Forbidden */
      403: {
        content: never;
      };
      /** @description Not Found */
      404: {
        content: never;
      };
    };
  };
  /**
   * Get Team Accessors
   * @description Returns a list of the access-control rules set for this team.
   */
  get_team_accessors: {
    parameters: {
      path: {
        /** @description The unique ID of the team. */
        team_id: number;
      };
    };
    responses: {
      200: components["responses"]["accessors_list"];
      /** @description Unauthorized */
      401: {
        content: never;
      };
      /** @description Forbidden */
      403: {
        content: never;
      };
      /** @description Not Found */
      404: {
        content: never;
      };
    };
  };
  /**
   * Add Team Accessors
   * @description Adds new access-control rules to this team.
   */
  add_team_accessors: {
    parameters: {
      path: {
        /** @description The unique ID of the team. */
        team_id: number;
      };
    };
    requestBody?: {
      content: {
        "application/vnd.nexla.api.v1+json": components["schemas"]["AccessorsRequestSchema"];
      };
    };
    responses: {
      200: components["responses"]["accessors_list"];
      /** @description Unauthorized */
      401: {
        content: never;
      };
      /** @description Forbidden */
      403: {
        content: never;
      };
      /** @description Not Found */
      404: {
        content: never;
      };
    };
  };
  /**
   * Replace Team Accessors List
   * @description Replaces the list of access-control rules set for this team. Existing rules will be removed from the team, and only these new rules will be applied.
   */
  replace_team_accessors: {
    parameters: {
      path: {
        /** @description The unique ID of the team. */
        team_id: number;
      };
    };
    requestBody?: {
      content: {
        "application/vnd.nexla.api.v1+json": components["schemas"]["AccessorsRequestSchema"];
      };
    };
    responses: {
      200: components["responses"]["accessors_list"];
      /** @description Unauthorized */
      401: {
        content: never;
      };
      /** @description Forbidden */
      403: {
        content: never;
      };
      /** @description Not Found */
      404: {
        content: never;
      };
    };
  };
  /**
   * Delete Team Accessors
   * @description Removes access-control rules from a team. If no request body is provided, all rules associated with the team will be removed.
   */
  delete_team_accessors: {
    parameters: {
      path: {
        /** @description The unique ID of the team. */
        team_id: number;
      };
    };
    /** @description Optional list of accessors. */
    requestBody?: {
      content: {
        "application/vnd.nexla.api.v1+json": components["schemas"]["AccessorsRequestSchema"];
      };
    };
    responses: {
      200: components["responses"]["accessors_list"];
      /** @description Unauthorized */
      401: {
        content: never;
      };
      /** @description Forbidden */
      403: {
        content: never;
      };
      /** @description Not Found */
      404: {
        content: never;
      };
    };
  };
  /**
   * Get marketplace domains.
   * @description Use this endpoint to fetch marketplace domains. You need a read permission for the org.
   */
  get_domains: {
    parameters: {
      header?: {
        Accept?: components["parameters"]["accept"];
      };
    };
    responses: {
      200: components["responses"]["domains_many"];
      /** @description Forbidden */
      403: {
        content: never;
      };
    };
  };
  /**
   * Create marketplace domains.
   * @description Use this endpoint to create marketplace domains. You need a manage permission for the org.
   */
  create_domains: {
    parameters: {
      header?: {
        Accept?: components["parameters"]["accept"];
      };
    };
    requestBody?: {
      content: {
        "application/vnd.nexla.api.v1+json": components["schemas"]["MarketplaceDomainCreate"];
      };
    };
    responses: {
      200: components["responses"]["domains_many"];
      /** @description Unauthorized */
      401: {
        content: never;
      };
      /** @description Forbidden */
      403: {
        content: never;
      };
    };
  };
  /**
   * Get marketplace domains for organization.
   * @description Use this endpoint to fetch marketplace domains for a specific organization. You need a read permission for the org.
   */
  get_domains_for_org: {
    parameters: {
      query: {
        /** @description The organization ID to filter domains by */
        org_id: number;
      };
      header?: {
        Accept?: components["parameters"]["accept"];
      };
    };
    responses: {
      200: components["responses"]["domains_many"];
      /** @description Forbidden */
      403: {
        content: never;
      };
    };
  };
  /**
   * Get a single marketplace domain.
   * @description Use this endpoint to fetch a marketplace domain. You need a read permission for the domain.
   */
  get_domain: {
    parameters: {
      header?: {
        Accept?: components["parameters"]["accept"];
      };
      path: {
        /** @description The unique ID of the domain that needs to be fetched. */
        domain_id: number;
      };
    };
    responses: {
      200: components["responses"]["domains_one"];
      /** @description Forbidden */
      403: {
        content: never;
      };
    };
  };
  /**
   * Update a single marketplace domain.
   * @description Use this endpoint to update a marketplace domain. You need a manage permission for the domain.
   */
  update_domain: {
    parameters: {
      header?: {
        Accept?: components["parameters"]["accept"];
      };
      path: {
        /** @description The unique ID of the domain that needs to be updated. */
        domain_id: number;
      };
    };
    requestBody?: {
      content: {
        "application/vnd.nexla.api.v1+json": components["schemas"]["MarketplaceDomainCreate"];
      };
    };
    responses: {
      200: components["responses"]["domains_one"];
      /** @description Unauthorized */
      401: {
        content: never;
      };
      /** @description Forbidden */
      403: {
        content: never;
      };
    };
  };
  /**
   * Create a single marketplace domain.
   * @description Use this endpoint to create a marketplace domain. You need a manage permission for the org.
   */
  create_domain: {
    parameters: {
      header?: {
        Accept?: components["parameters"]["accept"];
      };
    };
    requestBody?: {
      content: {
        "application/vnd.nexla.api.v1+json": components["schemas"]["MarketplaceDomainCreate"];
      };
    };
    responses: {
      200: components["responses"]["domains_one"];
      /** @description Unauthorized */
      401: {
        content: never;
      };
      /** @description Forbidden */
      403: {
        content: never;
      };
    };
  };
  /**
   * Delete a single marketplace domain.
   * @description Use this endpoint to delete a marketplace domain. You need a manage permission for the domain to delete it.
   */
  delete_domain: {
    parameters: {
      header?: {
        Accept?: components["parameters"]["accept"];
      };
      path: {
        /** @description The unique ID of the domain that needs to be deleted. */
        domain_id: number;
      };
    };
    responses: {
      /** @description Successfully deleted */
      200: {
        content: never;
      };
      /** @description Unauthorized */
      401: {
        content: never;
      };
      /** @description Forbidden */
      403: {
        content: never;
      };
    };
  };
  /**
   * Get marketplace items for a domain.
   * @description Use this endpoint to fetch marketplace items for a domain. You need a read permission for the domain.
   */
  get_domain_items: {
    parameters: {
      header?: {
        Accept?: components["parameters"]["accept"];
      };
      path: {
        /** @description The unique ID of the domain. */
        domain_id: number;
      };
    };
    responses: {
      200: components["responses"]["domain_items_many"];
      /** @description Forbidden */
      403: {
        content: never;
      };
    };
  };
  /**
   * Create a marketplace item for a domain.
   * @description Use this endpoint to create a marketplace item for a domain. You need a manage permission for the domain.
   */
  create_domain_item: {
    parameters: {
      header?: {
        Accept?: components["parameters"]["accept"];
      };
      path: {
        /** @description The unique ID of the domain. */
        domain_id: number;
      };
    };
    requestBody?: {
      content: {
        "application/vnd.nexla.api.v1+json": components["schemas"]["MarketplaceDomainsItemCreate"];
      };
    };
    responses: {
      200: components["responses"]["domain_items_many"];
      /** @description Unauthorized */
      401: {
        content: never;
      };
      /** @description Forbidden */
      403: {
        content: never;
      };
    };
  };
  /**
   * Get custodians for a marketplace domain.
   * @description Use this endpoint to fetch custodians for a marketplace domain. You need a read permission for the domain.
   */
  get_domain_custodians: {
    parameters: {
      header?: {
        Accept?: components["parameters"]["accept"];
      };
      path: {
        /** @description The unique ID of the domain. */
        domain_id: number;
      };
    };
    responses: {
      200: components["responses"]["custodians_many"];
      /** @description Unauthorized */
      401: {
        content: never;
      };
      /** @description Forbidden */
      403: {
        content: never;
      };
    };
  };
  /**
   * Update custodians for a marketplace domain.
   * @description Use this endpoint to update custodians for a marketplace domain. You need a manage permission for the domain.
   */
  update_domain_custodians: {
    parameters: {
      header?: {
        Accept?: components["parameters"]["accept"];
      };
      path: {
        /** @description The unique ID of the domain. */
        domain_id: number;
      };
    };
    requestBody?: {
      content: {
        "application/vnd.nexla.api.v1+json": components["schemas"]["CustodiansPayload"];
      };
    };
    responses: {
      200: components["responses"]["custodians_many"];
      /** @description Unauthorized */
      401: {
        content: never;
      };
      /** @description Forbidden */
      403: {
        content: never;
      };
    };
  };
  /**
   * Add custodians to a marketplace domain.
   * @description Use this endpoint to add custodians to a marketplace domain. You need a manage permission for the domain.
   */
  add_domain_custodians: {
    parameters: {
      header?: {
        Accept?: components["parameters"]["accept"];
      };
      path: {
        /** @description The unique ID of the domain. */
        domain_id: number;
      };
    };
    requestBody?: {
      content: {
        "application/vnd.nexla.api.v1+json": components["schemas"]["CustodiansPayload"];
      };
    };
    responses: {
      200: components["responses"]["custodians_many"];
      /** @description Unauthorized */
      401: {
        content: never;
      };
      /** @description Forbidden */
      403: {
        content: never;
      };
    };
  };
  /**
   * Remove custodians from a marketplace domain.
   * @description Use this endpoint to remove custodians from a marketplace domain. You need a manage permission for the domain.
   */
  remove_domain_custodians: {
    parameters: {
      header?: {
        Accept?: components["parameters"]["accept"];
      };
      path: {
        /** @description The unique ID of the domain that needs to be deleted. */
        domain_id: number;
      };
    };
    requestBody?: {
      content: {
        "application/vnd.nexla.api.v1+json": components["schemas"]["CustodiansPayload"];
      };
    };
    responses: {
      /** @description Successfully deleted */
      200: {
        content: never;
      };
      /** @description Unauthorized */
      401: {
        content: never;
      };
      /** @description Forbidden */
      403: {
        content: never;
      };
    };
  };
  /**
   * Get organization custodians.
   * @description Use this endpoint to fetch custodians of organization. Org read permission is required to access this endpoint.
   */
  get_org_custodians: {
    parameters: {
      header?: {
        Accept?: components["parameters"]["accept"];
      };
      path: {
        /** @description The unique ID of the organization. */
        org_id: number;
      };
    };
    responses: {
      200: components["responses"]["custodians_many"];
      /** @description Forbidden */
      403: {
        content: never;
      };
    };
  };
  /**
   * Update organization custodians.
   * @description Users listed within the request body will be updated as custodians for the organization. Users can be identified by their email or id.
   */
  update_org_custodians: {
    parameters: {
      header?: {
        Accept?: components["parameters"]["accept"];
      };
      path: {
        /** @description The unique ID of the organization. */
        org_id: number;
      };
    };
    requestBody?: {
      content: {
        "application/vnd.nexla.api.v1+json": components["schemas"]["CustodiansPayload"];
      };
    };
    responses: {
      200: components["responses"]["custodians_many"];
      /** @description Unauthorized */
      401: {
        content: never;
      };
      /** @description Forbidden */
      403: {
        content: never;
      };
    };
  };
  /**
   * Add organization custodians.
   * @description Users listed within the request body will be added as custodians to the organization. Users can be identified by their email or id.
   */
  add_org_custodians: {
    parameters: {
      header?: {
        Accept?: components["parameters"]["accept"];
      };
      path: {
        /** @description The unique ID of the organization. */
        org_id: number;
      };
    };
    requestBody?: {
      content: {
        "application/vnd.nexla.api.v1+json": components["schemas"]["CustodiansPayload"];
      };
    };
    responses: {
      200: components["responses"]["custodians_many"];
      /** @description Unauthorized */
      401: {
        content: never;
      };
      /** @description Forbidden */
      403: {
        content: never;
      };
    };
  };
  /**
   * Remove organization custodians.
   * @description Users listed within the request body will be deleted as custodians from the organization. Users can be identified by their email or id.
   */
  remove_org_custodians: {
    parameters: {
      header?: {
        Accept?: components["parameters"]["accept"];
      };
      path: {
        /** @description The unique ID of the organization. */
        org_id: number;
      };
    };
    requestBody?: {
      content: {
        "application/vnd.nexla.api.v1+json": components["schemas"]["CustodiansPayload"];
      };
    };
    responses: {
      /** @description Successfully deleted */
      200: {
        content: never;
      };
      /** @description Unauthorized */
      401: {
        content: never;
      };
      /** @description Forbidden */
      403: {
        content: never;
      };
    };
  };
  /**
   * Login with Basic Authentication
   * @description Use this endpoint for authentication if your organization allows basic authentication. A successful authentication attempt will result in an `access_token` that can be used to make authenticated requests to other API endpoints. The `access_token` automatically expires after a fixed duration, but you can also call the `/logout` endpoint to invalidate the access token at the end of your session.
   *
   * Nexla supports various methods of authentication, including Basic (email/password), Google SSO, and custom SAML- or OIDC-based SSO. One or more of these methods might be allowed in any organization, depending on the configuration chosen by the administrators. Instead of using this endpoint to start a session programmatically, we recommend performing authentication through the Nexla UI and using the Nexla Session Token (available in Tools >> Nexla Session Token) to connect to the API programmatically.
   *
   * > Note: A user might belong to multiple organizations. This method initiates an authenticated session in their default organization.
   */
  login_with_basic_auth: {
    responses: {
      200: components["responses"]["token"];
      /** @description Unauthorized */
      401: {
        content: never;
      };
    };
  };
  /**
   * Logout
   * @description Ends the current session and invalidates the `NexlaSessionToken` for future requests.
   */
  logout: {
    responses: {
      /** @description OK */
      200: {
        content: never;
      };
      /** @description Bad Request */
      400: {
        content: never;
      };
    };
  };
  /**
   * Get current rate limit and usage
   * @description Returns the API rate limiting categories and the user's current usage
   */
  limits: {
    responses: {
      /** @description Current usage for the types of endpoints */
      200: {
        content: {
          "application/json": {
            second?: {
              common?: {
                limit?: number;
                count?: number;
              };
              light?: {
                limit?: number;
                count?: number;
              };
              medium?: {
                limit?: number;
                count?: number;
              };
              high?: {
                limit?: number;
                count?: number;
              };
            };
            day?: {
              common?: {
                limit?: number;
                count?: number;
              };
              light?: {
                limit?: number;
                count?: number;
              };
              medium?: {
                limit?: number;
                count?: number;
              };
              high?: {
                limit?: number;
                count?: number;
              };
            };
          };
        };
      };
      /** @description Forbidden */
      403: {
        content: never;
      };
      /** @description Not found error */
      404: {
        content: never;
      };
    };
  };
  /**
   * Get auth configs.
   * @description Get the authentication configurations by it's ID.
   */
  get_api_auth_configs: {
    parameters: {
      header?: {
        Accept?: components["parameters"]["accept"];
      };
      path: {
        /** @description ID of the authentication configuration. */
        auth_config_id: number;
      };
    };
    responses: {
      200: components["responses"]["auth_config_one"];
      /** @description Forbidden */
      403: {
        content: never;
      };
    };
  };
  /**
   * Create auth config.
   * @description Create a new authentication configuration for the API.
   */
  create_api_auth_config: {
    requestBody?: {
      content: {
        "application/json": components["schemas"]["AuthConfigPayload"];
      };
    };
    responses: {
      200: components["responses"]["auth_config_one"];
      /** @description Bad Request */
      400: {
        content: never;
      };
      /** @description Forbidden */
      403: {
        content: never;
      };
    };
  };
  /**
   * Get all auth configs.
   * @description Get the authentication configurations for the API. This will return all auth configs. Super-admin privilege is required.
   */
  get_all_api_auth_configs: {
    parameters: {
      header?: {
        Accept?: components["parameters"]["accept"];
      };
    };
    responses: {
      200: components["responses"]["auth_configs_many"];
      /** @description Forbidden */
      403: {
        content: never;
      };
    };
  };
  /**
   * Update auth config (enable/disable).
   * @description Update an authentication configuration for the API.
   */
  update_api_auth_config: {
    parameters: {
      header?: {
        Accept?: components["parameters"]["accept"];
      };
      path: {
        /** @description The unique ID of the organization for which settings will be returned. */
        org_id: number;
        /** @description The unique ID of the authentication setting that needs to be updated. */
        auth_setting_id: number;
      };
    };
    requestBody?: {
      content: {
        "application/json": components["schemas"]["AuthSettingPayload"];
      };
    };
    responses: {
      200: components["responses"]["auth_setting_one"];
      /** @description Bad Request */
      400: {
        content: never;
      };
      /** @description Forbidden */
      403: {
        content: never;
      };
      /** @description Not Found */
      404: {
        content: never;
      };
    };
  };
  /**
   * Delete auth config.
   * @description Delete an authentication configuration for the API.
   */
  delete_api_auth_config: {
    parameters: {
      path: {
        /** @description The unique ID of the organization that needs to be deleted. */
        auth_config_id: number;
      };
    };
    responses: {
      /** @description Success */
      200: {
        content: never;
      };
      /** @description Forbidden */
      403: {
        content: never;
      };
    };
  };
  /**
   * Sign Up
   * @description This endpoint is used for users to register in the system. Once signup process is completed (email is verified, manual approval by admin may be required),
   * user can set a password and login to the system.
   * Email verification link is sent to the email provided by the user.
   *
   * Optionally, it allows for logged in user to be called. In this case, email verification will be skipped, and new org is created immediately.
   */
  self_sign_up: {
    requestBody?: {
      content: {
        "application/json": components["schemas"]["SignupRequest"];
      };
    };
    responses: {
      /** @description Successful response. */
      200: {
        content: never;
      };
      /** @description Bad Request in case of invalid input, unacceptable email etc. */
      400: {
        content: never;
      };
    };
  };
  /**
   * Verify Email
   * @description This endpoint is used to verify the email address of the user.
   * The user will be able to set a password and login to the system after the email is verified (unless manual admin approval is required).
   */
  verify_email: {
    parameters: {
      query: {
        /** @description The token received in the email. */
        token: string;
      };
    };
    responses: {
      /** @description Successful response. */
      200: {
        content: never;
      };
      /** @description Bad Request */
      400: {
        content: never;
      };
    };
  };
  /**
   * List Self Sign Up Requests
   * @description Returns a list of self sign up requests for an admin.
   */
  get_self_signup_requests: {
    responses: {
      200: components["responses"]["self_signup_requests_response"];
      /** @description Forbidden */
      403: {
        content: never;
      };
    };
  };
  /**
   * Approve Self Sign Up Request
   * @description This endpoint is used to approve a self sign up request. System admin access required.
   * The user will be able to set a password and login to the system after the request is approved.
   */
  approve_self_sign_up_request: {
    parameters: {
      path: {
        /** @description The ID of the self sign up request. */
        request_id: string;
      };
    };
    responses: {
      /** @description Successful response. */
      200: {
        content: never;
      };
      /** @description Forbidden */
      403: {
        content: never;
      };
    };
  };
  /**
   * List self-sign-up blocked domains for admins.
   * @description Returns a list of domains that are blocked for self-sign-up. Requires admin access.
   */
  get_self_signup_blocked_domains: {
    responses: {
      200: components["responses"]["self_signup_blocked_domains_response"];
      /** @description Forbidden */
      403: {
        content: never;
      };
    };
  };
  /**
   * Add self-sign-up blocked domain for admins.
   * @description Adds a domain to the list of domains that are blocked for self-sign-up. Requires admin access.
   */
  add_self_signup_blocked_domain: {
    requestBody?: {
      content: {
        "application/json": {
          /**
           * @description The domain to block for self-sign-up.
           * @example example-domain.com
           */
          domain?: string;
        };
      };
    };
    responses: {
      /** @description Successful response. */
      200: {
        content: never;
      };
      /** @description Bad Request */
      400: {
        content: never;
      };
      /** @description Forbidden */
      403: {
        content: never;
      };
    };
  };
  /**
   * Update self-sign-up blocked domain for admins.
   * @description Updates a domain in the list of domains that are blocked for self-sign-up. Requires admin access.
   */
  update_self_signup_blocked_domain: {
    parameters: {
      path: {
        /** @description The ID of the self sign up blocked domain. */
        domain_id: string;
      };
    };
    requestBody?: {
      content: {
        "application/json": {
          /**
           * @description The domain to block for self-sign-up.
           * @example example-domain.com
           */
          domain?: string;
        };
      };
    };
    responses: {
      /** @description Successful response. */
      200: {
        content: never;
      };
      /** @description Bad Request */
      400: {
        content: never;
      };
      /** @description Forbidden */
      403: {
        content: never;
      };
      /** @description Not found error */
      404: {
        content: never;
      };
    };
  };
  /**
   * Delete self-sign-up blocked domain for admins.
   * @description Deletes a domain from the list of domains that are blocked for self-sign-up. Requires admin access.
   */
  delete_self_signup_blocked_domain: {
    parameters: {
      path: {
        /** @description The ID of the self sign up blocked domain. */
        domain_id: string;
      };
    };
    responses: {
      /** @description Successful response. */
      200: {
        content: never;
      };
      /** @description Forbidden */
      403: {
        content: never;
      };
      /** @description Not found error */
      404: {
        content: never;
      };
    };
  };
  /**
   * Get auth settings for org.
   * @description Get the authentication settings for the given org. This allows to enable or disable specific auth configs for the org.
   */
  get_api_auth_settings: {
    parameters: {
      header?: {
        Accept?: components["parameters"]["accept"];
      };
      path: {
        /** @description The unique ID of the organization for which settings will be returned. */
        org_id: number;
      };
    };
    responses: {
      200: components["responses"]["auth_settings_many"];
      /** @description Forbidden */
      403: {
        content: never;
      };
    };
  };
  /**
   * Get async operations list for current user.
   * @description Get a list of async operations for current user. Returns type, arguments, status, results etc.
   */
  get_async_tasks: {
    parameters: {
      header?: {
        Accept?: components["parameters"]["accept"];
      };
    };
    responses: {
      200: components["responses"]["async_tasks_many"];
      /** @description Unauthorized */
      401: {
        content: never;
      };
    };
  };
  /**
   * Create an async operation.
   * @description Create an async operation. Returns the task id and other related data. Checks if the user has permission to create the task with all entities, and other preconditions.
   */
  create_async_task: {
    requestBody?: {
      content: {
        "application/json": components["schemas"]["AsyncTaskPayload"];
      };
    };
    responses: {
      200: components["responses"]["async_task_one"];
      /** @description Bad Request (e.g. invalid arguments) */
      400: {
        content: never;
      };
      /** @description Unauthorized */
      401: {
        content: never;
      };
      /** @description Forbidden */
      403: {
        content: never;
      };
    };
  };
  /**
   * Get async operations list for current user of a specific type.
   * @description Get a list of async operations for current user of a specific type. Returns type, arguments, status, results etc.
   */
  get_async_tasks_of_type: {
    parameters: {
      header?: {
        Accept?: components["parameters"]["accept"];
      };
      path: {
        /** @description The type of the task. */
        task_type: components["schemas"]["async_task_types"];
      };
    };
    responses: {
      200: components["responses"]["async_tasks_many"];
      /** @description Unauthorized */
      401: {
        content: never;
      };
    };
  };
  /**
   * Get async operations list for current user by status
   * @description Get a list of async operations for current user of a specific type. Returns type, arguments, status, results etc.
   */
  get_async_tasks_by_status: {
    parameters: {
      header?: {
        Accept?: components["parameters"]["accept"];
      };
      path: {
        /** @description The status of tasks. */
        status: components["schemas"]["async_task_statuses"];
      };
    };
    responses: {
      200: components["responses"]["async_tasks_many"];
      /** @description Unauthorized */
      401: {
        content: never;
      };
    };
  };
  /**
   * Get async operation types
   * @description Get a list of async operation types. Returns type, arguments, status, results etc.
   */
  get_async_task_types: {
    parameters: {
      header?: {
        Accept?: components["parameters"]["accept"];
      };
    };
    responses: {
      /** @description Success */
      200: {
        content: {
          "application/json": string[];
        };
      };
      /** @description Unauthorized */
      401: {
        content: never;
      };
    };
  };
  /**
   * Get async operation arguments for a specific type with descriptions
   * @description Get a list of async operation arguments for a specific type with descriptions.
   */
  get_async_tasks_explain_arguments: {
    parameters: {
      header?: {
        Accept?: components["parameters"]["accept"];
      };
      path: {
        /** @description The type of the task. */
        task_type: components["schemas"]["async_task_types"];
      };
    };
    responses: {
      /** @description Success. The response is a dictionary with the argument names as keys and the descriptions as values. */
      200: {
        content: {
          "application/json": Record<string, never>;
        };
      };
      /** @description Not Found */
      404: {
        content: never;
      };
    };
  };
  /**
   * Get async operation by ID
   * @description Get an async operation by ID. Returns type, arguments, status, results and other fields.
   */
  get_async_task: {
    parameters: {
      header?: {
        Accept?: components["parameters"]["accept"];
      };
      path: {
        /** @description The ID of the task. */
        task_id: number;
      };
    };
    responses: {
      200: components["responses"]["async_task_one"];
      /** @description Unauthorized */
      401: {
        content: never;
      };
      /** @description Not Found */
      404: {
        content: never;
      };
    };
  };
  /**
   * Delete async operation by ID
   * @description Delete an async operation by ID. Returns the task id and other related data.
   */
  delete_async_task: {
    parameters: {
      header?: {
        Accept?: components["parameters"]["accept"];
      };
      path: {
        /** @description The ID of the task. */
        task_id: number;
      };
    };
    responses: {
      /** @description Success */
      200: {
        content: never;
      };
      /** @description Bad Request (e.g. task is running) */
      400: {
        content: never;
      };
      /** @description Forbidden */
      403: {
        content: never;
      };
      /** @description Not Found */
      404: {
        content: never;
      };
    };
  };
  /**
   * Rerun async operation
   * @description Rerun an async operation. This is used to re-run an async operation. The task will be re-created and executed with the same arguments.
   */
  rerun_async_task: {
    parameters: {
      header?: {
        Accept?: components["parameters"]["accept"];
      };
      path: {
        /** @description The task id. */
        task_id: number;
      };
    };
    responses: {
      200: components["responses"]["async_task_one"];
      /** @description Unauthorized */
      401: {
        content: never;
      };
      /** @description Not Found */
      404: {
        content: never;
      };
    };
  };
  /**
   * Get async operation result
   * @description Get the result of an async operation.
   */
  get_async_task_result: {
    parameters: {
      header?: {
        Accept?: components["parameters"]["accept"];
      };
      path: {
        /** @description The ID of the task. */
        task_id: number;
      };
    };
    responses: {
      /** @description Processing */
      102: {
        content: never;
      };
      /** @description Success */
      200: {
        content: {
          "application/json": Record<string, never>;
        };
      };
      /** @description Bad Request */
      400: {
        content: never;
      };
      /** @description Not Found */
      404: {
        content: never;
      };
    };
  };
  /**
   * Get download link for async operation result
   * @description Get a download link for the result of an async operation.
   */
  get_async_task_download_link: {
    parameters: {
      header?: {
        Accept?: components["parameters"]["accept"];
      };
      path: {
        /** @description The ID of the task. */
        task_id: string;
      };
    };
    responses: {
      /** @description Success */
      200: {
        content: {
          "application/json": string;
        };
      };
      /** @description Bad Request. Returned when tasks is not completed, or doesn't support downloading the result. */
      400: {
        content: never;
      };
      /** @description Not Found */
      404: {
        content: never;
      };
    };
  };
  /**
   * Acknowledge async operation
   * @description Acknowledge an async operation. This is used to confirm that the user has seen the results of the async operation. After that, if tasks has stored results, they will be deleted.
   */
  acknowledge_async_task: {
    parameters: {
      header?: {
        Accept?: components["parameters"]["accept"];
      };
      path: {
        /** @description The task id. */
        task_id: number;
      };
    };
    responses: {
      /** @description Success */
      200: components["responses"]["async_task_one"];
      /** @description Not Found */
      404: {
        content: never;
      };
    };
  };
  /**
   * Get all Custom Runtimes
   * @description Retrieves a list of all custom runtimes defined for the organization.
   */
  get_runtimes: {
    responses: {
      200: components["responses"]["runtimes_many"];
      /** @description Unauthorized */
      401: {
        content: never;
      };
      /** @description Forbidden */
      403: {
        content: never;
      };
    };
  };
  /**
   * Create a Custom Runtime
   * @description Creates a custom runtime with the specified configuration.
   */
  create_runtime: {
    requestBody?: {
      content: {
        "application/json": components["schemas"]["RuntimePayload"];
      };
    };
    responses: {
      200: components["responses"]["runtimes_one"];
      /** @description Unauthorized */
      401: {
        content: never;
      };
      /** @description Forbidden */
      403: {
        content: never;
      };
    };
  };
  /**
   * Get a custom runtime by ID
   * @description Retrieves a custom runtime
   */
  get_runtime: {
    parameters: {
      path: {
        /** @description The ID of the runtime to retrieve */
        runtime_id: number;
      };
    };
    responses: {
      200: components["responses"]["runtimes_one"];
      /** @description Unauthorized */
      401: {
        content: never;
      };
      /** @description Forbidden */
      403: {
        content: never;
      };
    };
  };
  /**
   * Update a Custom Runtime
   * @description Updates a custom runtime.
   */
  update_runtime: {
    parameters: {
      path: {
        /** @description The ID of the runtime to update */
        runtime_id: number;
      };
    };
    requestBody?: {
      content: {
        "application/json": components["schemas"]["RuntimePayload"];
      };
    };
    responses: {
      200: components["responses"]["runtimes_one"];
      /** @description Unauthorized */
      401: {
        content: never;
      };
      /** @description Forbidden */
      403: {
        content: never;
      };
    };
  };
  /**
   * Delete a Custom Runtime
   * @description Creates a custom runtime with the specified configuration.
   */
  delete_runtime: {
    parameters: {
      path: {
        /** @description The ID of the runtime to delete */
        runtime_id: number;
      };
    };
    responses: {
      /** @description Success */
      200: {
        content: never;
      };
      /** @description Unauthorized */
      401: {
        content: never;
      };
      /** @description Forbidden */
      403: {
        content: never;
      };
    };
  };
  /**
   * Activate a Custom Runtime
   * @description Activates a custom runtime with the specified ID.
   */
  activate_runtime: {
    parameters: {
      path: {
        /** @description The ID of the runtime to activate */
        runtime_id: number;
      };
    };
    responses: {
      200: components["responses"]["runtimes_one"];
      /** @description Unauthorized */
      401: {
        content: never;
      };
      /** @description Forbidden */
      403: {
        content: never;
      };
    };
  };
  /**
   * Pause a Custom Runtime
   * @description Pause a custom runtime with the specified ID.
   */
  pause_runtime: {
    parameters: {
      path: {
        /** @description The ID of the runtime to pause */
        runtime_id: number;
      };
    };
    responses: {
      200: components["responses"]["runtimes_one"];
      /** @description Unauthorized */
      401: {
        content: never;
      };
      /** @description Forbidden */
      403: {
        content: never;
      };
    };
  };
  /**
   * Get all GenAI configs in org
   * @description Retrieves all GenAI configurations accessible to the authenticated user.
   */
  get_gen_ai_configs: {
    parameters: {
      header?: {
        Accept?: components["parameters"]["accept"];
      };
    };
    responses: {
      200: components["responses"]["gen_ai_configs_many"];
      /** @description Unauthorized */
      401: {
        content: never;
      };
      /** @description Forbidden */
      403: {
        content: never;
      };
    };
  };
  /**
   * Create a GenAI config
   * @description Creates a GenAI configuration.
   */
  create_gen_ai_config: {
    requestBody?: {
      content: {
        "application/json": components["schemas"]["GenAiConfigPayload"];
      };
    };
    responses: {
      200: components["responses"]["gen_ai_configs_one"];
      /** @description Bad Request */
      400: {
        content: never;
      };
      /** @description Unauthorized */
      401: {
        content: never;
      };
      /** @description Forbidden */
      403: {
        content: never;
      };
    };
  };
  /**
   * Get GenAI Integration Config
   * @description Retrieves a GenAI integration configuration by ID.
   */
  get_gen_ai_integration_config: {
    parameters: {
      header?: {
        Accept?: components["parameters"]["accept"];
      };
      path: {
        /** @description The unique ID of the GenAI config. */
        set_id: number;
      };
    };
    responses: {
      200: components["responses"]["gen_ai_configs_one"];
      /** @description Unauthorized */
      401: {
        content: never;
      };
      /** @description Forbidden */
      403: {
        content: never;
      };
      /** @description Not Found */
      404: {
        content: never;
      };
    };
  };
  /**
   * Update GenAI Integration Config
   * @description Updates a GenAI integration configuration by ID.
   */
  update_gen_ai_integration_config: {
    parameters: {
      header?: {
        Accept?: components["parameters"]["accept"];
      };
      path: {
        /** @description The unique ID of the GenAI config. */
        set_id: number;
      };
    };
    requestBody?: {
      content: {
        "application/json": components["schemas"]["GenAiConfigCreatePayload"];
      };
    };
    responses: {
      200: components["responses"]["gen_ai_configs_one"];
      /** @description Bad Request */
      400: {
        content: never;
      };
      /** @description Unauthorized */
      401: {
        content: never;
      };
      /** @description Forbidden */
      403: {
        content: never;
      };
      /** @description Not Found */
      404: {
        content: never;
      };
    };
  };
  /**
   * Delete GenAI Integration Config
   * @description Deletes a GenAI integration configuration by ID.
   */
  delete_gen_ai_integration_config: {
    parameters: {
      header?: {
        Accept?: components["parameters"]["accept"];
      };
      path: {
        /** @description The unique ID of the GenAI config. */
        set_id: number;
      };
    };
    responses: {
      /** @description Success */
      200: {
        content: never;
      };
      /** @description Unauthorized */
      401: {
        content: never;
      };
      /** @description Forbidden */
      403: {
        content: never;
      };
      /** @description Not Found */
      404: {
        content: never;
      };
    };
  };
  /**
   * Get all bindings of GenAI configs of the org for specified usages.
   * @description Retrieves all activated GenAI configurations for the org.
   */
  get_gen_ai_org_settings: {
    parameters: {
      query?: {
        /** @description The ID of the org (super-admin access required). */
        org_id?: number;
        /** @description Flag to fetch all config bindings in the system (super-admin access required). */
        all?: boolean;
      };
      header?: {
        Accept?: components["parameters"]["accept"];
      };
    };
    responses: {
      200: components["responses"]["gen_ai_org_settings_many"];
      /** @description Unauthorized */
      401: {
        content: never;
      };
      /** @description Forbidden */
      403: {
        content: never;
      };
      /** @description Not Found */
      404: {
        content: never;
      };
    };
  };
  /**
   * Create a binding of GenAI config for the org for specific usage.
   * @description Activates a GenAI configuration for specific usage. All other bindings for the same usage will be deactivated.
   */
  create_gen_ai_org_setting: {
    parameters: {
      header?: {
        Accept?: components["parameters"]["accept"];
      };
    };
    requestBody?: {
      content: {
        "application/json": components["schemas"]["GenAiOrgSettingPayload"];
      };
    };
    responses: {
      200: components["responses"]["gen_ai_org_settings_one"];
      /** @description Unauthorized */
      401: {
        content: never;
      };
      /** @description Forbidden */
      403: {
        content: never;
      };
      /** @description Not Found */
      404: {
        content: never;
      };
    };
  };
  /**
   * Get Org GenAI binding
   * @description Retrieves a GenAI configuration binding by ID.
   */
  get_gen_ai_org_setting: {
    parameters: {
      header?: {
        Accept?: components["parameters"]["accept"];
      };
      path: {
        /** @description The unique ID of the GenAI config. */
        org_gen_ai_config_id: number;
      };
    };
    responses: {
      200: components["responses"]["gen_ai_org_settings_one"];
      /** @description Unauthorized */
      401: {
        content: never;
      };
      /** @description Forbidden */
      403: {
        content: never;
      };
      /** @description Not Found */
      404: {
        content: never;
      };
    };
  };
  /**
   * Delete GenAI Config binding for org.
   * @description Delete GenAI config binding for an org (disables a GenAI configuration usage).
   */
  delete_gen_ai_org_setting: {
    parameters: {
      header?: {
        Accept?: components["parameters"]["accept"];
      };
      path: {
        /** @description The unique ID of the GenAI config. */
        org_gen_ai_config_id: number;
      };
    };
    responses: {
      /** @description Success */
      200: {
        content: never;
      };
      /** @description Unauthorized */
      401: {
        content: never;
      };
      /** @description Forbidden */
      403: {
        content: never;
      };
      /** @description Not Found */
      404: {
        content: never;
      };
    };
  };
  /**
   * Shows active GenAI Configuration for specific usage
   * @description Shows active GenAI Configuration for specific usage
   */
  gen_ai_org_settings_show_active: {
    parameters: {
      query: {
        /** @description The usage of the GenAI configuration. */
        gen_ai_usage: string;
      };
      header?: {
        Accept?: components["parameters"]["accept"];
      };
    };
    responses: {
      /** @description Success */
      200: {
        content: never;
      };
      /** @description Unauthorized */
      401: {
        content: never;
      };
      /** @description Forbidden */
      403: {
        content: never;
      };
      /** @description Not Found */
      404: {
        content: never;
      };
    };
  };
  /** Send one record to Webhook */
  send_one_record: {
    parameters: {
      path: {
        /**
         * @description Set this to `true` if you wish to send any custom headers to be included in the ingested records as part of the request.
         *
         * The platform will ignore standard headers like `Authorization` and `Content-Type`. Any custom headers will be added as a `header_<header_name>` attribute in the record.
         *
         * Example: The request header `NEX-HEADER: test` will be ingested as the attribute `header_NEX-HEADER` with the value `test`.
         *
         * Default value: `false`
         */
        include_headers: boolean;
        /**
         * @description Set this to `true` if you wish to send any custom query parameters to be included in the ingested records as part of the request.
         *
         * The platform will ignore standard query parameters like `api_key`. Any custom query parameters will be added as a `url_param_<param_name>` attribute in the record.
         *
         * Example: The request query parameter `abc=def` will be ingested as the attribute `url_param_abc` with the value `def`.
         *
         * Default value: `false`
         */
        include_url_params: boolean;
        /**
         * @description Usually, the platform performs Nexset schema detection only for the first few records from a new webhook. This is to avoid any unnecessary latencies in webhook record processing.
         *
         * Set this to `true` if you wish to enforce any webhook event to trigger schema detection.
         *
         * Default value: `false`
         */
        force_schema_detection: boolean;
      };
    };
    requestBody?: {
      content: {
        /**
         * @example {
         *   "id": 1,
         *   "name": "one"
         * }
         */
        "application/json": components["schemas"]["nexset_record"];
        /**
         * @example <root>
         *   <id>1</id>
         *   <name>one</name>
         * </root>
         */
        "application/xml": {
          root?: components["schemas"]["nexset_record"];
        };
      };
    };
    responses: {
      /** @description Returns the 200 status to indicate that data was received. */
      200: {
        content: {
          "application/json": {
            /** @description Nexset ID of the Nexset to which this record is sent. */
            datasetId?: number;
            /** @description Number of records successfully processed by Nexla. */
            processed?: number;
          };
        };
      };
      /** @description Request failed authentication */
      403: {
        content: never;
      };
      /** @description Returned when the service is not able to consume the data. */
      500: {
        content: {
          "application/json": {
            /**
             * @description Descriptive text about the error reason.
             *
             * @example Source #1000 is PAUSED
             */
            error?: string;
          };
        };
      };
    };
  };
  /**
   * Send many records to Webhook
   * @description Send an array of JSON objects. Nexla will treat each object as a unique record for the webhook.
   */
  send_many_records: {
    parameters: {
      path: {
        /**
         * @description Set this to `true` if you wish to send any custom headers to be included in the ingested record as part of the request.
         *
         * The platform will ignore standard headers like `Authorization` and `Content-Type`. Any custom headers will be added as a `header_<header_name>` attribute in the record.
         *
         * Example: The request header `NEX-HEADER: test`  will be ingested as the attribute `header_NEX-HEADER` with the value `test`.
         *
         * Default value: `false`
         */
        include_headers: boolean;
        /**
         * @description Set this to `true` if you wish to send any custom query parameters to be included in the ingested records as part of the request.
         *
         * The platform will ignore standard query parameters like `api_key`. Any custom query parameters will be added as a `url_param_<param_name>` attribute in the record.
         *
         * Example: The request query parameter `abc=def` will be ingested as the attribute `url_param_abc` with the value `def`.
         *
         * Default value: `false`
         */
        include_url_params: boolean;
        /**
         * @description Usually, the platform performs Nexset schema detection only for the first few records from a new webhook. This is to avoid any unnecessary latencies in webhook record processing.
         *
         * Set this to `true` if you wish to enforce any webhook event to trigger schema detection.
         *
         * Default value: `false`
         */
        force_schema_detection: boolean;
      };
    };
    requestBody?: {
      content: {
        "application/json": components["schemas"]["nexset_record"][];
      };
    };
    responses: {
      /** @description Returns the 200 status to indicate that data was received. */
      200: {
        content: {
          "application/json": {
            /** @description Nexset ID of the Nexset to which this record is sent. */
            datasetId?: number;
            /** @description Number of records successfully processed by Nexla. */
            processed?: number;
          };
        };
      };
      /** @description Request failed authentication */
      403: {
        content: never;
      };
      /** @description Returned when the service is not able to consume the data. */
      500: {
        content: {
          "application/json": {
            /**
             * @description Descriptive text about the error reason.
             *
             * @example Source #1000 is PAUSED
             */
            error?: string;
          };
        };
      };
    };
  };
}
